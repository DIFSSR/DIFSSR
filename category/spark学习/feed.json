{
    "version": "https://jsonfeed.org/version/1",
    "title": "千里稻花应秀色 • All posts by \"spark学习\" category",
    "description": "blogs by SSR",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2021/10/13/Spark%E5%AD%A6%E4%B9%A0/Spark-RDD/",
            "url": "http://example.com/2021/10/13/Spark%E5%AD%A6%E4%B9%A0/Spark-RDD/",
            "title": "Spark+RDD",
            "date_published": "2021-10-13T00:40:00.000Z",
            "content_html": "<h1 id=\"spark-rdd编程案例\"><a class=\"markdownIt-Anchor\" href=\"#spark-rdd编程案例\">#</a> Spark RDD 编程案例</h1>\n<h2 id=\"wordcount\"><a class=\"markdownIt-Anchor\" href=\"#wordcount\">#</a> WordCount</h2>\n<p>WordCount 编程是我们最熟悉不过的了，使用 Spark 进行编写程序会比 MapReduce 编程简便许多。<br>\n代码示例如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.&#123;<span class=\"type\">SparkConf</span>, <span class=\"type\">SparkContext</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">WordCount</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> config: <span class=\"type\">SparkConf</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setMaster(<span class=\"string\">&quot;local[*]&quot;</span>).setAppName(<span class=\"string\">&quot;WordCount&quot;</span>)</span><br><span class=\"line\">\t<span class=\"comment\">//设置内核个数以及程序名称</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> sc: <span class=\"type\">SparkContext</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(config)</span><br><span class=\"line\">    <span class=\"comment\">//创建Spark上下文</span></span><br><span class=\"line\">    sc.setLogLevel(<span class=\"string\">&quot;WARN&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> result: <span class=\"type\">Array</span>[(<span class=\"type\">String</span>,<span class=\"type\">Int</span>)] = sc.textFile(<span class=\"string\">&quot;in&quot;</span>).</span><br><span class=\"line\">    <span class=\"comment\">//逐行读入数据，路径是项目根目录下in文件夹</span></span><br><span class=\"line\">      flatMap(_.split(<span class=\"string\">&quot; &quot;</span>)).</span><br><span class=\"line\">      <span class=\"comment\">//拆分单词</span></span><br><span class=\"line\">      map((_,<span class=\"number\">1</span>)).</span><br><span class=\"line\">      <span class=\"comment\">//将每个单词变成键值对</span></span><br><span class=\"line\">      reduceByKey(_+_).</span><br><span class=\"line\">      <span class=\"comment\">//对每个键值对进行处理，对于相同的键进行相加</span></span><br><span class=\"line\">      collect()</span><br><span class=\"line\">    result.foreach(x =&gt; println(x))</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里选择从本地文件导入数据，存放在 Idea 项目根目录下 in 文件夹，数据内容以及运行结果如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//输入数据</span></span><br><span class=\"line\">hadoop hello</span><br><span class=\"line\">spark hello</span><br><span class=\"line\">ambari yes</span><br><span class=\"line\">scala java</span><br><span class=\"line\">hive hbase</span><br><span class=\"line\">hadoop hello</span><br><span class=\"line\">spark hello</span><br><span class=\"line\">ambari yes</span><br><span class=\"line\">scala java</span><br><span class=\"line\">hive hbase</span><br><span class=\"line\">hive hbase</span><br><span class=\"line\">hadoop hello</span><br><span class=\"line\">spark hello</span><br><span class=\"line\">ambari yes</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//输出结果</span></span><br><span class=\"line\">(scala,<span class=\"number\">2</span>)</span><br><span class=\"line\">(hive,<span class=\"number\">3</span>)</span><br><span class=\"line\">(ambari,<span class=\"number\">3</span>)</span><br><span class=\"line\">(hello,<span class=\"number\">6</span>)</span><br><span class=\"line\">(java,<span class=\"number\">2</span>)</span><br><span class=\"line\">(spark,<span class=\"number\">3</span>)</span><br><span class=\"line\">(yes,<span class=\"number\">3</span>)</span><br><span class=\"line\">(hadoop,<span class=\"number\">3</span>)</span><br><span class=\"line\">(hbase,<span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"topn\"><a class=\"markdownIt-Anchor\" href=\"#topn\">#</a> TopN</h2>\n<p>TopN 功能是实现对一个较大数据量的数据进行排序，之后输出前 N 条数据，一般来说有 3 种类型的 TopN 写法，这里使用的是键不相同的写法。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.&#123;<span class=\"type\">SparkConf</span>, <span class=\"type\">SparkContext</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">TopN</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> config: <span class=\"type\">SparkConf</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setMaster(<span class=\"string\">&quot;local[*]&quot;</span>).setAppName(<span class=\"string\">&quot;TopN&quot;</span>) </span><br><span class=\"line\">    <span class=\"comment\">//设置内核个数以及程序名称</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> sc: <span class=\"type\">SparkContext</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(config) </span><br><span class=\"line\">    <span class=\"comment\">//创建Spark上下文</span></span><br><span class=\"line\">    sc.setLogLevel(<span class=\"string\">&quot;WARN&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> result: <span class=\"type\">Array</span>[(<span class=\"type\">String</span>,<span class=\"type\">String</span> )] = sc.textFile(<span class=\"string\">&quot;in/top/&quot;</span>) </span><br><span class=\"line\">    <span class=\"comment\">//逐行读入数据，路径是项目根目录下in/top文件夹</span></span><br><span class=\"line\">      .map(_.split(<span class=\"string\">&quot; &quot;</span>))</span><br><span class=\"line\">      <span class=\"comment\">//按空格分开</span></span><br><span class=\"line\">      .map(line =&gt; (line(<span class=\"number\">0</span>), line(<span class=\"number\">1</span>)))</span><br><span class=\"line\">      <span class=\"comment\">//映射键值对</span></span><br><span class=\"line\">      .sortByKey(<span class=\"literal\">false</span>)</span><br><span class=\"line\">      <span class=\"comment\">//按键进行排序，默认升序，false降序</span></span><br><span class=\"line\">      .take(<span class=\"number\">5</span>)</span><br><span class=\"line\">      <span class=\"comment\">//取结果前N个</span></span><br><span class=\"line\">    result.foreach(println)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>输入数据以及输出结果：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//输入数据</span></span><br><span class=\"line\"><span class=\"number\">56</span> test1</span><br><span class=\"line\"><span class=\"number\">73</span> test2</span><br><span class=\"line\"><span class=\"number\">84</span> test3</span><br><span class=\"line\"><span class=\"number\">74</span> test4</span><br><span class=\"line\"><span class=\"number\">83</span> test5</span><br><span class=\"line\"><span class=\"number\">93</span> test6</span><br><span class=\"line\"><span class=\"number\">88</span> test7</span><br><span class=\"line\"><span class=\"number\">81</span> test8</span><br><span class=\"line\"><span class=\"number\">92</span> test9</span><br><span class=\"line\"><span class=\"number\">34</span> test10</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//输出</span></span><br><span class=\"line\">(<span class=\"number\">93</span>,test6)</span><br><span class=\"line\">(<span class=\"number\">92</span>,test9)</span><br><span class=\"line\">(<span class=\"number\">88</span>,test7)</span><br><span class=\"line\">(<span class=\"number\">84</span>,test3)</span><br><span class=\"line\">(<span class=\"number\">83</span>,test5)</span><br></pre></td></tr></table></figure>\n<h2 id=\"avg\"><a class=\"markdownIt-Anchor\" href=\"#avg\">#</a> Avg</h2>\n<p>题目：给定一组键值对 (“spark”,2),(“hadoop”,6),(“hadoop”,4),(“spark”,6)，键值对的 key 表示图书名称，value 表示某天图书销量，请计算每个键对应的平均值，也就是计算每种图书的每天平均销量。<br>\n代码示例如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.&#123;<span class=\"type\">SparkConf</span>, <span class=\"type\">SparkContext</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">Avg</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> config: <span class=\"type\">SparkConf</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setMaster(<span class=\"string\">&quot;local[*]&quot;</span>).setAppName(<span class=\"string\">&quot;Avg&quot;</span>)</span><br><span class=\"line\">    <span class=\"comment\">//设置内核个数以及程序名称</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> sc: <span class=\"type\">SparkContext</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(config)</span><br><span class=\"line\">    <span class=\"comment\">//创建Spark上下文</span></span><br><span class=\"line\">    sc.setLogLevel(<span class=\"string\">&quot;WARN&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> data = <span class=\"type\">Array</span>((<span class=\"string\">&quot;spark&quot;</span>,<span class=\"number\">2</span>),(<span class=\"string\">&quot;hadoop&quot;</span>,<span class=\"number\">6</span>),(<span class=\"string\">&quot;hadoop&quot;</span>,<span class=\"number\">4</span>),(<span class=\"string\">&quot;spark&quot;</span>,<span class=\"number\">6</span>))</span><br><span class=\"line\">    <span class=\"keyword\">val</span> res = sc.parallelize(data)</span><br><span class=\"line\">    <span class=\"comment\">//读入数据</span></span><br><span class=\"line\">      .mapValues(a =&gt; (a,<span class=\"number\">1</span>))</span><br><span class=\"line\">      <span class=\"comment\">//将值映射成为（值，次数）的形式</span></span><br><span class=\"line\">      .reduceByKey((a,b) =&gt; (a._1+b._1,a._2+b._2))</span><br><span class=\"line\">      <span class=\"comment\">//相同键进行Reduce，累加次数以及销量</span></span><br><span class=\"line\">      .map(t =&gt; (t._1,t._2._1/t._2._2))</span><br><span class=\"line\">      <span class=\"comment\">//计算平均值</span></span><br><span class=\"line\">    res.foreach(println)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里使用简易的数组导入数据，使用 parallelize () 方法，输出如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//output</span></span><br><span class=\"line\">(spark,<span class=\"number\">4</span>)</span><br><span class=\"line\">(hadoop,<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">进程已结束，退出代码 <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"secondarysort\"><a class=\"markdownIt-Anchor\" href=\"#secondarysort\">#</a> SecondarySort</h2>\n<p>二次排序也是一个经典案例，实现按键排序的同时按值排序，代码如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.&#123;<span class=\"type\">SparkConf</span>, <span class=\"type\">SparkContext</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//定义一个比较类，重写比较方法，记得加上序列化</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SecondarySortKey</span>(<span class=\"params\">val first: <span class=\"type\">Int</span>, val second: <span class=\"type\">Int</span></span>) <span class=\"keyword\">extends</span> <span class=\"title\">Ordered</span>[<span class=\"type\">SecondarySortKey</span>] <span class=\"keyword\">with</span> <span class=\"title\">Serializable</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">compare</span></span>(other: <span class=\"type\">SecondarySortKey</span>): <span class=\"type\">Int</span> =</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>.first - other.first != <span class=\"number\">0</span>)</span><br><span class=\"line\">      <span class=\"keyword\">this</span>.first - other.first</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">      <span class=\"keyword\">this</span>.second - other.second</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">SecondarySort</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> config: <span class=\"type\">SparkConf</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setMaster(<span class=\"string\">&quot;local[*]&quot;</span>).setAppName(<span class=\"string\">&quot;SecondarySort&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">//设置内核个数以及程序名称</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> sc: <span class=\"type\">SparkContext</span> = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(config)</span><br><span class=\"line\">      <span class=\"comment\">//创建Spark上下文</span></span><br><span class=\"line\">    sc.setLogLevel(<span class=\"string\">&quot;WARN&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> result: <span class=\"type\">Array</span>[(<span class=\"type\">Int</span>,<span class=\"type\">Int</span>)] = sc.textFile(<span class=\"string\">&quot;in/second&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">//逐行读入数据，路径是项目根目录下in/second文件夹</span></span><br><span class=\"line\">      .map(_.split(<span class=\"string\">&quot; &quot;</span>))</span><br><span class=\"line\">      <span class=\"comment\">//按空格分开</span></span><br><span class=\"line\">      .map(line =&gt; (line(<span class=\"number\">0</span>).toInt, line(<span class=\"number\">1</span>).toInt)) </span><br><span class=\"line\">      <span class=\"comment\">//映射键值对</span></span><br><span class=\"line\">      .map(line =&gt; (<span class=\"keyword\">new</span> <span class=\"type\">SecondarySortKey</span>(line._1,line._2), line))</span><br><span class=\"line\">      <span class=\"comment\">//映射成为（可比较类，原数据）的形式</span></span><br><span class=\"line\">      .sortByKey(<span class=\"literal\">false</span>)</span><br><span class=\"line\">      <span class=\"comment\">//按键降序</span></span><br><span class=\"line\">      .map(x =&gt; x._2).collect()</span><br><span class=\"line\">      <span class=\"comment\">//排序完只保留原数据</span></span><br><span class=\"line\">    result.foreach(println)</span><br><span class=\"line\"></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>输入数据以及输出结果：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//input</span></span><br><span class=\"line\"><span class=\"number\">32</span> <span class=\"number\">35</span></span><br><span class=\"line\"><span class=\"number\">25</span> <span class=\"number\">46</span></span><br><span class=\"line\"><span class=\"number\">52</span> <span class=\"number\">65</span></span><br><span class=\"line\"><span class=\"number\">29</span> <span class=\"number\">85</span></span><br><span class=\"line\"><span class=\"number\">85</span> <span class=\"number\">42</span></span><br><span class=\"line\"><span class=\"number\">25</span> <span class=\"number\">45</span></span><br><span class=\"line\"><span class=\"number\">95</span> <span class=\"number\">96</span></span><br><span class=\"line\"><span class=\"number\">75</span> <span class=\"number\">96</span></span><br><span class=\"line\"><span class=\"number\">75</span> <span class=\"number\">62</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//output</span></span><br><span class=\"line\">(<span class=\"number\">95</span>,<span class=\"number\">96</span>)</span><br><span class=\"line\">(<span class=\"number\">85</span>,<span class=\"number\">42</span>)</span><br><span class=\"line\">(<span class=\"number\">75</span>,<span class=\"number\">96</span>)</span><br><span class=\"line\">(<span class=\"number\">75</span>,<span class=\"number\">62</span>)</span><br><span class=\"line\">(<span class=\"number\">52</span>,<span class=\"number\">65</span>)</span><br><span class=\"line\">(<span class=\"number\">32</span>,<span class=\"number\">35</span>)</span><br><span class=\"line\">(<span class=\"number\">29</span>,<span class=\"number\">85</span>)</span><br><span class=\"line\">(<span class=\"number\">25</span>,<span class=\"number\">46</span>)</span><br><span class=\"line\">(<span class=\"number\">25</span>,<span class=\"number\">45</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>",
            "tags": [
                "大数据"
            ]
        }
    ]
}