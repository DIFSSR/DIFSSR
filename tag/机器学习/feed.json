{
    "version": "https://jsonfeed.org/version/1",
    "title": "千里稻花应秀色 • All posts by \"机器学习\" tag",
    "description": "blogs by SSR",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/TensorFlow%E7%AC%94%E8%AE%B0/Ch1/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/TensorFlow%E7%AC%94%E8%AE%B0/Ch1/",
            "title": "第一讲 神经网络计算",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"实验环境准备\"><a class=\"markdownIt-Anchor\" href=\"#实验环境准备\">#</a> 实验环境准备</h1>\n<ul>\n<li>Anoconda3.7</li>\n<li>TensorFlow2.1</li>\n<li>PyCharm</li>\n</ul>\n<h2 id=\"安装anoconda\"><a class=\"markdownIt-Anchor\" href=\"#安装anoconda\">#</a> 安装 Anoconda</h2>\n<p>官网下载安装，勾选添加到环境变量。</p>\n<h2 id=\"安装tensorflow21\"><a class=\"markdownIt-Anchor\" href=\"#安装tensorflow21\">#</a> 安装 TensorFlow2.1</h2>\n<p>1 打开安装好的 Anoconda Prompt</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211211133411024.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211211133411024\"></p>\n<p>2 创建一个环境</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n TF2.1 python=3.7</span><br><span class=\"line\">y</span><br></pre></td></tr></table></figure>\n<p>3 进入新创建的环境</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda activate TF2.1</span><br></pre></td></tr></table></figure>\n<p>4 安装所需软件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">安装英伟达SDK10.1版本</span></span><br><span class=\"line\">conda install cudatoolkit=10.1</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">安装英伟达深度学习软件包7.6版本</span></span><br><span class=\"line\">conda install cudann=7.6</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">以上两条是为了支持N卡GPU，如果报错，暂时跳过</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">安装TensorFlow，指定版本2.1</span></span><br><span class=\"line\">pip install tensorflow==2.1</span><br></pre></td></tr></table></figure>\n<p>5 验证安装</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python</span><br><span class=\"line\">import tensorflow as tf </span><br><span class=\"line\">tf.__version__</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装pycharm\"><a class=\"markdownIt-Anchor\" href=\"#安装pycharm\">#</a> 安装 PyCharm</h2>\n<p>官网下载安装</p>\n<h2 id=\"新建工程\"><a class=\"markdownIt-Anchor\" href=\"#新建工程\">#</a> 新建工程</h2>\n<ul>\n<li>打开 PyCharm，新建工程，添加创建好的环境 TF2.1</li>\n<li>右键工程文件夹选择在文件管理器中打开（open in explorer）</li>\n<li>将课程代码拷贝进入工程目录</li>\n</ul>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211211150007347.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211211150007347\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211211150025257.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211211150025257\"></p>\n<h1 id=\"神经网络计算\"><a class=\"markdownIt-Anchor\" href=\"#神经网络计算\">#</a> 神经网络计算</h1>\n<p>本讲目标：学会神经网络计算过程，使用基于 TF2 原生代码搭建你的第一个的神经网络训练模型</p>\n<ul>\n<li>当今人工智能主流方向 —— 连接主义</li>\n<li>前向传播</li>\n<li>损失函数（初体会）</li>\n<li>梯度下降（初体会）</li>\n<li>学习率（初体会）</li>\n<li>反向传播更新参数</li>\n<li>Tensorflow2 常用函数</li>\n</ul>\n<h2 id=\"11-人工智能三学派\"><a class=\"markdownIt-Anchor\" href=\"#11-人工智能三学派\">#</a> 1.1 人工智能三学派</h2>\n<p>人工智能：让机器具备人的思维和意识。<br>\n<strong>人工智能三学派：</strong></p>\n<ul>\n<li>\n<p>行为主义：基于控制论，构建感知 - 动作控制系统。<br>\n（控制论，如平衡、行走、避障等自适应控制系统）</p>\n</li>\n<li>\n<p>符号主义：基于算数逻辑表达式，求解问题时先把问题描述为表达式，再求解表达式。<br>\n（可用公式描述、实现理性思维，如专家系统）</p>\n</li>\n<li>\n<p>连接主义：仿生学，模仿神经元连接关系。本课重点<br>\n（仿脑神经元连接，实现感性思维，如神经网络）</p>\n</li>\n</ul>\n<h2 id=\"12-基于连结主义的神经网络设计过程\"><a class=\"markdownIt-Anchor\" href=\"#12-基于连结主义的神经网络设计过程\">#</a> 1.2 基于连结主义的神经网络设计过程</h2>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211211140449793.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211211140449793\"></p>\n<p>用计算机仿出神经网络连接关系，让计算机具备感性思维。</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211211140517854.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211211140517854\"></p>\n<ul>\n<li>准备数据：采集大量 “特征 / 标签” 数据</li>\n<li>搭建网络：搭建神经网络结构</li>\n<li>优化参数：训练网络获取最佳参数（反传）</li>\n<li>应用网络：将网络保存为模型，输入新数据，输出分类或预测结果（前传）</li>\n</ul>\n<h2 id=\"13-tf2\"><a class=\"markdownIt-Anchor\" href=\"#13-tf2\">#</a> 1.3 TF2</h2>\n<p>TensorFlow2</p>\n<ul>\n<li>2019 年 3 月 Tensorflow2.0 测试版发布</li>\n<li>2019 年 10 月 Tensorflow2.0 正式版发布</li>\n<li>2020 年 1 月 Tensorflow2.1 发布</li>\n</ul>\n<p><strong>张量</strong></p>\n<ul>\n<li>张量（Tensor）：多维数组（列表）阶：张量的维数</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>维数</th>\n<th>阶</th>\n<th>名字</th>\n<th>例子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0-D</td>\n<td>0</td>\n<td>标量 scalar</td>\n<td>s=123</td>\n</tr>\n<tr>\n<td>1-D</td>\n<td>1</td>\n<td>向量 vector</td>\n<td>v=[1,2,3]</td>\n</tr>\n<tr>\n<td>2-D</td>\n<td>2</td>\n<td>矩阵 matrix</td>\n<td>m=[[1,2,3],[4,5,6],[7,8,9]]</td>\n</tr>\n<tr>\n<td>3-D</td>\n<td>n</td>\n<td>张量 tensor</td>\n<td>t=[[[…]]]</td>\n</tr>\n</tbody>\n</table>\n<p><strong>数据类型</strong></p>\n<ul>\n<li>\n<p>tf.int, tf.float……<br>\ntf.int 32, tf.float32, tf.float64</p>\n</li>\n<li>\n<p>tf.bool<br>\ntf.constant([True, False])</p>\n</li>\n<li>\n<p>tf.string<br>\ntf.constant(“Hello, world!”)</p>\n</li>\n</ul>\n<p><strong>如何创建一个 Tensor</strong></p>\n<ul>\n<li>tf 创建一个张量<br>\n tf.constant (张量内容，dtype = 数据类型 (可选))</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflowas tf</span><br><span class=\"line\">a=tf.constant([<span class=\"number\">1</span>,<span class=\"number\">5</span>],dtype=tf.int64)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.dtype)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.shape)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>将 numpy 的数据类型转换为 Tensor 数据类型<br>\n tf. convert_to_tensor (数据名，dtype = 数据类型 (可选))</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflowas tf</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpyas np</span><br><span class=\"line\">a = np.arange(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">b = tf.convert_to_tensor( a, dtype=tf.int64 )</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(b)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>创建全为 0 的张量<br>\n tf. zeros (维度)</p>\n</li>\n<li>\n<p>创建全为 1 的张量<br>\n tf. ones (维度)</p>\n</li>\n<li>\n<p>创建全为指定值的张量<br>\n tf. fill (维度，指定值)</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">维度：</span></span><br><span class=\"line\"><span class=\"string\">一维直接写个数</span></span><br><span class=\"line\"><span class=\"string\">二维用[行，列]</span></span><br><span class=\"line\"><span class=\"string\">多维用[n,m,j,k……]</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">a = tf.zeros([<span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">b = tf.ones(<span class=\"number\">4</span>)</span><br><span class=\"line\">c = tf.fill([<span class=\"number\">2</span>, <span class=\"number\">2</span>], <span class=\"number\">9</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(c)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>生成正态分布的随机数，默认均值为 0，标准差为 1<br>\ntf. random.normal (维度，mean = 均值，stddev = 标准差)</p>\n</li>\n<li>\n<p>生成截断式正态分布的随机数<br>\n tf. random.truncated_normal (维度，mean = 均值，stddev = 标准差)<br>\n 在 tf.truncated_normal 中如果随机生成数据的取值在（μ-2σ，μ+2σ）之外则重新进行生成，保证了生成值在均值附近。<br>\nμ：均值，σ：标准差</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d = tf.random.normal([<span class=\"number\">2</span>, <span class=\"number\">2</span>], mean=<span class=\"number\">0.5</span>, stddev=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(d)</span><br><span class=\"line\">e = tf.random.truncated_normal([<span class=\"number\">2</span>, <span class=\"number\">2</span>], mean=<span class=\"number\">0.5</span>, stddev=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(e)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>生成均匀分布随机数 [minval, maxval)<br>\n tf. random. uniform (维度，minval = 最小值，maxval = 最大值)</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = tf.random.uniform([<span class=\"number\">2</span>, <span class=\"number\">2</span>], minval=<span class=\"number\">0</span>, maxval=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f)</span><br></pre></td></tr></table></figure>\n<h2 id=\"14-tf2常用函数\"><a class=\"markdownIt-Anchor\" href=\"#14-tf2常用函数\">#</a> 1.4 TF2 常用函数</h2>\n<ul>\n<li>强制 tensor 转换为该数据类型</li>\n</ul>\n<p>tf.cast (张量名，dtype = 数据类型)</p>\n<ul>\n<li>计算张量维度上元素的最小值</li>\n</ul>\n<p>tf.reduce_min (张量名)</p>\n<ul>\n<li>计算张量维度上元素的最大值</li>\n</ul>\n<p>tf.reduce_max (张量名)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x1 = tf.constant([<span class=\"number\">1.</span>, <span class=\"number\">2.</span>, <span class=\"number\">3.</span>],dtype=tf.float64)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x1)</span><br><span class=\"line\">x2 = tf.cast(x1, tf.int32)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x2)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (tf.reduce_min(x2), tf.reduce_max(x2))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">理解axis</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">在一个二维张量或数组中，可以通过调整</span></span><br><span class=\"line\"><span class=\"string\">axis 等于0或1 控制执行维度。</span></span><br><span class=\"line\"><span class=\"string\">axis=0代表跨行（经度，down)，而axis=1代表跨列（纬度，across)</span></span><br><span class=\"line\"><span class=\"string\">如果不指定axis，则所有元素参与计算。</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211211150529913.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211211150529913\"></p>\n<ul>\n<li>计算张量沿着指定维度的平均值</li>\n</ul>\n<p>tf.reduce_mean (张量名，axis = 操作轴)</p>\n<ul>\n<li>计算张量沿着指定维度的和</li>\n</ul>\n<p>tf.reduce_sum (张量名，axis = 操作轴)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=tf.constant( [ [ <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>],[ <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>] ] )</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.reduce_mean( x ))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.reduce_sum( x, axis=<span class=\"number\">1</span> ))</span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.Variable()</li>\n</ul>\n<p>tf.Variable () 将变量标记为 “可训练”，被标记的变量会在反向传播中记录梯度信息。神经网络训练中，常用该函数标记待训练参数。<br>\ntf.Variable (初始值)<br>\nw = tf.Variable(tf.random.normal([2, 2], mean=0, stddev=1))</p>\n<p><strong>TensorFlow 中的数学运算</strong></p>\n<ul>\n<li>对应元素的四则运算：tf.add，tf.subtract，tf.multiply，tf.divide</li>\n</ul>\n<p>只有维度相同的张量才可以做四则运算</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = tf.ones([<span class=\"number\">1</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">b = tf.fill([<span class=\"number\">1</span>, <span class=\"number\">3</span>], <span class=\"number\">3.</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.add(a,b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.subtract(a,b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.multiply(a,b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.divide(b,a))</span><br></pre></td></tr></table></figure>\n<ul>\n<li>平方、次方与开方： tf.square，tf.pow，tf.sqrt</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = tf.fill([<span class=\"number\">1</span>, <span class=\"number\">2</span>], <span class=\"number\">3.</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.<span class=\"built_in\">pow</span>(a, <span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.square(a))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.sqrt(a))</span><br></pre></td></tr></table></figure>\n<ul>\n<li>矩阵乘：tf.matmul</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">tf.matmul(矩阵1，矩阵2)</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">a = tf.ones([<span class=\"number\">3</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">b = tf.fill([<span class=\"number\">2</span>, <span class=\"number\">3</span>], <span class=\"number\">3.</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(tf.matmul(a, b))</span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.data.Dataset.from_tensor_slices</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">切分传入张量的第一维度，生成输入特征/标签对，构建数据集</span></span><br><span class=\"line\"><span class=\"string\">data = tf.data.Dataset.from_tensor_slices((输入特征, 标签))</span></span><br><span class=\"line\"><span class=\"string\">（Numpy和Tensor格式都可用该语句读入数据）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">features = tf.constant([<span class=\"number\">12</span>,<span class=\"number\">23</span>,<span class=\"number\">10</span>,<span class=\"number\">17</span>])</span><br><span class=\"line\">labels = tf.constant([<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\">dataset = tf.data.Dataset.from_tensor_slices((features, labels))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dataset)</span><br><span class=\"line\"><span class=\"keyword\">for</span> element <span class=\"keyword\">in</span> dataset:</span><br><span class=\"line\">  <span class=\"built_in\">print</span>(element)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.GradientTape</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">with结构记录计算过程，gradient求出张量的梯度</span></span><br><span class=\"line\"><span class=\"string\">with tf.GradientTape( ) as tape:</span></span><br><span class=\"line\"><span class=\"string\">  若干个计算过程</span></span><br><span class=\"line\"><span class=\"string\">grad=tape.gradient(函数，对谁求导)</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.GradientTape( ) <span class=\"keyword\">as</span> tape:</span><br><span class=\"line\">  w = tf.Variable(tf.constant(<span class=\"number\">3.0</span>))</span><br><span class=\"line\">  loss = tf.<span class=\"built_in\">pow</span>(w,<span class=\"number\">2</span>)</span><br><span class=\"line\">grad = tape.gradient(loss,w)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(grad)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>enumerate</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">enumerate是python的内建函数，它可遍历每个元素(如列表、元组</span></span><br><span class=\"line\"><span class=\"string\">或字符串)，组合为：索引 元素，常在for循环中使用。</span></span><br><span class=\"line\"><span class=\"string\">enumerate(列表名)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">seq = [<span class=\"string\">&#x27;one&#x27;</span>, <span class=\"string\">&#x27;two&#x27;</span>, <span class=\"string\">&#x27;three&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, element <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(seq):</span><br><span class=\"line\">  <span class=\"built_in\">print</span>(i, element)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.one_hot</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">独热编码（one-hot encoding）：在分类问题中，常用独热码做标签，标记类别：1表示是，0表示非.</span></span><br><span class=\"line\"><span class=\"string\">tf.one_hot (待转换数据, depth=几分类)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">classes = <span class=\"number\">3</span></span><br><span class=\"line\">labels = tf.constant([<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">2</span>]) <span class=\"comment\"># 输入的元素值最小为0，最大为2</span></span><br><span class=\"line\">output = tf.one_hot( labels, depth=classes )</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.nn.softmax</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">tf.nn.softmax(x) 使输出符合概率分布</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">y = tf.constant ( [<span class=\"number\">1.01</span>, <span class=\"number\">2.01</span>, -<span class=\"number\">0.66</span>] )</span><br><span class=\"line\">y_pro = tf.nn.softmax(y)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;After softmax, y_pro is:&quot;</span>, y_pro)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>assign_sub</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">赋值操作，更新参数的值并返回。</span></span><br><span class=\"line\"><span class=\"string\">调用assign_sub前，先用 tf.Variable 定义变量 w 为可训练（可自更新）。</span></span><br><span class=\"line\"><span class=\"string\">w.assign_sub (w要自减的内容) </span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">w = tf.Variable(<span class=\"number\">4</span>)</span><br><span class=\"line\">w.assign_sub(<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(w)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.argmax</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">返回张量沿指定维度最大值的索引tf.argmax (张量名,axis=操作轴)</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">test = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">4</span>, <span class=\"number\">3</span>], [<span class=\"number\">8</span>, <span class=\"number\">7</span>, <span class=\"number\">2</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>( tf.argmax (test, axis=<span class=\"number\">0</span>)) <span class=\"comment\"># 返回每一列（经度）最大值的索引</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>( tf.argmax (test, axis=<span class=\"number\">1</span>)) <span class=\"comment\"># 返回每一行（纬度）最大值的索引</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"15-神经网络实现鸢尾花分类\"><a class=\"markdownIt-Anchor\" href=\"#15-神经网络实现鸢尾花分类\">#</a> 1.5 神经网络实现鸢尾花分类</h2>\n<h3 id=\"数据集介绍\"><a class=\"markdownIt-Anchor\" href=\"#数据集介绍\">#</a> 数据集介绍</h3>\n<p>共有数据 150 组，每组包括花萼长、花萼宽、花瓣长、花瓣宽 4 个输入特征。同时给出了，这一组特征对应的鸢尾花类别。类别包括 Setosa Iris（狗尾草鸢尾），Versicolour Iris（杂色鸢尾），Virginica Iris（弗吉尼亚鸢尾）三类，分别用数字 0，1，2 表示。</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211212172907509.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211212172907509\"></p>\n<h3 id=\"准备数据\"><a class=\"markdownIt-Anchor\" href=\"#准备数据\">#</a> 准备数据</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#数据集读入</span></span><br><span class=\"line\"><span class=\"comment\">#从sklearn包datasets 读入数据集：</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\">x_data = datasets.load_iris().data 返回iris数据集所有输入特征</span><br><span class=\"line\">y_data = datasets.load_iris().target 返回iris数据集所有标签</span><br><span class=\"line\"><span class=\"comment\">#数据集乱序</span></span><br><span class=\"line\">np.random.seed(<span class=\"number\">116</span>) <span class=\"comment\"># 使用相同的seed，使输入特征/标签一一对应</span></span><br><span class=\"line\">np.random.shuffle(x_data)</span><br><span class=\"line\">np.random.seed(<span class=\"number\">116</span>)</span><br><span class=\"line\">np.random.shuffle(y_data)</span><br><span class=\"line\">tf.random.set_seed(<span class=\"number\">116</span>)</span><br><span class=\"line\"><span class=\"comment\">#数据集分出永不相见的训练集和测试集</span></span><br><span class=\"line\">x_train = x_data[:-<span class=\"number\">30</span>]</span><br><span class=\"line\">y_train = y_data[:-<span class=\"number\">30</span>]</span><br><span class=\"line\">x_test = x_data[-<span class=\"number\">30</span>:]</span><br><span class=\"line\">y_test = y_data[-<span class=\"number\">30</span>:]</span><br><span class=\"line\"><span class=\"comment\">#配成[输入特征，标签]对，每次喂入一小撮（batch）</span></span><br><span class=\"line\">train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(<span class=\"number\">32</span>)</span><br><span class=\"line\">test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class=\"number\">32</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"搭建网络\"><a class=\"markdownIt-Anchor\" href=\"#搭建网络\">#</a> 搭建网络</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#定义神经网路中所有可训练参数</span></span><br><span class=\"line\">w1 = tf.Variable(tf.random.truncated_normal([ <span class=\"number\">4</span>, <span class=\"number\">3</span> ], stddev=<span class=\"number\">0.1</span>, seed=<span class=\"number\">1</span>))</span><br><span class=\"line\">b1 = tf.Variable(tf.random.truncated_normal([ <span class=\"number\">3</span> ], stddev=<span class=\"number\">0.1</span>, seed=<span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"参数优化\"><a class=\"markdownIt-Anchor\" href=\"#参数优化\">#</a> 参数优化</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#嵌套循环迭代，with结构更新参数，显示当前loss</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(epoch): <span class=\"comment\">#数据集级别迭代</span></span><br><span class=\"line\">  <span class=\"keyword\">for</span> step, (x_train, y_train) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(train_db): <span class=\"comment\">#batch级别迭代</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.GradientTape() <span class=\"keyword\">as</span> tape: <span class=\"comment\"># 记录梯度信息</span></span><br><span class=\"line\">      前向传播过程计算y</span><br><span class=\"line\">      计算总loss</span><br><span class=\"line\">    grads = tape.gradient(loss, [ w1, b1 ])</span><br><span class=\"line\">    w1.assign_sub(lr * grads[<span class=\"number\">0</span>]) <span class=\"comment\">#参数自更新</span></span><br><span class=\"line\">    b1.assign_sub(lr * grads[<span class=\"number\">1</span>])</span><br><span class=\"line\">  <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Epoch &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(epoch, loss_all/<span class=\"number\">4</span>))</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试效果\"><a class=\"markdownIt-Anchor\" href=\"#测试效果\">#</a> 测试效果</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算当前参数前向传播后的准确率，显示当前acc</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> x_test, y_test <span class=\"keyword\">in</span> test_db:</span><br><span class=\"line\">y = tf.matmul(h, w) + b <span class=\"comment\"># y为预测结果</span></span><br><span class=\"line\">y = tf.nn.softmax(y) <span class=\"comment\"># y符合概率分布</span></span><br><span class=\"line\">pred = tf.argmax(y, axis=<span class=\"number\">1</span>) <span class=\"comment\"># 返回y中最大值的索引，即预测的分类</span></span><br><span class=\"line\">pred = tf.cast(pred, dtype=y_test.dtype) <span class=\"comment\">#调整数据类型与标签一致</span></span><br><span class=\"line\">correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)</span><br><span class=\"line\">correct = tf.reduce_sum (correct) <span class=\"comment\"># 将每个batch的correct数加起来</span></span><br><span class=\"line\">total_correct += <span class=\"built_in\">int</span> (correct) <span class=\"comment\"># 将所有batch中的correct数加起来</span></span><br><span class=\"line\">total_number += x_test.shape [<span class=\"number\">0</span>]</span><br><span class=\"line\">acc = total_correct / total_number</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;test_acc:&quot;</span>, acc)</span><br></pre></td></tr></table></figure>\n<h3 id=\"accloss可视化\"><a class=\"markdownIt-Anchor\" href=\"#accloss可视化\">#</a> acc/loss 可视化</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#acc / loss可视化</span></span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Acc Curve&#x27;</span>) <span class=\"comment\"># 图片标题</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Epoch&#x27;</span>) <span class=\"comment\"># x轴名称</span></span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Acc&#x27;</span>) <span class=\"comment\"># y轴名称</span></span><br><span class=\"line\">plt.plot(test_acc, label=<span class=\"string\">&quot;$Accuracy$&quot;</span>) <span class=\"comment\"># 逐点画出test_acc值并连线</span></span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "title": "基于支持向量机的分类预测",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"1-前言\"><a class=\"markdownIt-Anchor\" href=\"#1-前言\">#</a> 1 前言</h1>\n<p>支持向量机（Support Vector Machine，SVM）是一个非常优雅的算法，具有非常完善的数学理论，常用于数据分类，也可以用于数据的回归预测中，由于其其优美的理论保证和利用核函数对于线性不可分问题的处理技巧，在上世纪 90 年代左右，SVM 曾红极一时。</p>\n<p>本文将不涉及非常严格和复杂的理论知识，力求于通过直觉来感受 SVM。</p>\n<h1 id=\"2-学习目标\"><a class=\"markdownIt-Anchor\" href=\"#2-学习目标\">#</a> 2 学习目标</h1>\n<p>了解支持向量机的分类标准；<br>\n了解支持向量机的软间隔分类；<br>\n了解支持向量机的非线性核函数分类；</p>\n<h1 id=\"3-代码流程\"><a class=\"markdownIt-Anchor\" href=\"#3-代码流程\">#</a> 3 代码流程</h1>\n<h4 id=\"demo实践\"><a class=\"markdownIt-Anchor\" href=\"#demo实践\">#</a> Demo 实践</h4>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 构建数据集并进行模型训练</li>\n<li>Step3: 模型参数查看</li>\n<li>Step4: 模型预测</li>\n<li>Step5: 模型可视化</li>\n</ul>\n<h1 id=\"4-算法实战\"><a class=\"markdownIt-Anchor\" href=\"#4-算法实战\">#</a> 4. 算法实战</h1>\n<h2 id=\"41-demo实践\"><a class=\"markdownIt-Anchor\" href=\"#41-demo实践\">#</a> 4.1 Demo 实践</h2>\n<p>首先我们利用 sklearn 直接调用 SVM 函数进行实践尝试</p>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##  基础函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 导入画图库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 导入逻辑回归模型函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn  <span class=\"keyword\">import</span> svm</span><br></pre></td></tr></table></figure>\n<p><strong>Step2: 构建数据集并进行模型训练</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##Demo演示LogisticRegression分类</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 构造数据集</span></span><br><span class=\"line\">x_fearures = np.array([[-<span class=\"number\">1</span>, -<span class=\"number\">2</span>], [-<span class=\"number\">2</span>, -<span class=\"number\">1</span>], [-<span class=\"number\">3</span>, -<span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">3</span>], [<span class=\"number\">2</span>, <span class=\"number\">1</span>], [<span class=\"number\">3</span>, <span class=\"number\">2</span>]])</span><br><span class=\"line\">y_label = np.array([<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 调用SVC模型 （支持向量机分类）</span></span><br><span class=\"line\">svc = svm.SVC(kernel=<span class=\"string\">&#x27;linear&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 用SVM模型拟合构造的数据集</span></span><br><span class=\"line\">svc = svc.fit(x_fearures, y_label) </span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 模型参数查看</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 查看其对应模型的w</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the weight of Logistic Regression:&#x27;</span>,svc.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看其对应模型的w0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the intercept(w0) of Logistic Regression:&#x27;</span>,svc.intercept_)</span><br></pre></td></tr></table></figure>\n<pre><code>the weight of Logistic Regression: [[0.33364706 0.33270588]]\nthe intercept(w0) of Logistic Regression: [-0.00031373]\n</code></pre>\n<p><strong>Step4: 模型预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 模型预测</span></span><br><span class=\"line\">y_train_pred = svc.predict(x_fearures)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The predction result:&#x27;</span>,y_train_pred)</span><br></pre></td></tr></table></figure>\n<pre><code>The predction result: [0 0 0 1 1 1]\n</code></pre>\n<p><strong>Step5: 模型可视化</strong></p>\n<p>由于此处选择的线性核函数，所以在此我们可以将 svm 进行可视化。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 最佳函数</span></span><br><span class=\"line\">x_range = np.linspace(-<span class=\"number\">3</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">w = svc.coef_[<span class=\"number\">0</span>]</span><br><span class=\"line\">a = -w[<span class=\"number\">0</span>] / w[<span class=\"number\">1</span>]</span><br><span class=\"line\">y_3 = a*x_range - (svc.intercept_[<span class=\"number\">0</span>]) / w[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化决策边界</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x_fearures[:,<span class=\"number\">0</span>],x_fearures[:,<span class=\"number\">1</span>], c=y_label, s=<span class=\"number\">50</span>, cmap=<span class=\"string\">&#x27;viridis&#x27;</span>)</span><br><span class=\"line\">plt.plot(x_range, y_3, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_9_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>可以对照之前的逻辑回归模型的决策边界，我们可以发现两个决策边界是有一定差异的（可以对比两者在 X,Y 轴上的截距），这说明这两个不同在相同数据集上找到的判别线是不同的，而这不同的原因其实是由于两者选择的最优目标是不一致的。接下来我们进行 SVM 的一些简单介绍。</p>\n<h1 id=\"5支持向量机介绍\"><a class=\"markdownIt-Anchor\" href=\"#5支持向量机介绍\">#</a> 5 支持向量机介绍</h1>\n<p>我们常常会碰到这样的一个问题，首先给你一些分属于两个类别的数据</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_blobs</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">60</span>, cmap=plt.cm.Paired)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.collections.PathCollection at 0x1d050096a58&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_11_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>现在需要一个线性分类器，将这些数据分开来。</p>\n<p>我们可能会有多种分法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"></span><br><span class=\"line\">x_fit = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画函数</span></span><br><span class=\"line\">y_1 = <span class=\"number\">1</span> * x_fit + <span class=\"number\">0.8</span></span><br><span class=\"line\">plt.plot(x_fit, y_1, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\">y_2 = -<span class=\"number\">0.3</span> * x_fit + <span class=\"number\">3</span></span><br><span class=\"line\">plt.plot(x_fit, y_2, <span class=\"string\">&#x27;-k&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>[&lt;matplotlib.lines.Line2D at 0x1d05011bf28&gt;]\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_13_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>那么现在有一个问题，两个分类器，哪一个更好呢？</p>\n<p>为了判断好坏，我们需要引入一个准则：好的分类器不仅仅是能够很好的分开已有的数据集，还能对未知数据集进行两个的划分。</p>\n<p>假设，现在有一个属于红色数据点的新数据（3， 2.8）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\">plt.scatter([<span class=\"number\">3</span>], [<span class=\"number\">2.8</span>], c=<span class=\"string\">&#x27;#cccc00&#x27;</span>, marker=<span class=\"string\">&#x27;&lt;&#x27;</span>, s=<span class=\"number\">100</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"></span><br><span class=\"line\">x_fit = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画函数</span></span><br><span class=\"line\">y_1 = <span class=\"number\">1</span> * x_fit + <span class=\"number\">0.8</span></span><br><span class=\"line\">plt.plot(x_fit, y_1, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\">y_2 = -<span class=\"number\">0.3</span> * x_fit + <span class=\"number\">3</span></span><br><span class=\"line\">plt.plot(x_fit, y_2, <span class=\"string\">&#x27;-k&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>[&lt;matplotlib.lines.Line2D at 0x1d050163470&gt;]\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_15_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>可以看到，此时黑色的线会把这个新的数据集分错，而蓝色的线不会。</p>\n<p>我们刚刚举的例子可能会带有一些主观性。</p>\n<p>那么如何客观的评判两条线的健壮性呢？</p>\n<p>此时，我们需要引入一个非常重要的概念：最大间隔。</p>\n<p>最大间隔刻画着当前分类器与数据集的边界，以这两个分类器为例：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"></span><br><span class=\"line\">x_fit = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画函数</span></span><br><span class=\"line\">y_1 = <span class=\"number\">1</span> * x_fit + <span class=\"number\">0.8</span></span><br><span class=\"line\">plt.plot(x_fit, y_1, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画边距</span></span><br><span class=\"line\">plt.fill_between(x_fit, y_1 - <span class=\"number\">0.6</span>, y_1 + <span class=\"number\">0.6</span>, edgecolor=<span class=\"string\">&#x27;none&#x27;</span>, color=<span class=\"string\">&#x27;#AAAAAA&#x27;</span>,</span><br><span class=\"line\">                 alpha=<span class=\"number\">0.4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">y_2 = -<span class=\"number\">0.3</span> * x_fit + <span class=\"number\">3</span></span><br><span class=\"line\">plt.plot(x_fit, y_2, <span class=\"string\">&#x27;-k&#x27;</span>)</span><br><span class=\"line\">plt.fill_between(x_fit, y_2 - <span class=\"number\">0.4</span>, y_2 + <span class=\"number\">0.4</span>, edgecolor=<span class=\"string\">&#x27;none&#x27;</span>, color=<span class=\"string\">&#x27;#AAAAAA&#x27;</span>, </span><br><span class=\"line\">                 alpha=<span class=\"number\">0.4</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.collections.PolyCollection at 0x1d05021dba8&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_17_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>可以看到， 蓝色的线最大间隔是大于黑色的线的。<br>\n所以我们会选择蓝色的线作为我们的分类器。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">y_1 = <span class=\"number\">1</span> * x_fit + <span class=\"number\">0.8</span></span><br><span class=\"line\">plt.plot(x_fit, y_1, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画边距</span></span><br><span class=\"line\">plt.fill_between(x_fit, y_1 - <span class=\"number\">0.6</span>, y_1 + <span class=\"number\">0.6</span>, edgecolor=<span class=\"string\">&#x27;none&#x27;</span>, </span><br><span class=\"line\">                 color=<span class=\"string\">&#x27;#AAAAAA&#x27;</span>, alpha=<span class=\"number\">0.4</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.collections.PolyCollection at 0x1d0502606a0&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_19_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>那么，我们现在的分类器是最优分类器吗？</p>\n<p>或者说，有没有更好的分类器，它具有更大的间隔？</p>\n<p>答案是有的。</p>\n<p>为了找出最优分类器，我们需要引入我们今天的主角：SVM</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"comment\"># SVM 函数</span></span><br><span class=\"line\">clf = SVC(kernel=<span class=\"string\">&#x27;linear&#x27;</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br></pre></td></tr></table></figure>\n<pre><code>SVC(kernel='linear')\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 最佳函数</span></span><br><span class=\"line\">w = clf.coef_[<span class=\"number\">0</span>]</span><br><span class=\"line\">a = -w[<span class=\"number\">0</span>] / w[<span class=\"number\">1</span>]</span><br><span class=\"line\">y_3 = a*x_fit - (clf.intercept_[<span class=\"number\">0</span>]) / w[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 最大边距 下届</span></span><br><span class=\"line\">b_down = clf.support_vectors_[<span class=\"number\">0</span>]</span><br><span class=\"line\">y_down = a* x_fit + b_down[<span class=\"number\">1</span>] - a * b_down[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\"># 最大边距 上届</span></span><br><span class=\"line\">b_up = clf.support_vectors_[-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_up = a* x_fit + b_up[<span class=\"number\">1</span>] - a * b_up[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"><span class=\"comment\"># 画函数</span></span><br><span class=\"line\">plt.plot(x_fit, y_3, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画边距</span></span><br><span class=\"line\">plt.fill_between(x_fit, y_down, y_up, edgecolor=<span class=\"string\">&#x27;none&#x27;</span>, color=<span class=\"string\">&#x27;#AAAAAA&#x27;</span>, alpha=<span class=\"number\">0.4</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画支持向量</span></span><br><span class=\"line\">plt.scatter(clf.support_vectors_[:, <span class=\"number\">0</span>], clf.support_vectors_[:, <span class=\"number\">1</span>], edgecolor=<span class=\"string\">&#x27;b&#x27;</span>,</span><br><span class=\"line\">            s=<span class=\"number\">80</span>, facecolors=<span class=\"string\">&#x27;none&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.collections.PathCollection at 0x1d05031fa90&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_23_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>带黑边的点是距离当前分类器最近的点，我们称之为支持向量。</p>\n<p>支持向量机为我们提供了在众多可能的分类器之间进行选择的原则，从而确保对未知数据集具有更高的泛化性。</p>\n<h2 id=\"32-软间隔\"><a class=\"markdownIt-Anchor\" href=\"#32-软间隔\">#</a> 3.2 软间隔</h2>\n<p>但很多时候，我们拿到的数据是这样子的</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.9</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.collections.PathCollection at 0x1d050383710&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_25_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>这种情况并不容易找到这样的最大间隔。</p>\n<p>于是我们就有了软间隔，相比于硬间隔而言，我们允许个别数据出现在间隔带中。</p>\n<p>我们知道，如果没有一个原则进行约束，满足软间隔的分类器也会出现很多条。</p>\n<p>所以需要对分错的数据进行惩罚，SVC 函数中，有一个参数 C 就是惩罚参数。</p>\n<p>惩罚参数越小，容忍性就越大。</p>\n<p>以 C=1 为例子，比如说：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.9</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"><span class=\"comment\"># 惩罚参数：C=1 </span></span><br><span class=\"line\">clf = SVC(C=<span class=\"number\">1</span>, kernel=<span class=\"string\">&#x27;linear&#x27;</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 最佳函数</span></span><br><span class=\"line\">w = clf.coef_[<span class=\"number\">0</span>]</span><br><span class=\"line\">a = -w[<span class=\"number\">0</span>] / w[<span class=\"number\">1</span>]</span><br><span class=\"line\">y_3 = a*x_fit - (clf.intercept_[<span class=\"number\">0</span>]) / w[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 最大边距 下届</span></span><br><span class=\"line\">b_down = clf.support_vectors_[<span class=\"number\">0</span>]</span><br><span class=\"line\">y_down = a* x_fit + b_down[<span class=\"number\">1</span>] - a * b_down[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\"># 最大边距 上届</span></span><br><span class=\"line\">b_up = clf.support_vectors_[-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_up = a* x_fit + b_up[<span class=\"number\">1</span>] - a * b_up[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"><span class=\"comment\"># 画函数</span></span><br><span class=\"line\">plt.plot(x_fit, y_3, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画边距</span></span><br><span class=\"line\">plt.fill_between(x_fit, y_down, y_up, edgecolor=<span class=\"string\">&#x27;none&#x27;</span>, color=<span class=\"string\">&#x27;#AAAAAA&#x27;</span>, alpha=<span class=\"number\">0.4</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画支持向量</span></span><br><span class=\"line\">plt.scatter(clf.support_vectors_[:, <span class=\"number\">0</span>], clf.support_vectors_[:, <span class=\"number\">1</span>], edgecolor=<span class=\"string\">&#x27;b&#x27;</span>,</span><br><span class=\"line\">            s=<span class=\"number\">80</span>, facecolors=<span class=\"string\">&#x27;none&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.collections.PathCollection at 0x1d0504224a8&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_27_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>惩罚参数 C=0.2 时，SVM 会更具包容性，从而兼容更多的错分样本：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.9</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"><span class=\"comment\"># 惩罚参数：C=0.2 </span></span><br><span class=\"line\">clf = SVC(C=<span class=\"number\">0.2</span>, kernel=<span class=\"string\">&#x27;linear&#x27;</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\">x_fit = np.linspace(-<span class=\"number\">1.5</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"comment\"># 最佳函数</span></span><br><span class=\"line\">w = clf.coef_[<span class=\"number\">0</span>]</span><br><span class=\"line\">a = -w[<span class=\"number\">0</span>] / w[<span class=\"number\">1</span>]</span><br><span class=\"line\">y_3 = a*x_fit - (clf.intercept_[<span class=\"number\">0</span>]) / w[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 最大边距 下届</span></span><br><span class=\"line\">b_down = clf.support_vectors_[<span class=\"number\">10</span>]</span><br><span class=\"line\">y_down = a* x_fit + b_down[<span class=\"number\">1</span>] - a * b_down[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\"># 最大边距 上届</span></span><br><span class=\"line\">b_up = clf.support_vectors_[<span class=\"number\">1</span>]</span><br><span class=\"line\">y_up = a* x_fit + b_up[<span class=\"number\">1</span>] - a * b_up[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_blobs(n_samples=<span class=\"number\">60</span>, centers=<span class=\"number\">2</span>, random_state=<span class=\"number\">0</span>, cluster_std=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"><span class=\"comment\"># 画函数</span></span><br><span class=\"line\">plt.plot(x_fit, y_3, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画边距</span></span><br><span class=\"line\">plt.fill_between(x_fit, y_down, y_up, edgecolor=<span class=\"string\">&#x27;none&#x27;</span>, color=<span class=\"string\">&#x27;#AAAAAA&#x27;</span>, alpha=<span class=\"number\">0.4</span>)</span><br><span class=\"line\"><span class=\"comment\"># 画支持向量</span></span><br><span class=\"line\">plt.scatter(clf.support_vectors_[:, <span class=\"number\">0</span>], clf.support_vectors_[:, <span class=\"number\">1</span>], edgecolor=<span class=\"string\">&#x27;b&#x27;</span>,</span><br><span class=\"line\">            s=<span class=\"number\">80</span>, facecolors=<span class=\"string\">&#x27;none&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.collections.PathCollection at 0x1d05049e390&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_29_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<h2 id=\"33-超平面\"><a class=\"markdownIt-Anchor\" href=\"#33-超平面\">#</a> 3.3 超平面</h2>\n<p>如果我们遇到这样的数据集，没有办法利用线性分类器进行分类</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_circles</span><br><span class=\"line\"><span class=\"comment\"># 画散点图</span></span><br><span class=\"line\">X, y = make_circles(<span class=\"number\">100</span>, factor=<span class=\"number\">.1</span>, noise=<span class=\"number\">.1</span>, random_state=<span class=\"number\">2019</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\"></span><br><span class=\"line\">clf = SVC(kernel=<span class=\"string\">&#x27;linear&#x27;</span>).fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 最佳函数</span></span><br><span class=\"line\">x_fit = np.linspace(-<span class=\"number\">1.5</span>, <span class=\"number\">1.5</span>)</span><br><span class=\"line\">w = clf.coef_[<span class=\"number\">0</span>]</span><br><span class=\"line\">a = -w[<span class=\"number\">0</span>] / w[<span class=\"number\">1</span>]</span><br><span class=\"line\">y_3 = a*X - (clf.intercept_[<span class=\"number\">0</span>]) / w[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(X, y_3, <span class=\"string\">&#x27;-c&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>[&lt;matplotlib.lines.Line2D at 0x1d050524dd8&gt;,\n &lt;matplotlib.lines.Line2D at 0x1d050524e80&gt;]\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_31_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>我们可以将二维（低维）空间的数据映射到三维（高维）空间中。</p>\n<p>此时，我们便可以通过一个超平面对数据进行划分</p>\n<p>所以，我们映射的目的在于使用 SVM 在高维空间找到超平面的能力。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数据映射</span></span><br><span class=\"line\">r = np.exp(-(X[:, <span class=\"number\">0</span>] ** <span class=\"number\">2</span> + X[:, <span class=\"number\">1</span>] ** <span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">ax = plt.subplot(projection=<span class=\"string\">&#x27;3d&#x27;</span>)</span><br><span class=\"line\">ax.scatter3D(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], r, c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;x&#x27;</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&#x27;y&#x27;</span>)</span><br><span class=\"line\">ax.set_zlabel(<span class=\"string\">&#x27;z&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x_1, y_1 = np.meshgrid(np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">1</span>), np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">z =  <span class=\"number\">0.01</span>*x_1 + <span class=\"number\">0.01</span>*y_1 + <span class=\"number\">0.5</span></span><br><span class=\"line\">ax.plot_surface(x_1, y_1, z, alpha=<span class=\"number\">0.3</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x1d050564978&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_33_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>在 SVC 中，我们可以用高斯核函数来实现这以功能：kernel=‘rbf’</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">X, y = make_circles(<span class=\"number\">100</span>, factor=<span class=\"number\">.1</span>, noise=<span class=\"number\">.1</span>, random_state=<span class=\"number\">2019</span>)</span><br><span class=\"line\">plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">50</span>, cmap=plt.cm.Paired)</span><br><span class=\"line\">clf = SVC(kernel=<span class=\"string\">&#x27;rbf&#x27;</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">ax = plt.gca()</span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">x_1, y_1 = np.meshgrid(x, y)</span><br><span class=\"line\">P = np.zeros_like(x_1)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, xi <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(x):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j, yj <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(y):</span><br><span class=\"line\">        P[i, j] = clf.decision_function(np.array([[xi, yj]]))</span><br><span class=\"line\">ax.contour(x_1, y_1, P, colors=<span class=\"string\">&#x27;k&#x27;</span>, levels=[-<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0.9</span>], alpha=<span class=\"number\">0.5</span>,</span><br><span class=\"line\">            linestyles=[<span class=\"string\">&#x27;--&#x27;</span>, <span class=\"string\">&#x27;-&#x27;</span>, <span class=\"string\">&#x27;--&#x27;</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(clf.support_vectors_[:, <span class=\"number\">0</span>], clf.support_vectors_[:, <span class=\"number\">1</span>], edgecolor=<span class=\"string\">&#x27;b&#x27;</span>,</span><br><span class=\"line\">            s=<span class=\"number\">80</span>, facecolors=<span class=\"string\">&#x27;none&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_35_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>此时便完成了非线性分类。</p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/KMeans/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/KMeans/",
            "title": "KMeans",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_blobs</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> KMeans</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#创建数据</span></span><br><span class=\"line\"><span class=\"comment\">#make_blobs 聚类生成器</span></span><br><span class=\"line\">x, y_true = make_blobs(n_samples = <span class=\"number\">1000</span>, <span class=\"comment\">#生成1000条数据</span></span><br><span class=\"line\">                       centers =<span class=\"number\">5</span>, <span class=\"comment\">#5类数据</span></span><br><span class=\"line\">                       cluster_std = <span class=\"number\">0.5</span>, <span class=\"comment\">#方差一致</span></span><br><span class=\"line\">                       random_state = <span class=\"number\">9</span>) <span class=\"comment\">#随机数种子</span></span><br><span class=\"line\"><span class=\"comment\">#x.shape #(300, 2)</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>], x[:,<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">model = KMeans(n_clusters=<span class=\"number\">5</span>)<span class=\"comment\">#n_clusters是k</span></span><br><span class=\"line\">model.fit(x)</span><br><span class=\"line\">y_kmeans = model.predict(x)</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>], x[:,<span class=\"number\">1</span>], c = y_kmeans, cmap=<span class=\"string\">&#x27;Dark2&#x27;</span>, s=<span class=\"number\">50</span>, alpha=<span class=\"number\">0.5</span>, marker=<span class=\"string\">&#x27;o&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">centroids = model.cluster_centers_</span><br><span class=\"line\">plt.scatter(centroids[:,<span class=\"number\">0</span>], centroids[:,<span class=\"number\">1</span>],c=[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>],cmap=<span class=\"string\">&#x27;Dark2&#x27;</span>,s=<span class=\"number\">250</span>, marker=<span class=\"string\">&#x27;*&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;K-means 1000 points&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Value1&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Value2&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_1_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x, y_true = make_blobs(n_samples = <span class=\"number\">1000</span>, <span class=\"comment\">#生成300条数据</span></span><br><span class=\"line\">                       centers = <span class=\"number\">2</span>, <span class=\"comment\">#5类数据</span></span><br><span class=\"line\">                       cluster_std = <span class=\"number\">0.6</span>, <span class=\"comment\">#方差一致</span></span><br><span class=\"line\">                       random_state = <span class=\"number\">8</span>) <span class=\"comment\">#随机数种子</span></span><br><span class=\"line\">x.shape <span class=\"comment\">#(300, 2)</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>], x[:,<span class=\"number\">1</span>],c=y_true,s=<span class=\"number\">10</span>, alpha=<span class=\"number\">0.8</span>)</span><br><span class=\"line\">model = KMeans(n_clusters =<span class=\"number\">2</span>)</span><br><span class=\"line\">model.fit(x)</span><br><span class=\"line\">xmin,xmax=x[:,<span class=\"number\">0</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">0</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\">ymin,ymax=x[:,<span class=\"number\">1</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">1</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\">x1,y1=np.meshgrid(np.arange(xmin,xmax,<span class=\"number\">0.1</span>),np.arange(ymin,ymax,<span class=\"number\">0.02</span>))</span><br><span class=\"line\">z=model.predict(np.c_[x1.ravel(),y1.ravel()])</span><br><span class=\"line\">z=z.reshape(x1.shape)</span><br><span class=\"line\">y_kmeans = model.predict(x)</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.pcolormesh(x1,y1,z,cmap=plt.cm.Pastel1,shading=<span class=\"string\">&#x27;auto&#x27;</span>,)</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>], x[:,<span class=\"number\">1</span>], c = y_kmeans, cmap=<span class=\"string\">&#x27;Dark2&#x27;</span>, s=<span class=\"number\">50</span>, alpha=<span class=\"number\">0.5</span>, marker=<span class=\"string\">&#x27;x&#x27;</span>)</span><br><span class=\"line\">centroids = model.cluster_centers_</span><br><span class=\"line\">plt.scatter(centroids[:,<span class=\"number\">0</span>], centroids[:,<span class=\"number\">1</span>],c=[<span class=\"number\">0</span>,<span class=\"number\">1</span>],cmap=<span class=\"string\">&#x27;Dark2&#x27;</span>,s=<span class=\"number\">70</span>, marker=<span class=\"string\">&#x27;o&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;K-means 1000 points&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Value1&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Value2&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\">n=<span class=\"number\">10</span></span><br><span class=\"line\">dis=np.zeros([n,n])</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">    distances = np.sqrt(np.<span class=\"built_in\">sum</span>(np.asarray(centroids[i,:] - centroids)**<span class=\"number\">2</span>, axis=<span class=\"number\">1</span>))</span><br><span class=\"line\">    dis[i,:]=distances</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_2_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_2_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<pre><code>---------------------------------------------------------------------------\n\nValueError                                Traceback (most recent call last)\n\n&lt;ipython-input-6-73969d6b1829&gt; in &lt;module&gt;\n     27 for i in range(n):\n     28     distances = np.sqrt(np.sum(np.asarray(centroids[i,:] - centroids)**2, axis=1))\n---&gt; 29     dis[i,:]=distances\n\n\nValueError: could not broadcast input array from shape (2) into shape (10)\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/KNN/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/KNN/",
            "title": "KNN",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_blobs <span class=\"comment\">#调用生成数据函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier <span class=\"comment\">#调用KNN分类器函数</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.io <span class=\"keyword\">import</span> loadmat</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data=make_blobs(n_samples=<span class=\"number\">1000</span>,n_features=<span class=\"number\">2</span>,centers=<span class=\"number\">5</span>,random_state=<span class=\"number\">1</span>)<span class=\"comment\">#生成数据</span></span><br><span class=\"line\">x,y=data  <span class=\"comment\">#x获取数据的横轴和纵轴坐标，y获取数据的类别(标签)</span></span><br><span class=\"line\">plt.figure()<span class=\"comment\">#产生一个画布</span></span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],c=y,cmap=plt.cm.spring,edgecolor=<span class=\"string\">&#x27;k&#x27;</span>)<span class=\"comment\">#x[:,0]数据的横轴、x[:,1]数据的纵轴</span></span><br><span class=\"line\">                    <span class=\"comment\">#c:颜色；cm.spring数据点的可视化风格；edgecolor数据点的边界颜色。</span></span><br><span class=\"line\">model=KNeighborsClassifier()<span class=\"comment\">#生成一个初始化的knn分类器模型</span></span><br><span class=\"line\">model.fit(x,y)<span class=\"comment\">#对初始化的knn分类器进行训练（用现有的训练样本进行训练）</span></span><br><span class=\"line\"></span><br><span class=\"line\">xmin,xmax=x[:,<span class=\"number\">0</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">0</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span><span class=\"comment\">#获取训练样本横轴坐标的最小值和最大值</span></span><br><span class=\"line\">ymin,ymax=x[:,<span class=\"number\">1</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">1</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span><span class=\"comment\">#获取训练样本纵轴坐标的最小值和最大值</span></span><br><span class=\"line\">x1,y1=np.meshgrid(np.arange(xmin,xmax,<span class=\"number\">0.02</span>),np.arange(ymin,ymax,<span class=\"number\">0.02</span>))</span><br><span class=\"line\"><span class=\"comment\">#对整个训练样本数据的分布空间进行网格化</span></span><br><span class=\"line\">z=model.predict(np.c_[x1.ravel(),y1.ravel()])<span class=\"comment\">#对空间数据进行分类</span></span><br><span class=\"line\">z=z.reshape(x1.shape)<span class=\"comment\">#对分类后的数据进行变形（从一维变到二维）</span></span><br><span class=\"line\">plt.figure()<span class=\"comment\">#产生一个画布</span></span><br><span class=\"line\">plt.pcolormesh(x1,y1,z,cmap=plt.cm.Pastel1)</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],c=y,cmap=plt.cm.spring,edgecolor=<span class=\"string\">&#x27;k&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n  app.launch_new_instance()\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mnist=loadmat(<span class=\"string\">&#x27;mnist-original.mat&#x27;</span>)</span><br><span class=\"line\">x,y=mnist[<span class=\"string\">&quot;data&quot;</span>],mnist[<span class=\"string\">&quot;label&quot;</span>]</span><br><span class=\"line\">x=x.T</span><br><span class=\"line\">y=y[<span class=\"number\">0</span>]</span><br><span class=\"line\">some_digit=x[<span class=\"number\">69000</span>]</span><br><span class=\"line\">x_train=x[:<span class=\"number\">60000</span>]</span><br><span class=\"line\">y_train=y[:<span class=\"number\">60000</span>]</span><br><span class=\"line\">model=KNeighborsClassifier()</span><br><span class=\"line\">model.fit(x_train,y_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.predict([some_digit]))</span><br></pre></td></tr></table></figure>\n<pre><code>[9.]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/SVM/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/SVM/",
            "title": "SVM",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"> </span><br><span class=\"line\">xs=np.arange(-<span class=\"number\">5</span>,<span class=\"number\">5</span>,<span class=\"number\">0.2</span>)</span><br><span class=\"line\">ys1=np.sqrt(<span class=\"number\">25</span>-xs*xs)+np.random.uniform(-<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>,(xs.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">ys2=-<span class=\"number\">1</span>*np.sqrt(<span class=\"number\">25</span>-xs*xs)+np.random.uniform(-<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>,(xs.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">xys1=np.c_[xs,ys1]</span><br><span class=\"line\"></span><br><span class=\"line\">xys2=np.c_[xs,ys2]</span><br><span class=\"line\"></span><br><span class=\"line\">xy1=np.r_[xys1,xys2]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">xh=np.arange(-<span class=\"number\">8</span>,<span class=\"number\">8</span>,<span class=\"number\">0.2</span>)</span><br><span class=\"line\">yh1=np.sqrt(<span class=\"number\">64</span>-xh*xh)+np.random.uniform(-<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>,(xh.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">yh2=-<span class=\"number\">1</span>*np.sqrt(<span class=\"number\">64</span>-xh*xh)+np.random.uniform(-<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>,(xh.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">xyh1=np.c_[xh,yh1]</span><br><span class=\"line\"></span><br><span class=\"line\">xyh2=np.c_[xh,yh2]</span><br><span class=\"line\"></span><br><span class=\"line\">xy2=np.r_[xyh1,xyh2]</span><br><span class=\"line\"></span><br><span class=\"line\">xy3=np.r_[xy1,xy2]</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(xy3[<span class=\"number\">0</span>:<span class=\"number\">100</span>,<span class=\"number\">0</span>],xy3[<span class=\"number\">0</span>:<span class=\"number\">100</span>,<span class=\"number\">1</span>],c=<span class=\"string\">&#x27;k&#x27;</span>,marker=<span class=\"string\">&#x27;*&#x27;</span>)</span><br><span class=\"line\">plt.scatter(xy3[<span class=\"number\">100</span>:,<span class=\"number\">0</span>],xy3[<span class=\"number\">100</span>:,<span class=\"number\">1</span>],c=<span class=\"string\">&#x27;r&#x27;</span>,marker=<span class=\"string\">&#x27;o&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fig=plt.figure()</span><br><span class=\"line\">ax=Axes3D(fig)</span><br><span class=\"line\"></span><br><span class=\"line\">z1=xy3[:,<span class=\"number\">0</span>]**<span class=\"number\">2</span></span><br><span class=\"line\">z2=xy3[:,<span class=\"number\">1</span>]**<span class=\"number\">2</span></span><br><span class=\"line\">z3=xy3[:,<span class=\"number\">1</span>]</span><br><span class=\"line\">ax.scatter(z1[<span class=\"number\">0</span>:<span class=\"number\">100</span>],z2[<span class=\"number\">0</span>:<span class=\"number\">100</span>],z3[<span class=\"number\">0</span>:<span class=\"number\">100</span>],c=<span class=\"string\">&#x27;k&#x27;</span>,marker=<span class=\"string\">&#x27;*&#x27;</span>)</span><br><span class=\"line\">ax.scatter(z1[<span class=\"number\">100</span>:],z2[<span class=\"number\">100</span>:],z3[<span class=\"number\">100</span>:],c=<span class=\"string\">&#x27;r&#x27;</span>,marker=<span class=\"string\">&#x27;o&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:34: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_0_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_0_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> cross_val_score <span class=\"keyword\">as</span> cr<span class=\"comment\">#调用交叉检验函数</span></span><br><span class=\"line\">n_samples = <span class=\"number\">600</span></span><br><span class=\"line\">x,y=make_moons(n_samples=n_samples, noise=<span class=\"number\">0.1</span>,random_state=<span class=\"number\">3</span>)</span><br><span class=\"line\">clf=svm.SVC(kernel=<span class=\"string\">&#x27;rbf&#x27;</span>,gamma=<span class=\"number\">0.5</span>,C=<span class=\"number\">100</span>)<span class=\"comment\">#poly代表分类线是曲线，degree是曲线的最高次幂</span></span><br><span class=\"line\">clf.fit(x,y)</span><br><span class=\"line\"><span class=\"comment\">#clf.predict([x])</span></span><br><span class=\"line\">xmin,xmax=x[:,<span class=\"number\">0</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">0</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\">ymin,ymax=x[:,<span class=\"number\">1</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">1</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">xx,yy=np.meshgrid(np.arange(xmin,xmax,<span class=\"number\">0.02</span>),np.arange(ymin,ymax,<span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">xf=np.c_[xx.ravel(),yy.ravel()];</span><br><span class=\"line\">z=clf.predict(xf)</span><br><span class=\"line\">z=z.reshape(xx.shape)</span><br><span class=\"line\">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],c=y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(cr(clf,x,y,cv=<span class=\"number\">5</span>,scoring=<span class=\"string\">&quot;accuracy&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>[1.         0.99166667 1.         1.         1.        ]\n\n\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:20: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/",
            "title": "主成分分析",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h3 id=\"对数据降维后使用knn算法进行分类的案例\"><a class=\"markdownIt-Anchor\" href=\"#对数据降维后使用knn算法进行分类的案例\">#</a> 对数据降维后使用 KNN 算法进行分类的案例</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy.io <span class=\"keyword\">import</span> loadmat</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\">mnist=loadmat(<span class=\"string\">&#x27;mnist-original.mat&#x27;</span>)<span class=\"comment\">#获取原始数据</span></span><br><span class=\"line\">x,y=mnist[<span class=\"string\">&quot;data&quot;</span>],mnist[<span class=\"string\">&quot;label&quot;</span>]<span class=\"comment\">#分别获取原始数据的数据描述和数据标签</span></span><br><span class=\"line\">x=x.T<span class=\"comment\">#对原始数据描述进行转转置</span></span><br><span class=\"line\">y=y[<span class=\"number\">0</span>]</span><br><span class=\"line\">pca=PCA()<span class=\"comment\">#建立PCA模型</span></span><br><span class=\"line\">pca.fit(x)<span class=\"comment\">#通过PCA（主成分分析）对原始数据进行主成分分析,得到特征值和特征向量</span></span><br><span class=\"line\">cumsum=np.cumsum(pca.explained_variance_ratio_)<span class=\"comment\">#对特征值进行排序（从大到小进行排序），计算特征值的累计贡献率</span></span><br><span class=\"line\">d=np.argmax(cumsum&gt;=<span class=\"number\">0.95</span>)+<span class=\"number\">1</span> <span class=\"comment\">#设定一个累计贡献率的阈值，阈值为0.95，d是累计贡献率达到0.95的特征值的数量，d=154</span></span><br><span class=\"line\">pca=PCA(n_components=d)<span class=\"comment\">#对原始数据进行降维，从784维降到154维</span></span><br><span class=\"line\">x1=pca.fit_transform(x)<span class=\"comment\">#x1是降维之后的数据</span></span><br><span class=\"line\">x_train=x1[:<span class=\"number\">60000</span>]<span class=\"comment\">#选择训练数据，原始数据有70000条，我们选择前60000作为训练样本，x_train代表前60000个样本的数据描述</span></span><br><span class=\"line\">y_train=y[:<span class=\"number\">60000</span>]<span class=\"comment\">#前60000个样本的标签</span></span><br><span class=\"line\">shuffle_index=np.random.permutation(<span class=\"number\">60000</span>)<span class=\"comment\">#对前60000个数据打乱顺序</span></span><br><span class=\"line\">x_train=x_train[shuffle_index]</span><br><span class=\"line\">y_train=y_train[shuffle_index]</span><br><span class=\"line\">sgd_clf=KNeighborsClassifier()<span class=\"comment\">#调用KNN分类器</span></span><br><span class=\"line\">sgd_clf.fit(x_train,y_train)<span class=\"comment\">#建立KNN分类器模型</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(d)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;clf.pickle&#x27;</span>, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(sgd_clf, f)</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>154\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy.io <span class=\"keyword\">import</span> loadmat</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"></span><br><span class=\"line\">mnist=loadmat(<span class=\"string\">&#x27;mnist-original.mat&#x27;</span>)</span><br><span class=\"line\">x,y=mnist[<span class=\"string\">&quot;data&quot;</span>],mnist[<span class=\"string\">&quot;label&quot;</span>]</span><br><span class=\"line\">x=x.T</span><br><span class=\"line\">y=y[<span class=\"number\">0</span>]</span><br><span class=\"line\">pca=PCA(n_components=<span class=\"number\">154</span>)</span><br><span class=\"line\">x1=pca.fit_transform(x)</span><br><span class=\"line\">some_digit=x1[<span class=\"number\">66000</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">x_test=x[<span class=\"number\">60000</span>:]</span><br><span class=\"line\">y_test=y[<span class=\"number\">60000</span>:]</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;clf.pickle&#x27;</span>, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    clf2 = pickle.load(f)</span><br><span class=\"line\">y_pred = clf2.predict(x1[<span class=\"number\">60000</span>:])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(accuracy_score(y[<span class=\"number\">60000</span>:], y_pred))</span><br></pre></td></tr></table></figure>\n<pre><code>0.9719\n</code></pre>\n<h3 id=\"lle\"><a class=\"markdownIt-Anchor\" href=\"#lle\">#</a> LLE</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> LocallyLinearEmbedding</span><br><span class=\"line\"></span><br><span class=\"line\">N=<span class=\"number\">2000</span></span><br><span class=\"line\">angle=np.pi*(<span class=\"number\">1.5</span>*np.random.random(<span class=\"built_in\">int</span>(N/<span class=\"number\">2</span>))-<span class=\"number\">1</span>)</span><br><span class=\"line\">height=<span class=\"number\">5</span>*np.random.random(N)</span><br><span class=\"line\">x=np.array([np.append(np.cos(angle),-<span class=\"number\">1</span>*np.cos(angle)),height,np.append(np.sin(angle),<span class=\"number\">2</span>-np.sin(angle))])</span><br><span class=\"line\">x=x.T</span><br><span class=\"line\">fig=plt.figure()</span><br><span class=\"line\">ax=Axes3D(fig)</span><br><span class=\"line\">ax.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],x[:,<span class=\"number\">2</span>])</span><br><span class=\"line\">lle=LocallyLinearEmbedding(n_components=<span class=\"number\">2</span>,n_neighbors=<span class=\"number\">12</span>)<span class=\"comment\">#n_neighbors不能太小，也不能太大</span></span><br><span class=\"line\"><span class=\"comment\">#如果太小结果不理想，如果太大，则效果接近于PCA（主成分分析），原论文推荐是12</span></span><br><span class=\"line\">x2d=lle.fit_transform(x)</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(x2d[:,<span class=\"number\">0</span>],x2d[:,<span class=\"number\">1</span>],<span class=\"string\">&#x27;k.&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n  if sys.path[0] == '':\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_4_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_4_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E5%86%B3%E7%AD%96%E6%A0%91/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E5%86%B3%E7%AD%96%E6%A0%91/",
            "title": "决策树",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.io <span class=\"keyword\">import</span> loadmat</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"></span><br><span class=\"line\">mnist=loadmat(<span class=\"string\">&#x27;mnist-original.mat&#x27;</span>)</span><br><span class=\"line\">x,y=mnist[<span class=\"string\">&quot;data&quot;</span>],mnist[<span class=\"string\">&quot;label&quot;</span>]</span><br><span class=\"line\">x=x.T</span><br><span class=\"line\">y=y[<span class=\"number\">0</span>]</span><br><span class=\"line\">some_digit=x[<span class=\"number\">68888</span>]</span><br><span class=\"line\">x_train=x[:<span class=\"number\">60000</span>]</span><br><span class=\"line\">y_train=y[:<span class=\"number\">60000</span>]</span><br><span class=\"line\">model=DecisionTreeClassifier(max_depth=<span class=\"number\">10</span>)</span><br><span class=\"line\">model.fit(x_train,y_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.predict([some_digit]))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>[8.]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> cross_val_score <span class=\"keyword\">as</span> cr<span class=\"comment\">#调用交叉检验函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\">n_samples = <span class=\"number\">600</span></span><br><span class=\"line\">x,y=make_moons(n_samples=n_samples, noise=<span class=\"number\">.1</span>,random_state=<span class=\"number\">8</span>)</span><br><span class=\"line\">model=DecisionTreeClassifier(criterion=<span class=\"string\">&#x27;gini&#x27;</span>,max_depth=<span class=\"number\">15</span>)</span><br><span class=\"line\">model.fit(x,y)</span><br><span class=\"line\"><span class=\"comment\">#clf.predict([x])</span></span><br><span class=\"line\">xmin,xmax=x[:,<span class=\"number\">0</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">0</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\">ymin,ymax=x[:,<span class=\"number\">1</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">1</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">xx,yy=np.meshgrid(np.arange(xmin,xmax,<span class=\"number\">0.02</span>),np.arange(ymin,ymax,<span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">xf=np.c_[xx.ravel(),yy.ravel()];</span><br><span class=\"line\">z=model.predict(xf)</span><br><span class=\"line\">z=z.reshape(xx.shape)</span><br><span class=\"line\">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],c=y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(cr(model,x,y,cv=<span class=\"number\">5</span>,scoring=<span class=\"string\">&quot;accuracy&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>[0.99166667 1.         0.98333333 0.98333333 0.98333333]\n\n\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> export_graphviz</span><br><span class=\"line\"></span><br><span class=\"line\">iris = load_iris()</span><br><span class=\"line\">X = iris.data[:, <span class=\"number\">2</span>:] <span class=\"comment\"># petal length and width</span></span><br><span class=\"line\">y = iris.target</span><br><span class=\"line\">tree_clf = DecisionTreeClassifier(max_depth=<span class=\"number\">3</span>)</span><br><span class=\"line\">tree_clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\">export_graphviz(</span><br><span class=\"line\">  tree_clf,</span><br><span class=\"line\">  out_file=<span class=\"string\">&quot;tree.dot&quot;</span>,</span><br><span class=\"line\">  feature_names=iris.feature_names[<span class=\"number\">2</span>:],</span><br><span class=\"line\">  class_names=iris.target_names,</span><br><span class=\"line\">  rounded=<span class=\"literal\">True</span>,</span><br><span class=\"line\">  filled=<span class=\"literal\">True</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E6%8B%9F%E5%90%88/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E6%8B%9F%E5%90%88/",
            "title": "拟合",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy.linalg <span class=\"keyword\">as</span> lg</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures <span class=\"keyword\">as</span> pl</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">20</span>,<span class=\"number\">20</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y=<span class=\"number\">2</span>*x+<span class=\"number\">0.2</span>*x**<span class=\"number\">2</span>+<span class=\"number\">1</span>+np.random.uniform(-<span class=\"number\">5</span>,<span class=\"number\">5</span>,x.shape)</span><br><span class=\"line\">plt.figure</span><br><span class=\"line\">plt.plot(x,y,<span class=\"string\">&#x27;k*&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">A=np.c_[x**<span class=\"number\">2</span>,x,np.ones(x.shape)]</span><br><span class=\"line\">B=y.reshape(y.shape[<span class=\"number\">0</span>],<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">eta=<span class=\"number\">0.00001</span></span><br><span class=\"line\">n=<span class=\"number\">10000</span></span><br><span class=\"line\">m=x.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">arf=np.random.randn(<span class=\"number\">3</span>,<span class=\"number\">1</span>)*<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">    gradients=<span class=\"number\">2</span>/m*A.T.dot(A.dot(arf)-B)</span><br><span class=\"line\">    arf=arf-eta*gradients</span><br><span class=\"line\"></span><br><span class=\"line\">w=lg.inv(A.T.dot(A)).dot(A.T).dot(y)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(x,x**<span class=\"number\">2</span>*arf[<span class=\"number\">0</span>]+x*arf[<span class=\"number\">1</span>]+arf[<span class=\"number\">2</span>])</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_1_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">t=np.arange(<span class=\"number\">1</span>,<span class=\"number\">17</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">y=np.array([<span class=\"number\">4</span>,<span class=\"number\">6.4</span>,<span class=\"number\">8</span>,<span class=\"number\">8.8</span>,<span class=\"number\">9.22</span>,<span class=\"number\">9.5</span>,<span class=\"number\">9.7</span>,<span class=\"number\">9.86</span>,<span class=\"number\">10</span>,<span class=\"number\">10.20</span>,<span class=\"number\">10.32</span>,<span class=\"number\">10.42</span>,<span class=\"number\">10.5</span>,<span class=\"number\">10.55</span>,<span class=\"number\">10.58</span>,<span class=\"number\">10.6</span></span><br><span class=\"line\">])</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(t,y,<span class=\"string\">&#x27;k*&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># y=at^2+bt+c</span></span><br><span class=\"line\"></span><br><span class=\"line\">A=np.c_[t**<span class=\"number\">2</span>,t,np.ones(t.shape)]</span><br><span class=\"line\"></span><br><span class=\"line\">w=lg.inv(A.T.dot(A)).dot(A.T).dot(y)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(t,w[<span class=\"number\">0</span>]*t**<span class=\"number\">2</span>+w[<span class=\"number\">1</span>]*t+w[<span class=\"number\">2</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_2_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">t=np.arange(<span class=\"number\">1</span>,<span class=\"number\">17</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">t=t.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">y=np.array([<span class=\"number\">4</span>,<span class=\"number\">6.4</span>,<span class=\"number\">8</span>,<span class=\"number\">8.8</span>,<span class=\"number\">9.22</span>,<span class=\"number\">9.5</span>,<span class=\"number\">9.7</span>,<span class=\"number\">9.86</span>,<span class=\"number\">10</span>,<span class=\"number\">10.20</span>,<span class=\"number\">10.32</span>,<span class=\"number\">10.42</span>,<span class=\"number\">10.5</span>,<span class=\"number\">10.55</span>,<span class=\"number\">10.58</span>,<span class=\"number\">10.6</span></span><br><span class=\"line\">])</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(t,y,<span class=\"string\">&#x27;k*&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># y=at^2+bt+c</span></span><br><span class=\"line\"></span><br><span class=\"line\">lin_reg=LinearRegression()</span><br><span class=\"line\">lin_reg.fit(t,y)</span><br><span class=\"line\">plt.plot(t,lin_reg.predict(t).reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>))</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_3_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">t=np.arange(<span class=\"number\">1</span>,<span class=\"number\">17</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">t=t.reshape(-<span class=\"number\">1</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">y=np.array([<span class=\"number\">4</span>,<span class=\"number\">6.4</span>,<span class=\"number\">8</span>,<span class=\"number\">8.8</span>,<span class=\"number\">9.22</span>,<span class=\"number\">9.5</span>,<span class=\"number\">9.7</span>,<span class=\"number\">9.86</span>,<span class=\"number\">10</span>,<span class=\"number\">10.20</span>,<span class=\"number\">10.32</span>,<span class=\"number\">10.42</span>,<span class=\"number\">10.5</span>,<span class=\"number\">10.55</span>,<span class=\"number\">10.58</span>,<span class=\"number\">10.6</span>])</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(t,y,<span class=\"string\">&#x27;k*&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># y=at^2+bt+c</span></span><br><span class=\"line\"></span><br><span class=\"line\">poly_features=pl(degree=<span class=\"number\">2</span>,include_bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">x_poly=poly_features.fit_transform(t)</span><br><span class=\"line\">lin_reg=LinearRegression()</span><br><span class=\"line\">lin_reg.fit(x_poly,y)</span><br><span class=\"line\">plt.plot(t,lin_reg.coef_[<span class=\"number\">1</span>]*t**<span class=\"number\">2</span>+lin_reg.coef_[<span class=\"number\">0</span>]*t+lin_reg.intercept_)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_4_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/",
            "title": "朴素贝叶斯",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy.io <span class=\"keyword\">import</span> loadmat</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> BernoulliNB <span class=\"comment\">#伯努利分布,适用于离散型数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> GaussianNB <span class=\"comment\">#高斯分布，适用于连续型数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB <span class=\"comment\">#多项式分布</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\">mnist=loadmat(<span class=\"string\">&#x27;mnist-original.mat&#x27;</span>)</span><br><span class=\"line\">x,y=mnist[<span class=\"string\">&quot;data&quot;</span>],mnist[<span class=\"string\">&quot;label&quot;</span>]</span><br><span class=\"line\">x=x.T</span><br><span class=\"line\">y=y[<span class=\"number\">0</span>]</span><br><span class=\"line\">x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=<span class=\"number\">5</span>)</span><br><span class=\"line\">nb=BernoulliNB()</span><br><span class=\"line\">nb.fit(x_train,y_train)</span><br><span class=\"line\">a=nb.score(x_test,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>0.828\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> BernoulliNB <span class=\"comment\">#伯努利分布,适用于离散型数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> GaussianNB <span class=\"comment\">#高斯分布，适用于连续型数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB <span class=\"comment\">#多项式分布，</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_blobs</span><br><span class=\"line\"></span><br><span class=\"line\">x, y= make_blobs(n_samples = <span class=\"number\">1000</span>, <span class=\"comment\">#生成300条数据</span></span><br><span class=\"line\">                       centers =<span class=\"number\">5</span>, <span class=\"comment\">#5类数据</span></span><br><span class=\"line\">                       cluster_std = <span class=\"number\">0.7</span>, <span class=\"comment\">#方差一致</span></span><br><span class=\"line\">                       random_state = <span class=\"number\">8</span>) <span class=\"comment\">#随机数种子</span></span><br><span class=\"line\">nb=GaussianNB()</span><br><span class=\"line\">nb.fit(x,y)</span><br><span class=\"line\">z=nb.predict(x)</span><br><span class=\"line\">a=nb.score(x,y)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>], x[:,<span class=\"number\">1</span>],c=y)</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>], x[:,<span class=\"number\">1</span>],c=z)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>0.982\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> BernoulliNB <span class=\"comment\">#伯努利分布,适用于离散型数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> GaussianNB <span class=\"comment\">#高斯分布，适用于连续型数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB <span class=\"comment\">#多项式分布</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> cross_val_score <span class=\"keyword\">as</span> cr<span class=\"comment\">#调用交叉检验函数</span></span><br><span class=\"line\">n_samples = <span class=\"number\">600</span></span><br><span class=\"line\">x,y=make_moons(n_samples=n_samples, noise=<span class=\"number\">0.1</span>,random_state=<span class=\"number\">8</span>)</span><br><span class=\"line\">x=x+<span class=\"number\">2</span>;</span><br><span class=\"line\"><span class=\"comment\">#clf= MultinomialNB()</span></span><br><span class=\"line\">clf= GaussianNB()</span><br><span class=\"line\">clf.fit(x,y)</span><br><span class=\"line\"><span class=\"comment\">#clf.predict([x])</span></span><br><span class=\"line\">xmin,xmax=x[:,<span class=\"number\">0</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">0</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\">ymin,ymax=x[:,<span class=\"number\">1</span>].<span class=\"built_in\">min</span>()-<span class=\"number\">1</span>,x[:,<span class=\"number\">1</span>].<span class=\"built_in\">max</span>()+<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">xx,yy=np.meshgrid(np.arange(xmin,xmax,<span class=\"number\">0.02</span>),np.arange(ymin,ymax,<span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">xf=np.c_[xx.ravel(),yy.ravel()];</span><br><span class=\"line\">z=clf.predict(xf)</span><br><span class=\"line\">z=z.reshape(xx.shape)</span><br><span class=\"line\">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],c=y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(cr(clf,x,y,cv=<span class=\"number\">5</span>,scoring=<span class=\"string\">&quot;accuracy&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>[0.9        0.88333333 0.9        0.85833333 0.86666667]\n\n\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:25: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_2_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/",
            "title": "线性规划",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy <span class=\"keyword\">import</span> optimize <span class=\"keyword\">as</span> op</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211208163638086.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211208163638086\"></p>\n<p>scipy.optimize.linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None, method=‘simplex’, callback=None, options=None)</p>\n<p>很容易发现，c 指的应该是要求最大值的函数的系数数组，A_ub 是应该是不等式未知量的系数矩阵，仔细观察的人应该发现，为什么第一行里面写的是 [-2,5,-1] 而不是 [2,5,-1] 呢，应该要与图里对应才对啊，原来这不等式指的是 &lt;= 的不等式，那如果是 &gt;= 呢，乘个负号就行了。A_eq 就是其中等式的未知量系数矩阵了。B_ub 就是不等式的右边了，B_eq 就是等式右边了。bounds 的话，指的就是每个未知量的范围了</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#目标函数，求最大值</span></span><br><span class=\"line\">c=np.array([<span class=\"number\">2</span>,<span class=\"number\">3</span>,-<span class=\"number\">5</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#unbalence不等式，默认&lt;=，&gt;=乘-1</span></span><br><span class=\"line\"><span class=\"comment\">#不等式左系数矩阵</span></span><br><span class=\"line\">A_ub=np.array([[-<span class=\"number\">2</span>,<span class=\"number\">5</span>,-<span class=\"number\">1</span>],[<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">1</span>]])</span><br><span class=\"line\"><span class=\"comment\">#不等式右系数矩阵</span></span><br><span class=\"line\">B_ub=np.array([-<span class=\"number\">10</span>,<span class=\"number\">12</span>])</span><br><span class=\"line\"><span class=\"comment\">#equation等式，A_eq为左系数矩阵，B_eq为右系数矩阵</span></span><br><span class=\"line\">A_eq=np.array([[<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>]])<span class=\"comment\">#注意双括号</span></span><br><span class=\"line\">B_eq=np.array([<span class=\"number\">7</span>])</span><br><span class=\"line\"><span class=\"comment\">#x1,x2,x3大于等于0</span></span><br><span class=\"line\">x1=(<span class=\"number\">0</span>,<span class=\"literal\">None</span>)</span><br><span class=\"line\">x2=(<span class=\"number\">0</span>,<span class=\"literal\">None</span>)</span><br><span class=\"line\">x3=(<span class=\"number\">0</span>,<span class=\"literal\">None</span>)</span><br><span class=\"line\"><span class=\"comment\">#函数默认求最小值，-c，结果为负号</span></span><br><span class=\"line\">res=op.linprog(-c,A_ub,B_ub,A_eq,B_eq,bounds=(x1,x2,x3))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>     con: array([1.80713489e-09])\n     fun: -14.571428565645059\n message: 'Optimization terminated successfully.'\n     nit: 5\n   slack: array([-2.24614993e-10,  3.85714286e+00])\n  status: 0\n success: True\n       x: array([6.42857143e+00, 5.71428571e-01, 2.35900788e-10])\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = [<span class=\"number\">6.42857143e+00</span>, <span class=\"number\">5.71428571e-01</span>, <span class=\"number\">2.35900788e-10</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"number\">2</span>*x[<span class=\"number\">0</span>] + <span class=\"number\">3</span>*x[<span class=\"number\">1</span>] -<span class=\"number\">5</span>*x[<span class=\"number\">2</span>])</span><br></pre></td></tr></table></figure>\n<pre><code>14.571428571820496\n</code></pre>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/",
            "title": "随机森林",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#begging</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> BaggingClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"></span><br><span class=\"line\">n_samples = <span class=\"number\">2000</span></span><br><span class=\"line\">X_train, y_train=make_moons(n_samples=n_samples, noise=<span class=\"number\">.3</span>,random_state=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=<span class=\"number\">500</span>,max_samples=<span class=\"number\">100</span>, bootstrap=<span class=\"literal\">True</span>, n_jobs=-<span class=\"number\">1</span>)</span><br><span class=\"line\">bag_clf.fit(X_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>], y_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>])</span><br><span class=\"line\">y_pred = bag_clf.predict(X_train[<span class=\"number\">1500</span>:])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(accuracy_score(y_train[<span class=\"number\">1500</span>:], y_pred))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure();</span><br><span class=\"line\">plt.scatter(X_train[:,<span class=\"number\">0</span>],X_train[:,<span class=\"number\">1</span>],c=y_train)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>0.9\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_0_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#RandomForest</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"></span><br><span class=\"line\">n_samples = <span class=\"number\">2000</span></span><br><span class=\"line\">X_train, y_train=make_moons(n_samples=n_samples, noise=<span class=\"number\">.3</span>,random_state=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ada_clf = RandomForestClassifier(n_estimators=<span class=\"number\">500</span>,max_leaf_nodes=<span class=\"number\">16</span>,n_jobs=-<span class=\"number\">1</span>)</span><br><span class=\"line\">ada_clf.fit(X_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>], y_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>])</span><br><span class=\"line\">y_pred = ada_clf.predict(X_train[<span class=\"number\">1500</span>:])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(accuracy_score(y_train[<span class=\"number\">1500</span>:], y_pred))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure();</span><br><span class=\"line\">plt.scatter(X_train[:,<span class=\"number\">0</span>],X_train[:,<span class=\"number\">1</span>],c=y_train)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>0.904\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_1_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Boost</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> AdaBoostClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"></span><br><span class=\"line\">n_samples = <span class=\"number\">2000</span></span><br><span class=\"line\">X_train, y_train=make_moons(n_samples=n_samples, noise=<span class=\"number\">.3</span>,random_state=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ada_clf = AdaBoostClassifier(</span><br><span class=\"line\">DecisionTreeClassifier(max_depth=<span class=\"number\">1</span>), n_estimators=<span class=\"number\">500</span>,</span><br><span class=\"line\">algorithm=<span class=\"string\">&quot;SAMME.R&quot;</span>, learning_rate=<span class=\"number\">0.5</span></span><br><span class=\"line\">)</span><br><span class=\"line\">ada_clf.fit(X_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>], y_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>])</span><br><span class=\"line\">y_pred = ada_clf.predict(X_train[<span class=\"number\">1500</span>:])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(accuracy_score(y_train[<span class=\"number\">1500</span>:], y_pred))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure();</span><br><span class=\"line\">plt.scatter(X_train[:,<span class=\"number\">0</span>],X_train[:,<span class=\"number\">1</span>],c=y_train)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>0.892\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_2_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Stacking</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> model_selection</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> GaussianNB</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> mlxtend.classifier <span class=\"keyword\">import</span> StackingClassifier</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">X, y = iris.data[:, <span class=\"number\">1</span>:<span class=\"number\">3</span>], iris.target</span><br><span class=\"line\"></span><br><span class=\"line\">clf1 = KNeighborsClassifier(n_neighbors=<span class=\"number\">1</span>)</span><br><span class=\"line\">clf2 = RandomForestClassifier(random_state=<span class=\"number\">1</span>)</span><br><span class=\"line\">clf3 = GaussianNB()</span><br><span class=\"line\">lr = LogisticRegression()</span><br><span class=\"line\">sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;3-fold cross validation:\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> clf, label <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(</span><br><span class=\"line\">    [clf1, clf2, clf3, sclf],</span><br><span class=\"line\">    [<span class=\"string\">&#x27;KNN&#x27;</span>, <span class=\"string\">&#x27;Random Forest&#x27;</span>, <span class=\"string\">&#x27;Naive Bayes&#x27;</span>, <span class=\"string\">&#x27;StackingClassifier&#x27;</span>]):</span><br><span class=\"line\"></span><br><span class=\"line\">    scores = model_selection.cross_val_score(clf, X, y, cv=<span class=\"number\">3</span>, scoring=<span class=\"string\">&#x27;accuracy&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot;</span> % (scores.mean(), scores.std(), label))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>---------------------------------------------------------------------------\n\nModuleNotFoundError                       Traceback (most recent call last)\n\n&lt;ipython-input-4-483486e68139&gt; in &lt;module&gt;\n      6 from sklearn.naive_bayes import GaussianNB\n      7 from sklearn.ensemble import RandomForestClassifier\n----&gt; 8 from mlxtend.classifier import StackingClassifier\n      9 import numpy as np\n     10 \n\n\nModuleNotFoundError: No module named 'mlxtend'\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">!pip install mlxtend</span><br></pre></td></tr></table></figure>\n<pre><code>Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n\n\nERROR: Could not find a version that satisfies the requirement mlxtend (from versions: none)\nERROR: No matching distribution found for mlxtend\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Voting</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons<span class=\"comment\">#生成月牙形数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score<span class=\"comment\">#分类器的准确率</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt<span class=\"comment\">#画图</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> VotingClassifier<span class=\"comment\">#调用集成学习的投票分类器</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression<span class=\"comment\">#调用逻辑回归分类器</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC<span class=\"comment\">#调用支持向量机分类器</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier<span class=\"comment\">#调用KNN分类器</span></span><br><span class=\"line\"></span><br><span class=\"line\">n_samples = <span class=\"number\">2000</span></span><br><span class=\"line\">X_train, y_train=make_moons(n_samples=n_samples, noise=<span class=\"number\">.3</span>,random_state=<span class=\"number\">8</span>)</span><br><span class=\"line\"><span class=\"comment\">#shuffle_index=np.random.permutation(2000)</span></span><br><span class=\"line\"></span><br><span class=\"line\">log_clf = LogisticRegression()</span><br><span class=\"line\">svm_clf = SVC()</span><br><span class=\"line\">knn_clf=KNeighborsClassifier()</span><br><span class=\"line\"></span><br><span class=\"line\">voting_clf = VotingClassifier(</span><br><span class=\"line\">estimators=[(<span class=\"string\">&#x27;lr&#x27;</span>, log_clf),(<span class=\"string\">&#x27;svc&#x27;</span>, svm_clf),(<span class=\"string\">&#x27;knn&#x27;</span>,knn_clf)],</span><br><span class=\"line\">voting=<span class=\"string\">&#x27;hard&#x27;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\">#voting_clf.fit(X_train[0:1500], y_train[0:1500])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> clf <span class=\"keyword\">in</span> (log_clf,svm_clf,knn_clf,voting_clf):</span><br><span class=\"line\">    clf.fit(X_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>], y_train[<span class=\"number\">0</span>:<span class=\"number\">1500</span>])</span><br><span class=\"line\">    y_pred = clf.predict(X_train[<span class=\"number\">1500</span>:])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(clf.__class__.__name__, accuracy_score(y_train[<span class=\"number\">1500</span>:], y_pred))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure();</span><br><span class=\"line\">plt.scatter(X_train[:,<span class=\"number\">0</span>],X_train[:,<span class=\"number\">1</span>],c=y_train)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>LogisticRegression 0.862\nSVC 0.906\nKNeighborsClassifier 0.902\nVotingClassifier 0.91\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_5_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/",
            "title": "非线性规划",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<p><img \"\" class=\"lazyload placeholder\" data-original=\"image-20211208163755018.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"image-20211208163755018\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">minimize</span>(<span class=\"params\">fun: <span class=\"type\">Callable</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             x0: ndarray,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             args: <span class=\"type\">Union</span>[Iterable, <span class=\"built_in\">tuple</span>, <span class=\"literal\">None</span>] = (<span class=\"params\"></span>),</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             method: <span class=\"type\">Union</span>[<span class=\"built_in\">str</span>, <span class=\"type\">Callable</span>, <span class=\"literal\">None</span>] = <span class=\"literal\">None</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             jac: <span class=\"type\">Union</span>[<span class=\"type\">Callable</span>, <span class=\"built_in\">str</span>, <span class=\"built_in\">bool</span>, <span class=\"literal\">None</span>] = <span class=\"literal\">None</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             hess: <span class=\"built_in\">str</span> = <span class=\"literal\">None</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             hessp: <span class=\"type\">Optional</span>[<span class=\"type\">Callable</span>] = <span class=\"literal\">None</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             bounds: <span class=\"type\">Union</span>[Iterable, Bounds, <span class=\"literal\">None</span>] = <span class=\"literal\">None</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             constraints: <span class=\"type\">Optional</span>[<span class=\"built_in\">dict</span>] = (<span class=\"params\"></span>),</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             tol: <span class=\"type\">Optional</span>[<span class=\"built_in\">float</span>] = <span class=\"literal\">None</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             callback: <span class=\"type\">Optional</span>[<span class=\"type\">Callable</span>] = <span class=\"literal\">None</span>,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">             options: <span class=\"type\">Optional</span>[<span class=\"built_in\">dict</span>] = <span class=\"literal\">None</span></span>) -&gt; <span class=\"type\">Any</span></span></span><br><span class=\"line\"><span class=\"function\">#Minimization of scalar function of one <span class=\"keyword\">or</span> more variables.</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy <span class=\"keyword\">import</span>  optimize <span class=\"keyword\">as</span> opt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 目标函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">objective</span>(<span class=\"params\">x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span> + x[<span class=\"number\">1</span>]**<span class=\"number\">2</span> + x[<span class=\"number\">2</span>]**<span class=\"number\">2</span> +<span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"comment\"># 约束条件，&gt;=以及=</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">constraint1</span>(<span class=\"params\">x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span> - x[<span class=\"number\">1</span>] + x[<span class=\"number\">2</span>]**<span class=\"number\">2</span>  <span class=\"comment\"># 不等约束</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">constraint2</span>(<span class=\"params\">x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> -(x[<span class=\"number\">0</span>] + x[<span class=\"number\">1</span>]**<span class=\"number\">2</span> + x[<span class=\"number\">2</span>]**<span class=\"number\">2</span>-<span class=\"number\">20</span>)  <span class=\"comment\"># 不等约束，默认&gt;=，这里是&lt;=,加上负号</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">constraint3</span>(<span class=\"params\">x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> -x[<span class=\"number\">0</span>] - x[<span class=\"number\">1</span>]**<span class=\"number\">2</span> + <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">constraint4</span>(<span class=\"params\">x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x[<span class=\"number\">1</span>] + <span class=\"number\">2</span>*x[<span class=\"number\">2</span>]**<span class=\"number\">2</span> -<span class=\"number\">3</span>           <span class=\"comment\"># 不等约束</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 边界约束，都大于零</span></span><br><span class=\"line\">b = (<span class=\"number\">0.0</span>, <span class=\"literal\">None</span>)</span><br><span class=\"line\">bnds = (b, b ,b) </span><br><span class=\"line\"></span><br><span class=\"line\">con1 = &#123;<span class=\"string\">&#x27;type&#x27;</span>: <span class=\"string\">&#x27;ineq&#x27;</span>, <span class=\"string\">&#x27;fun&#x27;</span>: constraint1&#125;<span class=\"comment\">#不等约束&gt;=</span></span><br><span class=\"line\">con2 = &#123;<span class=\"string\">&#x27;type&#x27;</span>: <span class=\"string\">&#x27;ineq&#x27;</span>, <span class=\"string\">&#x27;fun&#x27;</span>: constraint2&#125;<span class=\"comment\">#不等约束&gt;=</span></span><br><span class=\"line\">con3 = &#123;<span class=\"string\">&#x27;type&#x27;</span>: <span class=\"string\">&#x27;eq&#x27;</span>, <span class=\"string\">&#x27;fun&#x27;</span>: constraint3&#125;<span class=\"comment\">#相等约束</span></span><br><span class=\"line\">con4 = &#123;<span class=\"string\">&#x27;type&#x27;</span>: <span class=\"string\">&#x27;eq&#x27;</span>, <span class=\"string\">&#x27;fun&#x27;</span>: constraint4&#125;<span class=\"comment\">#相等约束</span></span><br><span class=\"line\"></span><br><span class=\"line\">cons = ([con1, con2, con3,con4])  <span class=\"comment\"># 4个约束条件</span></span><br><span class=\"line\"><span class=\"comment\"># 计算</span></span><br><span class=\"line\"><span class=\"comment\">#定义初始值</span></span><br><span class=\"line\"><span class=\"comment\">#x0 = ([0, 0, 0])</span></span><br><span class=\"line\"><span class=\"comment\">#使用函数minimize求解最小值，传入参数：objective目标函数，x0初始值，method使用QP问题解决方法，bounds取值范围，constraints约束套件</span></span><br><span class=\"line\">solution = minimize(objective, x0, method=<span class=\"string\">&#x27;SLSQP&#x27;</span>, bounds=bnds, constraints=cons)</span><br><span class=\"line\">x = solution.x</span><br><span class=\"line\"><span class=\"built_in\">print</span>(solution)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;目标值: &#x27;</span> + <span class=\"built_in\">str</span>(objective(x)))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;答案为&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x1 = &#x27;</span> + <span class=\"built_in\">str</span>(x[<span class=\"number\">0</span>]))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x2 = &#x27;</span> + <span class=\"built_in\">str</span>(x[<span class=\"number\">1</span>]))</span><br></pre></td></tr></table></figure>\n<pre><code>     fun: 10.651091840572583\n     jac: array([1.10433471, 2.40651834, 1.89564812])\n message: 'Optimization terminated successfully'\n    nfev: 71\n     nit: 15\n    njev: 15\n  status: 0\n success: True\n       x: array([0.55216734, 1.20325918, 0.94782404])\n目标值: 10.651091840572583\n答案为\nx1 = 0.5521673412903173\nx2 = 1.203259181851855\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8EBP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%A2%84%E6%B5%8B/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8EBP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%A2%84%E6%B5%8B/",
            "title": "基于BP神经网络的预测",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"机器学习算法八基于bp神经网络的预测\"><a class=\"markdownIt-Anchor\" href=\"#机器学习算法八基于bp神经网络的预测\">#</a> 机器学习算法（八）：基于 BP 神经网络的预测 ¶</h1>\n<h2 id=\"1前言算法简介和应用\"><a class=\"markdownIt-Anchor\" href=\"#1前言算法简介和应用\">#</a> 1. 前言：算法简介和应用</h2>\n<h3 id=\"11算法简介\"><a class=\"markdownIt-Anchor\" href=\"#11算法简介\">#</a> 1.1. 算法简介</h3>\n<p>BP（Back Propagation）网络是 1986 年由 Rumelhart 和 McCelland 为首的科学家小组提出，是一种按误差逆传播算法训练的多层前馈网络，是目前应用最广泛的神经网络模型之一。BP 网络能学习和存贮大量的输入 - 输出模式映射关系，而无需事前揭示描述这种映射关系的数学方程。它的学习规则是使用最速下降法，通过反向传播来不断调整网络的权值和阈值，使网络的误差平方和最小。BP 神经网络模型拓扑结构包括输入层（input）、隐层 (hide layer) 和输出层 (output layer)。在模拟过程中收集系统所产生的误差，通过误差反传，然后调整权值大小，通过该不断迭代更新，最后使得模型趋于整体最优化（这是一个循环，我们在训练神经网络的时候是要不断的去重复这个过程的）。</p>\n<p>BP 神经网络具有以下优点：</p>\n<ol>\n<li>\n<p>非线性映射能力：BP 神经网络实质上实现了一个从输入到输出的映射功能，数学理论证明三层的神经网络就能够以任意精度逼近任何非线性连续函数。这使得其特别适合于求解内部机制复杂的问题，即 BP 神经网络具有较强的非线性映射能力。</p>\n</li>\n<li>\n<p>自学习和自适应能力：BP 神经网络在训练时，能够通过学习自动提取输入、输出数据间的 “合理规则”，并自适应地将学习内容记忆于网络的权值中。即 BP 神经网络具有高度自学习和自适应的能力。</p>\n</li>\n<li>\n<p>泛化能力：所谓泛化能力是指在设计模式分类器时，即要考虑网络在保证对所需分类对象进行正确分类，还要关心网络在经过训练后，能否对未见过的模式或有噪声污染的模式，进行正确的分类。也即 BP 神经网络具有将学习成果应用于新知识的能力。</p>\n</li>\n</ol>\n<p>BP 神经网络具有以下缺点点：</p>\n<ol>\n<li>\n<p>局部极小化问题：从数学角度看，传统的 BP 神经网络为一种局部搜索的优化方法，它要解决的是一个复杂非线性化问题，网络的权值是通过沿局部改善的方向逐渐进行调整的，这样会使算法陷入局部极值，权值收敛到局部极小点，从而导致网络训练失败。加上 BP 神经网络对初始网络权重非常敏感，以不同的权重初始化网络，其往往会收敛于不同的局部极小，这也是每次训练得到不同结果的根本原因。</p>\n</li>\n<li>\n<p>BP 神经网络算法的收敛速度慢：由于 BP 神经网络算法本质上为梯度下降法，它所要优化的目标函数是非常复杂的，因此，必然会出现 “锯齿形现象”，这使得 BP 算法低效；又由于优化的目标函数很复杂，它必然会在神经元输出接近 0 或 1 的情况下，出现一些平坦区，在这些区域内，权值误差改变很小，使训练过程几乎停顿；BP 神经网络模型中，为了使网络执行 BP 算法，不能使用传统的一维搜索法求每次迭代的步长，而必须把步长的更新规则预先赋予网络，这种方法也会引起算法低效。以上种种，导致了 BP 神经网络算法收敛速度慢的现象。</p>\n</li>\n<li>\n<p>BP 神经网络结构选择不一：BP 神经网络结构的选择至今尚无一种统一而完整的理论指导，一般只能由经验选定。网络结构选择过大，训练中效率不高，可能出现过拟合现象，造成网络性能低，容错性下降，若选择过小，则又会造成网络可能不收敛。而网络的结构直接影响网络的逼近能力及推广性质。因此，应用中如何选择合适的网络结构是一个重要的问题。</p>\n</li>\n</ol>\n<h3 id=\"12算法应用\"><a class=\"markdownIt-Anchor\" href=\"#12算法应用\">#</a> 1.2. 算法应用</h3>\n<p>BP 反映了生物神经系统处理外界事物的基本过程，是在模拟人脑神经组织的基础上发展起来的计算系统，是由大量处理单元通过广泛互联而构成的网络体系，它具有生物神经系统的基本特征，在一定程度上反映了人脑功能的若干反映，是对生物系统的某种模拟，具有大规模并行、分布式处理、自组织、自学习等优点，被广泛应用于语音分析、图像识别、数字水印、计算机视觉等很多领域，取得了许多突出的成果。最近由于人工神经网络的快速发展，它已经成为模式识别的强有力的工具。神经网络的运用展开了新的领域，解决其它模式识别不能解决的问题，其分类功能特别适合于模式识别与分类的应用。</p>\n<h2 id=\"2学习目标\"><a class=\"markdownIt-Anchor\" href=\"#2学习目标\">#</a> 2. 学习目标</h2>\n<p>掌握 BP 算法基本原理<br>\n掌握利用 BP 进行代码实战</p>\n<h2 id=\"3代码流程\"><a class=\"markdownIt-Anchor\" href=\"#3代码流程\">#</a> 3. 代码流程</h2>\n<p><strong>Part 1 Demo 实践</strong></p>\n<ul>\n<li>\n<p>Step1: 库函数导入</p>\n</li>\n<li>\n<p>Step2: 模型训练</p>\n</li>\n<li>\n<p>Step3: 模型参数查看</p>\n</li>\n<li>\n<p>Step4: 数据和模型可视化</p>\n</li>\n<li>\n<p>Step5: 模型预测<br>\n<strong> Part 2 基于 BP 神经网络的乳腺癌分类实践</strong></p>\n</li>\n<li>\n<p>Step1: 库函数导入</p>\n</li>\n<li>\n<p>Step2: 数据读取 / 载入</p>\n</li>\n<li>\n<p>Step3: 数据信息简单查看与可视化</p>\n</li>\n<li>\n<p>Step4: 利用 BP 神经网络在乳腺癌数据上进行训练和预测</p>\n</li>\n</ul>\n<h2 id=\"4代码实战\"><a class=\"markdownIt-Anchor\" href=\"#4代码实战\">#</a> 4. 代码实战</h2>\n<h4 id=\"part-1-demo实践\"><a class=\"markdownIt-Anchor\" href=\"#part-1-demo实践\">#</a> <strong>Part 1 Demo 实践</strong></h4>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 基础数组运算库导入</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"><span class=\"comment\"># 画图库导入</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt </span><br><span class=\"line\"><span class=\"comment\"># 导入三维显示工具</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"><span class=\"comment\"># 导入BP模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neural_network <span class=\"keyword\">import</span> MLPClassifier</span><br><span class=\"line\"><span class=\"comment\"># 导入demo数据制作方法</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_classification</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report, confusion_matrix</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.exceptions <span class=\"keyword\">import</span> ConvergenceWarning</span><br></pre></td></tr></table></figure>\n<p><strong>Step2: 模型训练</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 制作五个类别的数据，每个类别1000个样本</span></span><br><span class=\"line\">train_samples, train_labels = make_classification(n_samples=<span class=\"number\">1000</span>, n_features=<span class=\"number\">3</span>, n_redundant=<span class=\"number\">0</span>,</span><br><span class=\"line\">                           n_classes=<span class=\"number\">5</span>, n_informative=<span class=\"number\">3</span>, n_clusters_per_class=<span class=\"number\">1</span>,</span><br><span class=\"line\">                           class_sep=<span class=\"number\">3</span>, random_state=<span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># 将五个类别的数据进行三维显示</span></span><br><span class=\"line\">fig = plt.figure()</span><br><span class=\"line\">ax = Axes3D(fig, rect=[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], elev=<span class=\"number\">20</span>, azim=<span class=\"number\">20</span>)</span><br><span class=\"line\">ax.scatter(train_samples[:, <span class=\"number\">0</span>], train_samples[:, <span class=\"number\">1</span>], train_samples[:, <span class=\"number\">2</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>, c=train_labels)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Demo Data Map&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n  import sys\n\n\n\n\n\nText(0.5, 0.92, 'Demo Data Map')\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_3_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 建立 BP 模型, 采用sgd优化器，relu非线性映射函数</span></span><br><span class=\"line\">BP = MLPClassifier(solver=<span class=\"string\">&#x27;sgd&#x27;</span>,activation = <span class=\"string\">&#x27;relu&#x27;</span>,max_iter = <span class=\"number\">500</span>,alpha = <span class=\"number\">1e-3</span>,hidden_layer_sizes = (<span class=\"number\">32</span>,<span class=\"number\">32</span>),random_state = <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># 进行模型训练</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> warnings.catch_warnings():</span><br><span class=\"line\">    warnings.filterwarnings(<span class=\"string\">&quot;ignore&quot;</span>, category=ConvergenceWarning,</span><br><span class=\"line\">                            module=<span class=\"string\">&quot;sklearn&quot;</span>)</span><br><span class=\"line\">    BP.fit(train_samples, train_labels)</span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 模型参数查看</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看 BP 模型的参数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(BP)</span><br></pre></td></tr></table></figure>\n<pre><code>MLPClassifier(alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=500,\n              random_state=1, solver='sgd')\n</code></pre>\n<p><strong>Step4: 数据和模型可视化</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行模型预测</span></span><br><span class=\"line\">predict_labels = BP.predict(train_samples)</span><br><span class=\"line\"><span class=\"comment\"># 显示预测的散点图</span></span><br><span class=\"line\">fig = plt.figure()</span><br><span class=\"line\">ax = Axes3D(fig, rect=[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], elev=<span class=\"number\">20</span>, azim=<span class=\"number\">20</span>)</span><br><span class=\"line\">ax.scatter(train_samples[:, <span class=\"number\">0</span>], train_samples[:, <span class=\"number\">1</span>], train_samples[:, <span class=\"number\">2</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>, c=predict_labels)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Demo Data Predict Map with BP Model&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 显示预测分数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;预测准确率: &#123;:.4f&#125;&quot;</span>.<span class=\"built_in\">format</span>(BP.score(train_samples, train_labels)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化预测数据 </span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;真实类别：&quot;</span>, train_labels[:<span class=\"number\">10</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;预测类别：&quot;</span>, predict_labels[:<span class=\"number\">10</span>])</span><br><span class=\"line\"><span class=\"comment\"># 准确率等报表</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(train_labels, predict_labels))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算混淆矩阵</span></span><br><span class=\"line\">classes = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]</span><br><span class=\"line\">cofusion_mat = confusion_matrix(train_labels, predict_labels, classes) </span><br><span class=\"line\">sns.<span class=\"built_in\">set</span>()</span><br><span class=\"line\">figur, ax = plt.subplots()</span><br><span class=\"line\"><span class=\"comment\"># 画热力图</span></span><br><span class=\"line\">sns.heatmap(cofusion_mat, cmap=<span class=\"string\">&quot;YlGnBu_r&quot;</span>, annot=<span class=\"literal\">True</span>, ax=ax) </span><br><span class=\"line\">ax.set_title(<span class=\"string\">&#x27;confusion matrix&#x27;</span>)  <span class=\"comment\"># 标题</span></span><br><span class=\"line\">ax.set_xticklabels([<span class=\"string\">&#x27;&#x27;</span>] + classes, minor=<span class=\"literal\">True</span>)</span><br><span class=\"line\">ax.set_yticklabels([<span class=\"string\">&#x27;&#x27;</span>] + classes, minor=<span class=\"literal\">True</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;predict&#x27;</span>)  <span class=\"comment\"># x轴</span></span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&#x27;true&#x27;</span>)  <span class=\"comment\"># y轴</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n  &quot;&quot;&quot;\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass labels=[0, 1, 2, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  &quot;will result in an error&quot;, FutureWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: FixedFormatter should only be used together with FixedLocator\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: FixedFormatter should only be used together with FixedLocator\n\n\n预测准确率: 0.9950\n真实类别： [0 4 2 2 3 2 3 0 1 0]\n预测类别： [0 4 2 2 3 2 3 0 1 0]\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99       198\n           1       1.00      0.99      0.99       203\n           2       1.00      1.00      1.00       200\n           3       0.99      1.00      1.00       199\n           4       0.99      0.99      0.99       200\n\n    accuracy                           0.99      1000\n   macro avg       0.99      1.00      0.99      1000\nweighted avg       1.00      0.99      1.00      1000\n</code></pre>\n<p>​</p>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_8_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_8_3.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><strong>Step5: 模型预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行新的测试数据测试</span></span><br><span class=\"line\">test_sample = np.array([[-<span class=\"number\">1</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别是: &quot;</span>, BP.predict(test_sample))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别概率分别是: &quot;</span>, BP.predict_proba(test_sample))</span><br><span class=\"line\"></span><br><span class=\"line\">test_sample = np.array([[-<span class=\"number\">1.2</span>, <span class=\"number\">10</span>, -<span class=\"number\">91</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别是: &quot;</span>, BP.predict(test_sample))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别概率分别是: &quot;</span>, BP.predict_proba(test_sample))</span><br><span class=\"line\"></span><br><span class=\"line\">test_sample = np.array([[-<span class=\"number\">12</span>, -<span class=\"number\">0.1</span>, -<span class=\"number\">0.1</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别是: &quot;</span>, BP.predict(test_sample))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别概率分别是: &quot;</span>, BP.predict_proba(test_sample))</span><br><span class=\"line\"></span><br><span class=\"line\">test_sample = np.array([[<span class=\"number\">100</span>, -<span class=\"number\">90.1</span>, -<span class=\"number\">9.1</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别是: &quot;</span>, BP.predict(test_sample))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;test_sample&#125;</span> 类别概率分别是: &quot;</span>, BP.predict_proba(test_sample))</span><br></pre></td></tr></table></figure>\n<pre><code>[[-1.   0.1  0.1]] 类别是:  [4]\n[[-1.   0.1  0.1]] 类别概率分别是:  [[0.08380116 0.1912275  0.17608601 0.16488309 0.38400224]]\n[[ -1.2  10.  -91. ]] 类别是:  [1]\n[[ -1.2  10.  -91. ]] 类别概率分别是:  [[3.37231505e-30 1.00000000e+00 4.24566351e-51 1.92771500e-57\n  5.16916174e-17]]\n[[-12.   -0.1  -0.1]] 类别是:  [4]\n[[-12.   -0.1  -0.1]] 类别概率分别是:  [[1.42696980e-06 5.86057194e-05 2.99819240e-05 3.03896335e-05\n  9.99879596e-01]]\n[[100.  -90.1  -9.1]] 类别是:  [2]\n[[100.  -90.1  -9.1]] 类别概率分别是:  [[2.45024178e-02 8.44965777e-67 9.75497582e-01 1.41511057e-66\n  4.23516105e-50]]\n</code></pre>\n<h4 id=\"part-2-基于bp神经网络的乳腺癌分类实践\"><a class=\"markdownIt-Anchor\" href=\"#part-2-基于bp神经网络的乳腺癌分类实践\">#</a> Part 2 基于 BP 神经网络的乳腺癌分类实践</h4>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入乳腺癌数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_breast_cancer</span><br><span class=\"line\"><span class=\"comment\"># 导入BP模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neural_network <span class=\"keyword\">import</span> MLPClassifier</span><br><span class=\"line\"><span class=\"comment\"># 导入训练集分割方法</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split </span><br><span class=\"line\"><span class=\"comment\"># 导入预测指标计算函数和混淆矩阵计算函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report, confusion_matrix</span><br><span class=\"line\"><span class=\"comment\"># 导入绘图包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib</span><br></pre></td></tr></table></figure>\n<p><strong>Step2: 数据读取 / 载入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入乳腺癌数据集</span></span><br><span class=\"line\">cancer = load_breast_cancer()</span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 数据信息简单查看与可视化</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看数据集信息</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;breast_cancer数据集的长度为：&#x27;</span>,<span class=\"built_in\">len</span>(cancer))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;breast_cancer数据集的类型为：&#x27;</span>,<span class=\"built_in\">type</span>(cancer))</span><br><span class=\"line\"><span class=\"comment\"># 分割数据为训练集和测试集</span></span><br><span class=\"line\">cancer_data = cancer[<span class=\"string\">&#x27;data&#x27;</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;cancer_data数据维度为：&#x27;</span>,cancer_data.shape)</span><br><span class=\"line\">cancer_target = cancer[<span class=\"string\">&#x27;target&#x27;</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;cancer_target标签维度为：&#x27;</span>,cancer_target.shape)</span><br><span class=\"line\">cancer_names = cancer[<span class=\"string\">&#x27;feature_names&#x27;</span>]</span><br><span class=\"line\">cancer_desc = cancer[<span class=\"string\">&#x27;DESCR&#x27;</span>]</span><br><span class=\"line\"><span class=\"comment\">#分为训练集与测试集</span></span><br><span class=\"line\">cancer_data_train,cancer_data_test = train_test_split(cancer_data,test_size=<span class=\"number\">0.2</span>,random_state=<span class=\"number\">42</span>)<span class=\"comment\">#训练集</span></span><br><span class=\"line\">cancer_target_train,cancer_target_test = train_test_split(cancer_target,test_size=<span class=\"number\">0.2</span>,random_state=<span class=\"number\">42</span>)<span class=\"comment\">#测试集</span></span><br></pre></td></tr></table></figure>\n<pre><code>breast_cancer数据集的长度为： 7\nbreast_cancer数据集的类型为： &lt;class 'sklearn.utils.Bunch'&gt;\ncancer_data数据维度为： (569, 30)\ncancer_target标签维度为： (569,)\n</code></pre>\n<p><strong>Step4: 利用 BP 神经网络在乳腺癌数据上进行训练和预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 建立 BP 模型, 采用Adam优化器，relu非线性映射函数</span></span><br><span class=\"line\">BP = MLPClassifier(solver=<span class=\"string\">&#x27;adam&#x27;</span>,activation = <span class=\"string\">&#x27;relu&#x27;</span>,max_iter = <span class=\"number\">1000</span>,alpha = <span class=\"number\">1e-3</span>,hidden_layer_sizes = (<span class=\"number\">64</span>,<span class=\"number\">32</span>, <span class=\"number\">32</span>),random_state = <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># 进行模型训练</span></span><br><span class=\"line\">BP.fit(cancer_data_train, cancer_target_train)</span><br></pre></td></tr></table></figure>\n<pre><code>MLPClassifier(alpha=0.001, hidden_layer_sizes=(64, 32, 32), max_iter=1000,\n              random_state=1)\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行模型预测</span></span><br><span class=\"line\">predict_train_labels = BP.predict(cancer_data_train)</span><br><span class=\"line\"><span class=\"comment\"># 可视化真实数据</span></span><br><span class=\"line\">fig = plt.figure()</span><br><span class=\"line\">ax = Axes3D(fig, rect=[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], elev=<span class=\"number\">20</span>, azim=<span class=\"number\">20</span>) </span><br><span class=\"line\">ax.scatter(cancer_data_train[:, <span class=\"number\">0</span>], cancer_data_train[:, <span class=\"number\">1</span>], cancer_data_train[:, <span class=\"number\">2</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>, c=cancer_target_train)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;True Label Map&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"><span class=\"comment\"># 可视化预测数据</span></span><br><span class=\"line\">fig = plt.figure()</span><br><span class=\"line\">ax = Axes3D(fig, rect=[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], elev=<span class=\"number\">20</span>, azim=<span class=\"number\">20</span>) </span><br><span class=\"line\">ax.scatter(cancer_data_train[:, <span class=\"number\">0</span>], cancer_data_train[:, <span class=\"number\">1</span>], cancer_data_train[:, <span class=\"number\">2</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>, c=predict_train_labels)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Cancer with BP Model&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n  &quot;&quot;&quot;\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_19_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:11: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n  # This is added back by InteractiveShellApp.init_path()\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_19_3.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示预测分数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;预测准确率: &#123;:.4f&#125;&quot;</span>.<span class=\"built_in\">format</span>(BP.score(cancer_data_test, cancer_target_test)))</span><br><span class=\"line\"><span class=\"comment\"># 进行测试集数据的类别预测</span></span><br><span class=\"line\">predict_test_labels = BP.predict(cancer_data_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;测试集的真实标签:\\n&quot;</span>, cancer_target_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;测试集的预测标签:\\n&quot;</span>, predict_test_labels)</span><br></pre></td></tr></table></figure>\n<pre><code>预测准确率: 0.9474\n测试集的真实标签:\n [1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n 1 1 0]\n测试集的预测标签:\n [1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1\n 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n 1 1 0]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行预测结果指标统计 统计每一类别的预测准确率、召回率、F1分数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(cancer_target_test, predict_test_labels))</span><br></pre></td></tr></table></figure>\n<pre><code>              precision    recall  f1-score   support\n\n           0       1.00      0.86      0.92        43\n           1       0.92      1.00      0.96        71\n\n    accuracy                           0.95       114\n   macro avg       0.96      0.93      0.94       114\nweighted avg       0.95      0.95      0.95       114\n</code></pre>\n<p>​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算混淆矩阵</span></span><br><span class=\"line\">confusion_mat = confusion_matrix(cancer_target_test, predict_test_labels)</span><br><span class=\"line\"><span class=\"comment\"># 打混淆矩阵</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(confusion_mat)</span><br></pre></td></tr></table></figure>\n<pre><code>[[37  6]\n [ 0 71]]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将混淆矩阵以热力图的防线显示</span></span><br><span class=\"line\">sns.<span class=\"built_in\">set</span>()</span><br><span class=\"line\">figure, ax = plt.subplots()</span><br><span class=\"line\"><span class=\"comment\"># 画热力图</span></span><br><span class=\"line\">sns.heatmap(confusion_mat, cmap=<span class=\"string\">&quot;YlGnBu_r&quot;</span>, annot=<span class=\"literal\">True</span>, ax=ax)  </span><br><span class=\"line\"><span class=\"comment\"># 标题 </span></span><br><span class=\"line\">ax.set_title(<span class=\"string\">&#x27;confusion matrix&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># x轴为预测类别</span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;predict&#x27;</span>)  </span><br><span class=\"line\"><span class=\"comment\"># y轴实际类别</span></span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&#x27;true&#x27;</span>)  </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_23_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<h2 id=\"5-算法重要知识点\"><a class=\"markdownIt-Anchor\" href=\"#5-算法重要知识点\">#</a> 5. 算法重要知识点</h2>\n<p>BP 神经网络模型要点在于数据的前向传播和误差反向传播，来对参数进行更新，使得损失最小化。 误差反向传播算法简称反向传播算法（即 BP 算法）。使用反向传播算法的多层感知器又称为 BP 神经网络。BP 算法是一个迭代算法，它的基本思想为：</p>\n<ol>\n<li>先计算每一层的状态和激活值，直到最后一层（即信号是前向传播的）；</li>\n<li>计算每一层的误差，误差的计算过程是从最后一层向前推进的（这就是反向传播算法名字的由来）；</li>\n<li>更新参数（目标是误差变小）。迭代前面两个步骤，直到满足停止准则（比如相邻两次迭代的误差的差别很小）。</li>\n</ol>\n<p>在这个过程，函数的导数链式法则求导很重要，需要手动推导 BP 神经网络模型的梯度反向传播过程，熟练掌握链式法则进行求导，对参数进行更新。</p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "title": "基于决策树的分类预测",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"1-逻决策树的介绍和应用\"><a class=\"markdownIt-Anchor\" href=\"#1-逻决策树的介绍和应用\">#</a> 1 逻决策树的介绍和应用</h1>\n<h2 id=\"11-决策树的介绍\"><a class=\"markdownIt-Anchor\" href=\"#11-决策树的介绍\">#</a> 1.1 决策树的介绍</h2>\n<p>决策树是一种常见的分类模型，在金融风控、医疗辅助诊断等诸多行业具有较为广泛的应用。决策树的核心思想是基于树结构对数据进行划分，这种思想是人类处理问题时的本能方法。例如在婚恋市场中，女方通常会先询问男方是否有房产，如果有房产再了解是否有车产，如果有车产再看是否有稳定工作…… 最后得出是否要深入了解的判断。</p>\n<p>决策树的主要优点：</p>\n<ul>\n<li>具有很好的解释性，模型可以生成可以理解的规则。</li>\n<li>可以发现特征的重要程度。</li>\n<li>模型的计算复杂度较低。</li>\n</ul>\n<p>决策树的主要缺点：</p>\n<ul>\n<li>模型容易过拟合，需要采用减枝技术处理。</li>\n<li>不能很好利用连续型特征。</li>\n<li>预测能力有限，无法达到其他强监督模型效果。</li>\n<li>方差较高，数据分布的轻微改变很容易造成树结构完全不同。</li>\n</ul>\n<h2 id=\"12-决策树的应用\"><a class=\"markdownIt-Anchor\" href=\"#12-决策树的应用\">#</a> 1.2 决策树的应用</h2>\n<p>由于决策树模型中自变量与因变量的非线性关系以及决策树简单的计算方法，使得它成为集成学习中最为广泛使用的基模型。梯度提升树 (GBDT)，XGBoost 以及 LightGBM 等先进的集成模型都采用了决策树作为基模型，在广告计算、CTR 预估、金融风控等领域大放异彩，成为当今与神经网络相提并论的复杂模型，更是数据挖掘比赛中的常客。在新的研究中，南京大学周志华教授提出一种多粒度级联森林模型，创造了一种全新的基于决策树的深度集成方法，为我们提供了决策树发展的另一种可能。</p>\n<p>同时决策树在一些明确需要可解释性或者提取分类规则的场景中被广泛应用，而其他机器学习模型在这一点很难做到。例如在医疗辅助系统中，为了方便专业人员发现错误，常常将决策树算法用于辅助病症检测。例如在一个预测哮喘患者的模型中，医生发现测试的许多高级模型的效果非常差。在他们运行了一个决策树模型后发现，算法认为剧烈咳嗽的病人患哮喘的风险很小。但医生非常清楚剧烈咳嗽一般都会被立刻检查治疗，这意味着患有剧烈咳嗽的哮喘病人都会马上得到收治。用于建模的数据认为这类病人风险很小，是因为所有这类病人都得到了及时治疗，所以极少有人在此之后患病或死亡。</p>\n<h1 id=\"2-实验室手册\"><a class=\"markdownIt-Anchor\" href=\"#2-实验室手册\">#</a> 2. 实验室手册</h1>\n<h2 id=\"21-学习目标\"><a class=\"markdownIt-Anchor\" href=\"#21-学习目标\">#</a> 2.1 学习目标</h2>\n<p>了解 决策树 的理论知识<br>\n掌握 决策树 的 sklearn 函数调用并将其运用在企鹅数据集的预测中</p>\n<h2 id=\"22-代码流程\"><a class=\"markdownIt-Anchor\" href=\"#22-代码流程\">#</a> 2.2 代码流程</h2>\n<h4 id=\"part1-demo实践\"><a class=\"markdownIt-Anchor\" href=\"#part1-demo实践\">#</a> Part1 Demo 实践</h4>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 模型训练</li>\n<li>Step3: 数据和模型可视化</li>\n<li>Step4: 模型预测</li>\n</ul>\n<h4 id=\"part2-基于企鹅penguins数据集的决策树分类实践\"><a class=\"markdownIt-Anchor\" href=\"#part2-基于企鹅penguins数据集的决策树分类实践\">#</a> Part2 基于企鹅（penguins）数据集的决策树分类实践</h4>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 数据读取 / 载入</li>\n<li>Step3: 数据信息简单查看</li>\n<li>Step4: 可视化描述</li>\n<li>Step5: 利用 决策树模型 在二分类上 进行训练和预测</li>\n<li>Step6: 利用 决策树模型 在三分类 (多分类) 上 进行训练和预测</li>\n</ul>\n<h2 id=\"23-算法实战\"><a class=\"markdownIt-Anchor\" href=\"#23-算法实战\">#</a> 2.3 算法实战</h2>\n<h3 id=\"231-demo实践\"><a class=\"markdownIt-Anchor\" href=\"#231-demo实践\">#</a> 2.3.1 Demo 实践</h3>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##  基础函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 导入画图库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 导入决策树模型函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br></pre></td></tr></table></figure>\n<p><strong>Step2: 模型训练</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##Demo演示LogisticRegression分类</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 构造数据集</span></span><br><span class=\"line\">x_fearures = np.array([[-<span class=\"number\">1</span>, -<span class=\"number\">2</span>], [-<span class=\"number\">2</span>, -<span class=\"number\">1</span>], [-<span class=\"number\">3</span>, -<span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">3</span>], [<span class=\"number\">2</span>, <span class=\"number\">1</span>], [<span class=\"number\">3</span>, <span class=\"number\">2</span>]])</span><br><span class=\"line\">y_label = np.array([<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 调用决策树回归模型</span></span><br><span class=\"line\">tree_clf = DecisionTreeClassifier()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 调用决策树模型拟合构造的数据集</span></span><br><span class=\"line\">tree_clf = tree_clf.fit(x_fearures, y_label)</span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 数据和模型可视化</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 可视化构造的数据样本点</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x_fearures[:,<span class=\"number\">0</span>],x_fearures[:,<span class=\"number\">1</span>], c=y_label, s=<span class=\"number\">50</span>, cmap=<span class=\"string\">&#x27;viridis&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Dataset&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_5_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><strong>Step4: 模型预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 创建新样本</span></span><br><span class=\"line\">x_fearures_new1 = np.array([[<span class=\"number\">0</span>, -<span class=\"number\">1</span>]])</span><br><span class=\"line\">x_fearures_new2 = np.array([[<span class=\"number\">2</span>, <span class=\"number\">1</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用训练好的模型进行预测</span></span><br><span class=\"line\">y_label_new1_predict = tree_clf.predict(x_fearures_new1)</span><br><span class=\"line\">y_label_new2_predict = tree_clf.predict(x_fearures_new2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The New point 1 predict class:\\n&#x27;</span>,y_label_new1_predict)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The New point 2 predict class:\\n&#x27;</span>,y_label_new2_predict)</span><br></pre></td></tr></table></figure>\n<pre><code>The New point 1 predict class:\n [1]\nThe New point 2 predict class:\n [0]\n</code></pre>\n<h3 id=\"232-基于企鹅数据集的决策树实战\"><a class=\"markdownIt-Anchor\" href=\"#232-基于企鹅数据集的决策树实战\">#</a> 2.3.2 基于企鹅数据集的决策树实战</h3>\n<p>在实践的最开始，我们首先需要导入一些基础的函数库包括：numpy （Python 进行科学计算的基础软件包），pandas（pandas 是一种快速，强大，灵活且易于使用的开源数据分析和处理工具），matplotlib 和 seaborn 绘图。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#下载需要用到的数据集</span></span><br><span class=\"line\">!wget https://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/6tree/penguins_raw.csv</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Step1: 库函数导入</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##  基础函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 绘图函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br></pre></td></tr></table></figure>\n<p>本次我们选择企鹅数据（palmerpenguins）进行方法的尝试训练，该数据集一共包含 8 个变量，其中 7 个特征变量，1 个目标分类变量。共有 150 个样本，目标变量为 企鹅的类别 其都属于企鹅类的三个亚属，分别是 (Adélie, Chinstrap and Gentoo)。包含的三种种企鹅的七个特征，分别是所在岛屿，嘴巴长度，嘴巴深度，脚蹼长度，身体体积，性别以及年龄。</p>\n<table>\n<thead>\n<tr>\n<th>变量</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>species</td>\n<td>a factor denoting penguin species</td>\n</tr>\n<tr>\n<td>island</td>\n<td>a factor denoting island in Palmer Archipelago, Antarctica</td>\n</tr>\n<tr>\n<td>bill_length_mm</td>\n<td>a number denoting bill length</td>\n</tr>\n<tr>\n<td>bill_depth_mm</td>\n<td>a number denoting bill depth</td>\n</tr>\n<tr>\n<td>flipper_length_mm</td>\n<td>an integer denoting flipper length</td>\n</tr>\n<tr>\n<td>body_mass_g</td>\n<td>an integer denoting body mass</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>a factor denoting penguin sex</td>\n</tr>\n<tr>\n<td>year</td>\n<td>an integer denoting the study year</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>Step2: 数据读取 / 载入</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 我们利用Pandas自带的read_csv函数读取并转化为DataFrame格式</span></span><br><span class=\"line\"></span><br><span class=\"line\">data = pd.read_csv(<span class=\"string\">&#x27;./penguins_raw.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 为了方便我们仅选取四个简单的特征，有兴趣的同学可以研究下其他特征的含义以及使用方法</span></span><br><span class=\"line\">data = data[[<span class=\"string\">&#x27;Species&#x27;</span>,<span class=\"string\">&#x27;Culmen Length (mm)&#x27;</span>,<span class=\"string\">&#x27;Culmen Depth (mm)&#x27;</span>,</span><br><span class=\"line\">            <span class=\"string\">&#x27;Flipper Length (mm)&#x27;</span>,<span class=\"string\">&#x27;Body Mass (g)&#x27;</span>]]</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Step3: 数据信息简单查看</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 利用.info()查看数据的整体信息</span></span><br><span class=\"line\">data.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 5 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Species              344 non-null    object \n 1   Culmen Length (mm)   342 non-null    float64\n 2   Culmen Depth (mm)    342 non-null    float64\n 3   Flipper Length (mm)  342 non-null    float64\n 4   Body Mass (g)        342 non-null    float64\ndtypes: float64(4), object(1)\nmemory usage: 13.6+ KB\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 进行简单的数据查看，我们可以利用 .head() 头部.tail()尾部</span></span><br><span class=\"line\">data.head()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Species</th>\n      <th>Culmen Length (mm)</th>\n      <th>Culmen Depth (mm)</th>\n      <th>Flipper Length (mm)</th>\n      <th>Body Mass (g)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n      <td>39.1</td>\n      <td>18.7</td>\n      <td>181.0</td>\n      <td>3750.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n      <td>39.5</td>\n      <td>17.4</td>\n      <td>186.0</td>\n      <td>3800.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n      <td>40.3</td>\n      <td>18.0</td>\n      <td>195.0</td>\n      <td>3250.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n      <td>36.7</td>\n      <td>19.3</td>\n      <td>193.0</td>\n      <td>3450.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>这里我们发现数据集中存在 NaN，一般的我们认为 NaN 在数据集中代表了缺失值，可能是数据采集或处理时产生的一种错误。这里我们采用 - 1 将缺失值进行填补，还有其他例如 “中位数填补、平均数填补” 的缺失值处理方法有兴趣的同学也可以尝试。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = data.fillna(-<span class=\"number\">1</span>)</span><br><span class=\"line\">data.tail()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Species</th>\n      <th>Culmen Length (mm)</th>\n      <th>Culmen Depth (mm)</th>\n      <th>Flipper Length (mm)</th>\n      <th>Body Mass (g)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>339</th>\n      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n      <td>55.8</td>\n      <td>19.8</td>\n      <td>207.0</td>\n      <td>4000.0</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n      <td>43.5</td>\n      <td>18.1</td>\n      <td>202.0</td>\n      <td>3400.0</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n      <td>49.6</td>\n      <td>18.2</td>\n      <td>193.0</td>\n      <td>3775.0</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n      <td>50.8</td>\n      <td>19.0</td>\n      <td>210.0</td>\n      <td>4100.0</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n      <td>50.2</td>\n      <td>18.7</td>\n      <td>198.0</td>\n      <td>3775.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 其对应的类别标签为&#x27;Adelie Penguin&#x27;, &#x27;Gentoo penguin&#x27;, </span></span><br><span class=\"line\"><span class=\"comment\">## &#x27;Chinstrap penguin&#x27;三种不同企鹅的类别。</span></span><br><span class=\"line\">data[<span class=\"string\">&#x27;Species&#x27;</span>].unique()</span><br></pre></td></tr></table></figure>\n<pre><code>array(['Adelie Penguin (Pygoscelis adeliae)',\n       'Gentoo penguin (Pygoscelis papua)',\n       'Chinstrap penguin (Pygoscelis antarctica)'], dtype=object)\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 利用value_counts函数查看每个类别数量</span></span><br><span class=\"line\">pd.Series(data[<span class=\"string\">&#x27;Species&#x27;</span>]).value_counts()</span><br></pre></td></tr></table></figure>\n<pre><code>Adelie Penguin (Pygoscelis adeliae)          152\nGentoo penguin (Pygoscelis papua)            124\nChinstrap penguin (Pygoscelis antarctica)     68\nName: Species, dtype: int64\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 对于特征进行一些统计描述</span></span><br><span class=\"line\">data.describe()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Culmen Length (mm)</th>\n      <th>Culmen Depth (mm)</th>\n      <th>Flipper Length (mm)</th>\n      <th>Body Mass (g)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>344.000000</td>\n      <td>344.000000</td>\n      <td>344.000000</td>\n      <td>344.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>43.660756</td>\n      <td>17.045640</td>\n      <td>199.741279</td>\n      <td>4177.319767</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.428957</td>\n      <td>2.405614</td>\n      <td>20.806759</td>\n      <td>861.263227</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>39.200000</td>\n      <td>15.500000</td>\n      <td>190.000000</td>\n      <td>3550.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>44.250000</td>\n      <td>17.300000</td>\n      <td>197.000000</td>\n      <td>4025.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>48.500000</td>\n      <td>18.700000</td>\n      <td>213.000000</td>\n      <td>4750.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>59.600000</td>\n      <td>21.500000</td>\n      <td>231.000000</td>\n      <td>6300.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<ul>\n<li>Step4: 可视化描述</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 特征与标签组合的散点可视化</span></span><br><span class=\"line\">sns.pairplot(data=data, diag_kind=<span class=\"string\">&#x27;hist&#x27;</span>, hue= <span class=\"string\">&#x27;Species&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_24_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>从上图可以发现，在 2D 情况下不同的特征组合对于不同类别的企鹅的散点分布，以及大概的区分能力。Culmen Lenth 与其他特征的组合散点的重合较少，所以对于数据集的划分能力最好。<br>\n我们发现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;为了方便我们将标签转化为数字</span></span><br><span class=\"line\"><span class=\"string\">       &#x27;Adelie Penguin (Pygoscelis adeliae)&#x27;        ------0</span></span><br><span class=\"line\"><span class=\"string\">       &#x27;Gentoo penguin (Pygoscelis papua)&#x27;          ------1</span></span><br><span class=\"line\"><span class=\"string\">       &#x27;Chinstrap penguin (Pygoscelis antarctica)   ------2 &#x27;&#x27;&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">trans</span>(<span class=\"params\">x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> x == data[<span class=\"string\">&#x27;Species&#x27;</span>].unique()[<span class=\"number\">0</span>]:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> x == data[<span class=\"string\">&#x27;Species&#x27;</span>].unique()[<span class=\"number\">1</span>]:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> x == data[<span class=\"string\">&#x27;Species&#x27;</span>].unique()[<span class=\"number\">2</span>]:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">data[<span class=\"string\">&#x27;Species&#x27;</span>] = data[<span class=\"string\">&#x27;Species&#x27;</span>].apply(trans)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> data.columns:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> col != <span class=\"string\">&#x27;Species&#x27;</span>:</span><br><span class=\"line\">        sns.boxplot(x=<span class=\"string\">&#x27;Species&#x27;</span>, y=col, saturation=<span class=\"number\">0.5</span>, palette=<span class=\"string\">&#x27;pastel&#x27;</span>, data=data)</span><br><span class=\"line\">        plt.title(col)</span><br><span class=\"line\">        plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_27_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_27_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_27_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_27_3.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>利用箱型图我们也可以得到不同类别在不同特征上的分布差异情况。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 选取其前三个特征绘制三维散点图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">8</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">&#x27;3d&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">data_class0 = data[data[<span class=\"string\">&#x27;Species&#x27;</span>]==<span class=\"number\">0</span>].values</span><br><span class=\"line\">data_class1 = data[data[<span class=\"string\">&#x27;Species&#x27;</span>]==<span class=\"number\">1</span>].values</span><br><span class=\"line\">data_class2 = data[data[<span class=\"string\">&#x27;Species&#x27;</span>]==<span class=\"number\">2</span>].values</span><br><span class=\"line\"><span class=\"comment\"># &#x27;setosa&#x27;(0), &#x27;versicolor&#x27;(1), &#x27;virginica&#x27;(2)</span></span><br><span class=\"line\">ax.scatter(data_class0[:,<span class=\"number\">0</span>], data_class0[:,<span class=\"number\">1</span>], data_class0[:,<span class=\"number\">2</span>],label=data[<span class=\"string\">&#x27;Species&#x27;</span>].unique()[<span class=\"number\">0</span>])</span><br><span class=\"line\">ax.scatter(data_class1[:,<span class=\"number\">0</span>], data_class1[:,<span class=\"number\">1</span>], data_class1[:,<span class=\"number\">2</span>],label=data[<span class=\"string\">&#x27;Species&#x27;</span>].unique()[<span class=\"number\">1</span>])</span><br><span class=\"line\">ax.scatter(data_class2[:,<span class=\"number\">0</span>], data_class2[:,<span class=\"number\">1</span>], data_class2[:,<span class=\"number\">2</span>],label=data[<span class=\"string\">&#x27;Species&#x27;</span>].unique()[<span class=\"number\">2</span>])</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_29_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<ul>\n<li>Step5: 利用 决策树模型 在二分类上 进行训练和预测</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 为了正确评估模型性能，将数据划分为训练集和测试集，并在训练集上训练模型，</span></span><br><span class=\"line\"><span class=\"comment\">## 在测试集上验证模型性能。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 选择其类别为0和1的样本 （不包括类别为2的样本）</span></span><br><span class=\"line\">data_target_part = data[data[<span class=\"string\">&#x27;Species&#x27;</span>].isin([<span class=\"number\">0</span>,<span class=\"number\">1</span>])][[<span class=\"string\">&#x27;Species&#x27;</span>]]</span><br><span class=\"line\">data_features_part = data[data[<span class=\"string\">&#x27;Species&#x27;</span>].isin([<span class=\"number\">0</span>,<span class=\"number\">1</span>])][[<span class=\"string\">&#x27;Culmen Length (mm)&#x27;</span>,</span><br><span class=\"line\">                                                        <span class=\"string\">&#x27;Culmen Depth (mm)&#x27;</span>,</span><br><span class=\"line\">            <span class=\"string\">&#x27;Flipper Length (mm)&#x27;</span>,<span class=\"string\">&#x27;Body Mass (g)&#x27;</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 测试集大小为20%， 80%/20%分</span></span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(data_features_part, data_target_part, </span><br><span class=\"line\">                                                    test_size = <span class=\"number\">0.2</span>, random_state = <span class=\"number\">2020</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 从sklearn中导入决策树模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"comment\">## 定义 决策树模型 </span></span><br><span class=\"line\">clf = DecisionTreeClassifier(criterion=<span class=\"string\">&#x27;entropy&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 在训练集上训练决策树模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>DecisionTreeClassifier(criterion='entropy')\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用训练好的模型进行预测</span></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> metrics</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵 (预测值和真实值的各类情况统计矩阵)</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>The accuracy of the Logistic Regression is: 0.9954545454545455\nThe accuracy of the Logistic Regression is: 1.0\nThe confusion matrix result:\n [[31  0]\n [ 0 25]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_33_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>我们可以发现其准确度为 1，代表所有的样本都预测正确了。</p>\n<ul>\n<li>Step6: 利用 决策树模型 在三分类 (多分类) 上 进行训练和预测</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 测试集大小为20%， 80%/20%分</span></span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(data[[<span class=\"string\">&#x27;Culmen Length (mm)&#x27;</span>,<span class=\"string\">&#x27;Culmen Depth (mm)&#x27;</span>,</span><br><span class=\"line\">            <span class=\"string\">&#x27;Flipper Length (mm)&#x27;</span>,<span class=\"string\">&#x27;Body Mass (g)&#x27;</span>]], data[[<span class=\"string\">&#x27;Species&#x27;</span>]], test_size = <span class=\"number\">0.2</span>, random_state = <span class=\"number\">2020</span>)</span><br><span class=\"line\"><span class=\"comment\">## 定义 决策树模型 </span></span><br><span class=\"line\">clf = DecisionTreeClassifier()</span><br><span class=\"line\"><span class=\"comment\"># 在训练集上训练决策树模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>DecisionTreeClassifier()\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用训练好的模型进行预测</span></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 由于决策树模型是概率预测模型（前文介绍的 p = p(y=1|x,\\theta)）,所有我们可以利用 predict_proba 函数预测其概率</span></span><br><span class=\"line\">train_predict_proba = clf.predict_proba(x_train)</span><br><span class=\"line\">test_predict_proba = clf.predict_proba(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The test predict Probability of each class:\\n&#x27;</span>,test_predict_proba)</span><br><span class=\"line\"><span class=\"comment\">## 其中第一列代表预测为0类的概率，第二列代表预测为1类的概率，第三列代表预测为2类的概率。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br></pre></td></tr></table></figure>\n<pre><code>The test predict Probability of each class:\n [[0. 0. 1.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [1. 0. 0.]]\nThe accuracy of the Logistic Regression is: 0.9963636363636363\nThe accuracy of the Logistic Regression is: 0.9710144927536232\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>The confusion matrix result:\n [[31  1  0]\n [ 0 23  0]\n [ 1  0 13]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_37_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<h2 id=\"24-重要知识点\"><a class=\"markdownIt-Anchor\" href=\"#24-重要知识点\">#</a> 2.4 重要知识点</h2>\n<h3 id=\"243-重要参数\"><a class=\"markdownIt-Anchor\" href=\"#243-重要参数\">#</a> 2.4.3 重要参数</h3>\n<h4 id=\"2431-criterion\"><a class=\"markdownIt-Anchor\" href=\"#2431-criterion\">#</a> 2.4.3.1 criterion</h4>\n<p>Criterion 这个参数正是用来决定模型特征选择的计算方法的。sklearn 提供了两种选择：</p>\n<p>输入”entropy“，使用信息熵（Entropy）</p>\n<p>输入”gini“，使用基尼系数（Gini Impurity）</p>\n<h4 id=\"2432-random_state-splitter\"><a class=\"markdownIt-Anchor\" href=\"#2432-random_state-splitter\">#</a> 2.4.3.2 random_state &amp; splitter</h4>\n<p>random_state 用来设置分枝中的随机模式的参数，默认 None，在高维度时随机性会表现更明显。splitter 也是用来控制决策树中的随机选项的，有两种输入值，输入”best&quot;，决策树在分枝时虽然随机，但是还是会优先选择更重要的特征进行分枝（重要性可以通过属性 feature_importances_查看），输入 “random&quot;，决策树在分枝时会更加随机，树会因为含有更多的不必要信息而更深更大，并因这些不必要信息而降低对训练集的拟合。</p>\n<h4 id=\"2433-max_depth\"><a class=\"markdownIt-Anchor\" href=\"#2433-max_depth\">#</a> 2.4.3.3 max_depth</h4>\n<p>限制树的最大深度，超过设定深度的树枝全部剪掉。这是用得最广泛的剪枝参数，在高维度低样本量时非常有效。决策树多生长一层，对样本量的需求会增加一倍，所以限制树深度能够有效地限制过拟合。</p>\n<h4 id=\"2434-min_samples_leaf\"><a class=\"markdownIt-Anchor\" href=\"#2434-min_samples_leaf\">#</a> 2.4.3.4 min_samples_leaf</h4>\n<p>min_samples_leaf 限定，一个节点在分枝后的每个子节点都必须包含至少 min_samples_leaf 个训练样本，否则分枝就不会发生，或者，分枝会朝着满足每个子节点都包含 min_samples_leaf 个样本的方向去发生。一般搭配 max_depth 使用，在回归树中有神奇的效果，可以让模型变得更加平滑。这个参数的数量设置得太小会引起过拟合，设置得太大就会阻止模型学习数据。</p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E7%B1%BB/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E7%B1%BB/",
            "title": "基于线性判别模型的分类",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"1前言lda算法简介和应用\"><a class=\"markdownIt-Anchor\" href=\"#1前言lda算法简介和应用\">#</a> 1. 前言：LDA 算法简介和应用</h1>\n<h2 id=\"11算法简介\"><a class=\"markdownIt-Anchor\" href=\"#11算法简介\">#</a> 1.1. 算法简介</h2>\n<p>线性判别模型（LDA）在模式识别领域（比如人脸识别等图形图像识别领域）中有非常广泛的应用。LDA 是一种监督学习的降维技术，也就是说它的数据集的每个样本是有类别输出的。这点和 PCA 不同。PCA 是不考虑样本类别输出的无监督降维技术。LDA 的思想可以用一句话概括，就是 “投影后类内方差最小，类间方差最大”。我们要将数据在低维度上进行投影，投影后希望每一种类别数据的投影点尽可能的接近，而不同类别的数据的类别中心之间的距离尽可能的大。即：将数据投影到维度更低的空间中，使得投影后的点，会形成按类别区分，一簇一簇的情况，相同类别的点，将会在投影后的空间中更接近方法。</p>\n<p>LDA 算法的主要优点：<br>\n1. 在降维过程中可以使用类别的先验知识经验，而像 PCA 这样的无监督学习则无法使用类别先验知识；<br>\n2.LDA 在样本分类信息依赖均值而不是方差的时候，比 PCA 之类的算法较优。</p>\n<p>LDA 算法的主要缺点：<br>\n1.LDA 不适合对非高斯分布样本进行降维，PCA 也有这个问题<br>\n 2.LDA 降维最多降到类别数 k-1 的维数，如果我们降维的维度大于 k-1，则不能使用 LDA。当然目前有一些 LDA 的进化版算法可以绕过这个问题<br>\n 3.LDA 在样本分类信息依赖方差而不是均值的时候，降维效果不好<br>\n 4.LDA 可能过度拟合数据，</p>\n<h2 id=\"12算法应用\"><a class=\"markdownIt-Anchor\" href=\"#12算法应用\">#</a> 1.2. 算法应用</h2>\n<p>LDA 在模式识别领域（比如人脸识别，舰艇识别等图形图像识别领域）中有非常广泛的应用，因此我们有必要了解一下它的算法原理。不过在学习 LDA 之前，我们有必要将其与自然语言处理领域中的 LDA 区分开，在自然语言处理领域，LDA 是隐含狄利克雷分布（Latent DIrichlet Allocation，简称 LDA），它是一种处理文档的主题模型，我们本文讨论的是线性判别分析，因此后面所说的 LDA 均为线性判别分析。</p>\n<p>LDA 除了可以用于降维以外，还可以用于分类。一个常见的 LDA 分类基本思想是假设各个类别的样本数据符合高斯分布，这样利用 LDA 进行投影后，可以利用极大似然估计计算各个类别投影数据的均值和方差，进而得到该类别高斯分布的概率密度函数。当一个新的样本到来后，我们可以将它投影，然后将投影后的样本特征分别带入各个类别的高斯分布概率密度函数，计算它属于这个类别的概率，最大的概率对应的类别即为预测类别。</p>\n<h1 id=\"2学习目标\"><a class=\"markdownIt-Anchor\" href=\"#2学习目标\">#</a> 2. 学习目标</h1>\n<ul>\n<li>掌握 LDA 算法基本原理</li>\n<li>掌握利用 LDA 进行代码实战</li>\n</ul>\n<h1 id=\"3代码流程\"><a class=\"markdownIt-Anchor\" href=\"#3代码流程\">#</a> 3. 代码流程</h1>\n<h3 id=\"part-1-demo实践\"><a class=\"markdownIt-Anchor\" href=\"#part-1-demo实践\">#</a> Part 1 Demo 实践</h3>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 模型训练</li>\n<li>Step3: 模型参数查看</li>\n<li>Step4: 数据和模型可视化</li>\n<li>Step5: 模型预测</li>\n</ul>\n<h3 id=\"part-2-基于lda手写数字分类实践\"><a class=\"markdownIt-Anchor\" href=\"#part-2-基于lda手写数字分类实践\">#</a> Part 2 基于 LDA 手写数字分类实践</h3>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 数据读取 / 载入</li>\n<li>Step3: 数据信息简单查看与可视化</li>\n<li>Step4: 利用 LDA 在手写数字上进行训练和预测</li>\n</ul>\n<h1 id=\"4代码实战\"><a class=\"markdownIt-Anchor\" href=\"#4代码实战\">#</a> 4. 代码实战</h1>\n<h2 id=\"41-demo实践\"><a class=\"markdownIt-Anchor\" href=\"#41-demo实践\">#</a> 4.1 Demo 实践</h2>\n<h4 id=\"step1库函数导入\"><a class=\"markdownIt-Anchor\" href=\"#step1库函数导入\">#</a> Step1: 库函数导入</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 基础数组运算库导入</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"><span class=\"comment\"># 画图库导入</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt </span><br><span class=\"line\"><span class=\"comment\"># 导入三维显示工具</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"><span class=\"comment\"># 导入LDA模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.discriminant_analysis <span class=\"keyword\">import</span> LinearDiscriminantAnalysis</span><br><span class=\"line\"><span class=\"comment\"># 导入demo数据制作方法</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_classification</span><br></pre></td></tr></table></figure>\n<h4 id=\"step2模型训练\"><a class=\"markdownIt-Anchor\" href=\"#step2模型训练\">#</a> Step2: 模型训练</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 制作四个类别的数据，每个类别100个样本</span></span><br><span class=\"line\">X, y = make_classification(n_samples=<span class=\"number\">1000</span>, n_features=<span class=\"number\">3</span>, n_redundant=<span class=\"number\">0</span>,</span><br><span class=\"line\">                           n_classes=<span class=\"number\">4</span>, n_informative=<span class=\"number\">2</span>, n_clusters_per_class=<span class=\"number\">1</span>,</span><br><span class=\"line\">                           class_sep=<span class=\"number\">3</span>, random_state=<span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># 将四个类别的数据进行三维显示</span></span><br><span class=\"line\">fig = plt.figure()</span><br><span class=\"line\">ax = Axes3D(fig, rect=[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], elev=<span class=\"number\">20</span>, azim=<span class=\"number\">20</span>)</span><br><span class=\"line\">ax.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], X[:, <span class=\"number\">2</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>, c=y)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n  import sys\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_3_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 建立 LDA 模型</span></span><br><span class=\"line\">lda = LinearDiscriminantAnalysis()</span><br><span class=\"line\"><span class=\"comment\"># 进行模型训练</span></span><br><span class=\"line\">lda.fit(X, y)</span><br></pre></td></tr></table></figure>\n<pre><code>LinearDiscriminantAnalysis()\n</code></pre>\n<h4 id=\"step3模型参数查看\"><a class=\"markdownIt-Anchor\" href=\"#step3模型参数查看\">#</a> Step3: 模型参数查看</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看 LDA 模型的参数</span></span><br><span class=\"line\">lda.get_params()</span><br></pre></td></tr></table></figure>\n<pre><code>&#123;'covariance_estimator': None,\n 'n_components': None,\n 'priors': None,\n 'shrinkage': None,\n 'solver': 'svd',\n 'store_covariance': False,\n 'tol': 0.0001&#125;\n</code></pre>\n<h4 id=\"step4数据和模型可视化\"><a class=\"markdownIt-Anchor\" href=\"#step4数据和模型可视化\">#</a> Step4: 数据和模型可视化</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行模型预测</span></span><br><span class=\"line\">X_new = lda.transform(X)</span><br><span class=\"line\"><span class=\"comment\"># 可视化预测数据</span></span><br><span class=\"line\">plt.scatter(X_new[:, <span class=\"number\">0</span>], X_new[:, <span class=\"number\">1</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>, c=y)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_8_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<h4 id=\"step5模型预测\"><a class=\"markdownIt-Anchor\" href=\"#step5模型预测\">#</a> Step5: 模型预测</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行新的测试数据测试</span></span><br><span class=\"line\">a = np.array([[-<span class=\"number\">1</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别是: &quot;</span>, lda.predict(a))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别概率分别是: &quot;</span>, lda.predict_proba(a))</span><br><span class=\"line\"></span><br><span class=\"line\">a = np.array([[-<span class=\"number\">12</span>, -<span class=\"number\">100</span>, -<span class=\"number\">91</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别是: &quot;</span>, lda.predict(a))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别概率分别是: &quot;</span>, lda.predict_proba(a))</span><br><span class=\"line\"></span><br><span class=\"line\">a = np.array([[-<span class=\"number\">12</span>, -<span class=\"number\">0.1</span>, -<span class=\"number\">0.1</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别是: &quot;</span>, lda.predict(a))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别概率分别是: &quot;</span>, lda.predict_proba(a))</span><br><span class=\"line\"></span><br><span class=\"line\">a = np.array([[<span class=\"number\">0.1</span>, <span class=\"number\">90.1</span>, <span class=\"number\">9.1</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别是: &quot;</span>, lda.predict(a))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;a&#125;</span> 类别概率分别是: &quot;</span>, lda.predict_proba(a))</span><br></pre></td></tr></table></figure>\n<pre><code>[[-1.   0.1  0.1]] 类别是:  [0]\n[[-1.   0.1  0.1]] 类别概率分别是:  [[9.37611354e-01 1.88760664e-05 3.36891510e-02 2.86806189e-02]]\n[[ -12 -100  -91]] 类别是:  [1]\n[[ -12 -100  -91]] 类别概率分别是:  [[1.08769337e-028 1.00000000e+000 1.54515810e-221 9.05666876e-183]]\n[[-12.   -0.1  -0.1]] 类别是:  [2]\n[[-12.   -0.1  -0.1]] 类别概率分别是:  [[1.60268201e-07 1.46912978e-39 9.99999840e-01 3.57001075e-28]]\n[[ 0.1 90.1  9.1]] 类别是:  [3]\n[[ 0.1 90.1  9.1]] 类别概率分别是:  [[8.42065614e-08 9.45021749e-11 8.63060269e-02 9.13693889e-01]]\n</code></pre>\n<h3 id=\"part-2-基于lda手写数字分类实践-2\"><a class=\"markdownIt-Anchor\" href=\"#part-2-基于lda手写数字分类实践-2\">#</a> Part 2 基于 LDA 手写数字分类实践 ¶</h3>\n<h4 id=\"step1库函数导入-2\"><a class=\"markdownIt-Anchor\" href=\"#step1库函数导入-2\">#</a> Step1: 库函数导入</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入手写数据集 MNIST</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_digits</span><br><span class=\"line\"><span class=\"comment\"># 导入训练集分割方法</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"comment\"># 导入LDA模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.discriminant_analysis <span class=\"keyword\">import</span> LinearDiscriminantAnalysis</span><br><span class=\"line\"><span class=\"comment\"># 导入预测指标计算函数和混淆矩阵计算函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report, confusion_matrix</span><br><span class=\"line\"><span class=\"comment\"># 导入绘图包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Step2: 数据读取 / 载入</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入MNIST数据集</span></span><br><span class=\"line\">mnist = load_digits()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看数据集信息</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The Mnist dataeset:\\n&#x27;</span>,mnist)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分割数据为训练集和测试集</span></span><br><span class=\"line\">x, test_x, y, test_y = train_test_split(mnist.data, mnist.target, </span><br><span class=\"line\">                                        test_size=<span class=\"number\">0.1</span>, random_state=<span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>The Mnist dataeset:\n &#123;'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n       ...,\n       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n        ...,\n        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n        ...,\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n        ...,\n        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n\n       ...,\n\n       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n        ...,\n        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n\n       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n        ...,\n        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n\n       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n        ...,\n        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': &quot;.. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n&quot;&#125;\n</code></pre>\n<ul>\n<li>Step3: 数据信息简单查看与可视化</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 输出示例图像</span></span><br><span class=\"line\">images = <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,<span class=\"number\">9</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(dpi=<span class=\"number\">100</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> images:</span><br><span class=\"line\">    plt.subplot(<span class=\"number\">330</span> + <span class=\"number\">1</span> + i)</span><br><span class=\"line\">    plt.imshow(x[i].reshape(<span class=\"number\">8</span>, <span class=\"number\">8</span>), cmap = matplotlib.cm.binary,interpolation=<span class=\"string\">&quot;nearest&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># show the plot</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_16_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<ul>\n<li>Step4: 利用 LDA 在手写数字上进行训练和预测</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 建立 LDA 模型</span></span><br><span class=\"line\">m_lda = LinearDiscriminantAnalysis()</span><br><span class=\"line\"><span class=\"comment\"># 进行模型训练</span></span><br><span class=\"line\">m_lda.fit(x, y)</span><br></pre></td></tr></table></figure>\n<pre><code>LinearDiscriminantAnalysis()\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行模型预测</span></span><br><span class=\"line\">x_new = m_lda.transform(x)</span><br><span class=\"line\"><span class=\"comment\"># 可视化预测数据</span></span><br><span class=\"line\">plt.scatter(x_new[:, <span class=\"number\">0</span>], x_new[:, <span class=\"number\">1</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>, c=y)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;MNIST with LDA Model&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_19_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行测试集数据的类别预测</span></span><br><span class=\"line\">y_test_pred = m_lda.predict(test_x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;测试集的真实标签:\\n&quot;</span>, test_y)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;测试集的预测标签:\\n&quot;</span>, y_test_pred)</span><br></pre></td></tr></table></figure>\n<pre><code>测试集的真实标签:\n [4 0 9 1 4 7 1 5 1 6 6 7 6 1 5 5 4 6 2 7 4 6 4 1 5 2 9 5 4 6 5 6 3 4 0 9 9\n 8 4 6 8 8 5 7 9 6 9 6 1 3 0 1 9 7 3 3 1 1 8 8 9 8 5 4 4 7 3 5 8 4 3 1 3 8\n 7 3 3 0 8 7 2 8 5 3 8 7 6 4 6 2 2 0 1 1 5 3 5 7 6 8 2 2 6 4 6 7 3 7 3 9 4\n 7 0 3 5 8 5 0 3 9 2 7 3 2 0 8 1 9 2 1 9 1 0 3 4 3 0 9 3 2 2 7 3 1 6 7 2 8\n 3 1 1 6 4 8 2 1 8 4 1 3 1 1 9 5 4 8 7 4 8 9 5 7 6 9 0 0 4 0 0 4]\n测试集的预测标签:\n [4 0 9 1 8 7 1 5 1 6 6 7 6 2 5 5 8 6 2 7 4 6 4 1 5 2 9 5 4 6 5 6 3 4 0 9 9\n 8 4 6 8 1 5 7 9 6 9 6 1 3 0 1 9 7 3 3 1 1 8 8 9 8 5 8 4 9 3 5 8 4 3 9 3 8\n 7 3 3 0 8 7 2 8 5 3 8 7 6 4 6 2 2 0 1 1 5 3 5 7 1 8 2 2 6 4 6 7 3 7 3 9 4\n 7 0 3 5 1 5 0 3 9 2 7 3 2 0 8 1 9 2 1 9 9 0 3 4 3 0 8 3 2 2 7 3 1 6 7 2 8\n 3 1 1 6 4 8 2 1 8 4 1 3 1 1 9 5 4 9 7 4 8 9 5 7 6 9 6 0 4 0 0 9]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行预测结果指标统计 统计每一类别的预测准确率、召回率、F1分数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(test_y, y_test_pred))</span><br></pre></td></tr></table></figure>\n<pre><code>              precision    recall  f1-score   support\n\n           0       1.00      0.93      0.96        14\n           1       0.86      0.86      0.86        22\n           2       0.93      1.00      0.97        14\n           3       1.00      1.00      1.00        22\n           4       1.00      0.81      0.89        21\n           5       1.00      1.00      1.00        16\n           6       0.94      0.94      0.94        18\n           7       1.00      0.94      0.97        18\n           8       0.80      0.84      0.82        19\n           9       0.75      0.94      0.83        16\n\n    accuracy                           0.92       180\n   macro avg       0.93      0.93      0.93       180\nweighted avg       0.93      0.92      0.92       180\n</code></pre>\n<p>​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算混淆矩阵</span></span><br><span class=\"line\">C2 = confusion_matrix(test_y, y_test_pred)</span><br><span class=\"line\"><span class=\"comment\"># 打混淆矩阵</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(C2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将混淆矩阵以热力图的防线显示</span></span><br><span class=\"line\">sns.<span class=\"built_in\">set</span>()</span><br><span class=\"line\">f, ax = plt.subplots()</span><br><span class=\"line\"><span class=\"comment\"># 画热力图</span></span><br><span class=\"line\">sns.heatmap(C2, cmap=<span class=\"string\">&quot;YlGnBu_r&quot;</span>, annot=<span class=\"literal\">True</span>, ax=ax)  </span><br><span class=\"line\"><span class=\"comment\"># 标题 </span></span><br><span class=\"line\">ax.set_title(<span class=\"string\">&#x27;confusion matrix&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># x轴为预测类别</span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;predict&#x27;</span>)  </span><br><span class=\"line\"><span class=\"comment\"># y轴实际类别</span></span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&#x27;true&#x27;</span>)  </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>[[13  0  0  0  0  0  1  0  0  0]\n [ 0 19  1  0  0  0  0  0  0  2]\n [ 0  0 14  0  0  0  0  0  0  0]\n [ 0  0  0 22  0  0  0  0  0  0]\n [ 0  0  0  0 17  0  0  0  3  1]\n [ 0  0  0  0  0 16  0  0  0  0]\n [ 0  1  0  0  0  0 17  0  0  0]\n [ 0  0  0  0  0  0  0 17  0  1]\n [ 0  2  0  0  0  0  0  0 16  1]\n [ 0  0  0  0  0  0  0  0  1 15]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_22_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<h1 id=\"5算法重要知识点\"><a class=\"markdownIt-Anchor\" href=\"#5算法重要知识点\">#</a> 5. 算法重要知识点</h1>\n<p>LDA 算法的一个目标是使得不同类别之间的距离越远越好，同一类别之中的距离越近越好。那么不同类别之间的距离越远越好，我们是可以理解的，就是越远越好区分。同时，协方差不仅是反映了变量之间的相关性，同样反映了多维样本分布的离散程度（一维样本使用方差），协方差越大（对于负相关来说是绝对值越大），表示数据的分布越分散。所以上面的 “欲使同类样例的投影点尽可能接近，可以让同类样本点的协方差矩阵尽可能小” 就可以理解了。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><msup><mi>w</mi><mi>T</mi></msup><msup><mrow><mi mathvariant=\"normal\">∣</mi><msub><mi>u</mi><mn>1</mn></msub><mo>−</mo><msub><mi>u</mi><mn>2</mn></msub><mi mathvariant=\"normal\">∣</mi></mrow><mn>2</mn></msup></mrow><mrow><msubsup><mi>s</mi><mn>1</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>s</mi><mn>2</mn><mn>2</mn></msubsup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">J(w) = \\frac{w^T{|u_1-u_2|}^2}{s_1^2+s_2^2}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.583316em;vertical-align:-0.9523079999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.631008em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.433692em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.26630799999999993em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.433692em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.26630799999999993em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954008em;\"><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9523079999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>如上述公式<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(w)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span></span></span></span> 所示，分子为投影数据后的均值只差，分母为方差之后，LDA 的目的就是使得 J 值最大化，那么可以理解为最大化分子，即使得类别之间的距离越远，同时最小化分母，使得每个类别内部的方差越小，这样就能使得每个类类别的数据可以在投影矩阵 w 的映射下，分的越开。</p>\n<p>需要注意的是，LDA 模型适用于线性可分数据，对于上述实战中用到的 MNIST 手写数据（其实是非线性的），但是依然可以取得较好的分类效果；但在以后的实战中需要注意 LDA 在非线性可分数据上的谨慎使用。</p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "title": "基于逻辑回归的分类预测",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"机器学习算法一-基于逻辑回归的分类预测\"><a class=\"markdownIt-Anchor\" href=\"#机器学习算法一-基于逻辑回归的分类预测\">#</a> 机器学习算法（一）: 基于逻辑回归的分类预测</h1>\n<h2 id=\"逻辑回归的介绍和应用\"><a class=\"markdownIt-Anchor\" href=\"#逻辑回归的介绍和应用\">#</a> 逻辑回归的介绍和应用</h2>\n<h3 id=\"11-逻辑回归的介绍\"><a class=\"markdownIt-Anchor\" href=\"#11-逻辑回归的介绍\">#</a> 1.1 逻辑回归的介绍</h3>\n<p>逻辑回归（Logistic regression，简称 LR）虽然其中带有 &quot;回归&quot; 两个字，但逻辑回归其实是一个分类模型，并且广泛应用于各个领域之中。虽然现在深度学习相对于这些传统方法更为火热，但实则这些传统方法由于其独特的优势依然广泛应用于各个领域中。</p>\n<p>而对于逻辑回归而且，最为突出的两点就是其模型简单和模型的可解释性强。</p>\n<p>逻辑回归模型的优劣势:</p>\n<ul>\n<li>优点：实现简单，易于理解和实现；计算代价不高，速度很快，存储资源低；</li>\n<li>缺点：容易欠拟合，分类精度可能不高</li>\n</ul>\n<h3 id=\"12-逻辑回归的应用\"><a class=\"markdownIt-Anchor\" href=\"#12-逻辑回归的应用\">#</a> 1.2 逻辑回归的应用</h3>\n<p>逻辑回归模型广泛用于各个领域，包括机器学习，大多数医学领域和社会科学。例如，最初由 Boyd 等人开发的创伤和损伤严重度评分（TRISS）被广泛用于预测受伤患者的死亡率，使用逻辑回归 基于观察到的患者特征（年龄，性别，体重指数，各种血液检查的结果等）分析预测发生特定疾病（例如糖尿病，冠心病）的风险。逻辑回归模型也用于预测在给定的过程中，系统或产品的故障的可能性。还用于市场营销应用程序，例如预测客户购买产品或中止订购的倾向等。在经济学中它可以用来预测一个人选择进入劳动力市场的可能性，而商业应用则可以用来预测房主拖欠抵押贷款的可能性。条件随机字段是逻辑回归到顺序数据的扩展，用于自然语言处理。</p>\n<p>逻辑回归模型现在同样是很多分类算法的基础组件，比如 分类任务中基于 GBDT 算法 + LR 逻辑回归实现的信用卡交易反欺诈，CTR (点击通过率) 预估等，其好处在于输出值自然地落在 0 到 1 之间，并且有概率意义。模型清晰，有对应的概率学理论基础。它拟合出来的参数就代表了每一个特征 (feature) 对结果的影响。也是一个理解数据的好工具。但同时由于其本质上是一个线性的分类器，所以不能应对较为复杂的数据情况。很多时候我们也会拿逻辑回归模型去做一些任务尝试的基线（基础水平）。</p>\n<p>说了这些逻辑回归的概念和应用，大家应该已经对其有所期待了吧，那么我们现在开始吧！！！</p>\n<h2 id=\"2-学习目标\"><a class=\"markdownIt-Anchor\" href=\"#2-学习目标\">#</a> 2 学习目标</h2>\n<ul>\n<li>了解 逻辑回归 的理论</li>\n<li>掌握 逻辑回归 的 sklearn 函数调用使用并将其运用到鸢尾花数据集预测</li>\n</ul>\n<h2 id=\"3-代码流程\"><a class=\"markdownIt-Anchor\" href=\"#3-代码流程\">#</a> 3 代码流程</h2>\n<p><strong>Part1 Demo 实践</strong></p>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 模型训练</li>\n<li>Step3: 模型参数查看</li>\n<li>Step4: 数据和模型可视化</li>\n<li>Step5: 模型预测</li>\n</ul>\n<p><strong>Part2 基于鸢尾花（iris）数据集的逻辑回归分类实践</strong></p>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 数据读取 / 载入</li>\n<li>Step3: 数据信息简单查看</li>\n<li>Step4: 可视化描述</li>\n<li>Step5: 利用 逻辑回归模型 在二分类上 进行训练和预测</li>\n<li>Step5: 利用 逻辑回归模型 在三分类 (多分类) 上 进行训练和预测</li>\n</ul>\n<h2 id=\"4-算法实战\"><a class=\"markdownIt-Anchor\" href=\"#4-算法实战\">#</a> 4 算法实战</h2>\n<h3 id=\"41-demo实践\"><a class=\"markdownIt-Anchor\" href=\"#41-demo实践\">#</a> 4.1 Demo 实践</h3>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##  基础函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 导入画图库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 导入逻辑回归模型函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br></pre></td></tr></table></figure>\n<p><strong>Step2: 模型训练</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##Demo演示LogisticRegression分类</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 构造数据集</span></span><br><span class=\"line\">x_fearures = np.array([[-<span class=\"number\">1</span>, -<span class=\"number\">2</span>], [-<span class=\"number\">2</span>, -<span class=\"number\">1</span>], [-<span class=\"number\">3</span>, -<span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">3</span>], [<span class=\"number\">2</span>, <span class=\"number\">1</span>], [<span class=\"number\">3</span>, <span class=\"number\">2</span>]])</span><br><span class=\"line\">y_label = np.array([<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 调用逻辑回归模型</span></span><br><span class=\"line\">lr_clf = LogisticRegression()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 用逻辑回归模型拟合构造的数据集</span></span><br><span class=\"line\">lr_clf = lr_clf.fit(x_fearures, y_label) <span class=\"comment\">#其拟合方程为 y=w0+w1*x1+w2*x2</span></span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 模型参数查看</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 查看其对应模型的w</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the weight of Logistic Regression:&#x27;</span>,lr_clf.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看其对应模型的w0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the intercept(w0) of Logistic Regression:&#x27;</span>,lr_clf.intercept_)</span><br></pre></td></tr></table></figure>\n<pre><code>the weight of Logistic Regression: [[0.73455784 0.69539712]]\nthe intercept(w0) of Logistic Regression: [-0.13139986]\n</code></pre>\n<p><strong>Step4: 数据和模型可视化</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 可视化构造的数据样本点</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x_fearures[:,<span class=\"number\">0</span>],x_fearures[:,<span class=\"number\">1</span>], c=y_label, s=<span class=\"number\">50</span>, cmap=<span class=\"string\">&#x27;viridis&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Dataset&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_7_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 可视化决策边界</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(x_fearures[:,<span class=\"number\">0</span>],x_fearures[:,<span class=\"number\">1</span>], c=y_label, s=<span class=\"number\">50</span>, cmap=<span class=\"string\">&#x27;viridis&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Dataset&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">nx, ny = <span class=\"number\">200</span>, <span class=\"number\">100</span></span><br><span class=\"line\">x_min, x_max = plt.xlim()</span><br><span class=\"line\">y_min, y_max = plt.ylim()</span><br><span class=\"line\">x_grid, y_grid = np.meshgrid(np.linspace(x_min, x_max, nx),np.linspace(y_min, y_max, ny))</span><br><span class=\"line\"></span><br><span class=\"line\">z_proba = lr_clf.predict_proba(np.c_[x_grid.ravel(), y_grid.ravel()])</span><br><span class=\"line\">z_proba = z_proba[:, <span class=\"number\">1</span>].reshape(x_grid.shape)</span><br><span class=\"line\">plt.contour(x_grid, y_grid, z_proba, [<span class=\"number\">0.5</span>], linewidths=<span class=\"number\">2.</span>, colors=<span class=\"string\">&#x27;blue&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_8_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 可视化预测新样本</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\"><span class=\"comment\">## new point 1</span></span><br><span class=\"line\">x_fearures_new1 = np.array([[<span class=\"number\">0</span>, -<span class=\"number\">1</span>]])</span><br><span class=\"line\">plt.scatter(x_fearures_new1[:,<span class=\"number\">0</span>],x_fearures_new1[:,<span class=\"number\">1</span>], s=<span class=\"number\">50</span>, cmap=<span class=\"string\">&#x27;viridis&#x27;</span>)</span><br><span class=\"line\">plt.annotate(s=<span class=\"string\">&#x27;New point 1&#x27;</span>,xy=(<span class=\"number\">0</span>,-<span class=\"number\">1</span>),xytext=(-<span class=\"number\">2</span>,<span class=\"number\">0</span>),color=<span class=\"string\">&#x27;blue&#x27;</span>,arrowprops=<span class=\"built_in\">dict</span>(arrowstyle=<span class=\"string\">&#x27;-|&gt;&#x27;</span>,connectionstyle=<span class=\"string\">&#x27;arc3&#x27;</span>,color=<span class=\"string\">&#x27;red&#x27;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## new point 2</span></span><br><span class=\"line\">x_fearures_new2 = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>]])</span><br><span class=\"line\">plt.scatter(x_fearures_new2[:,<span class=\"number\">0</span>],x_fearures_new2[:,<span class=\"number\">1</span>], s=<span class=\"number\">50</span>, cmap=<span class=\"string\">&#x27;viridis&#x27;</span>)</span><br><span class=\"line\">plt.annotate(s=<span class=\"string\">&#x27;New point 2&#x27;</span>,xy=(<span class=\"number\">1</span>,<span class=\"number\">2</span>),xytext=(-<span class=\"number\">1.5</span>,<span class=\"number\">2.5</span>),color=<span class=\"string\">&#x27;red&#x27;</span>,arrowprops=<span class=\"built_in\">dict</span>(arrowstyle=<span class=\"string\">&#x27;-|&gt;&#x27;</span>,connectionstyle=<span class=\"string\">&#x27;arc3&#x27;</span>,color=<span class=\"string\">&#x27;red&#x27;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 训练样本</span></span><br><span class=\"line\">plt.scatter(x_fearures[:,<span class=\"number\">0</span>],x_fearures[:,<span class=\"number\">1</span>], c=y_label, s=<span class=\"number\">50</span>, cmap=<span class=\"string\">&#x27;viridis&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Dataset&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化决策边界</span></span><br><span class=\"line\">plt.contour(x_grid, y_grid, z_proba, [<span class=\"number\">0.5</span>], linewidths=<span class=\"number\">2.</span>, colors=<span class=\"string\">&#x27;blue&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: MatplotlibDeprecationWarning: The 's' parameter of annotate() has been renamed 'text' since Matplotlib 3.3; support for the old name will be dropped two minor releases later.\n  import sys\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:12: MatplotlibDeprecationWarning: The 's' parameter of annotate() has been renamed 'text' since Matplotlib 3.3; support for the old name will be dropped two minor releases later.\n  if sys.path[0] == '':\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_9_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><strong>Step5: 模型预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分别利用训练好的模型进行预测</span></span><br><span class=\"line\">y_label_new1_predict = lr_clf.predict(x_fearures_new1)</span><br><span class=\"line\">y_label_new2_predict = lr_clf.predict(x_fearures_new2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The New point 1 predict class:\\n&#x27;</span>,y_label_new1_predict)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The New point 2 predict class:\\n&#x27;</span>,y_label_new2_predict)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 由于逻辑回归模型是概率预测模型（前文介绍的 p = p(y=1|x,\\theta)）,所以我们可以利用 predict_proba 函数预测其概率</span></span><br><span class=\"line\">y_label_new1_predict_proba = lr_clf.predict_proba(x_fearures_new1)</span><br><span class=\"line\">y_label_new2_predict_proba = lr_clf.predict_proba(x_fearures_new2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The New point 1 predict Probability of each class:\\n&#x27;</span>,y_label_new1_predict_proba)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The New point 2 predict Probability of each class:\\n&#x27;</span>,y_label_new2_predict_proba)</span><br></pre></td></tr></table></figure>\n<pre><code>The New point 1 predict class:\n [0]\nThe New point 2 predict class:\n [1]\nThe New point 1 predict Probability of each class:\n [[0.69567724 0.30432276]]\nThe New point 2 predict Probability of each class:\n [[0.11983936 0.88016064]]\n</code></pre>\n<h3 id=\"42-基于鸢尾花iris数据集的逻辑回归分类实践\"><a class=\"markdownIt-Anchor\" href=\"#42-基于鸢尾花iris数据集的逻辑回归分类实践\">#</a> 4.2 基于鸢尾花（iris）数据集的逻辑回归分类实践</h3>\n<p>在实践的最开始，我们首先需要导入一些基础的函数库包括：numpy （Python 进行科学计算的基础软件包），pandas（pandas 是一种快速，强大，灵活且易于使用的开源数据分析和处理工具），matplotlib 和 seaborn 绘图。</p>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##  基础函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 绘图函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br></pre></td></tr></table></figure>\n<p>本次我们选择鸢花数据（iris）进行方法的尝试训练，该数据集一共包含 5 个变量，其中 4 个特征变量，1 个目标分类变量。共有 150 个样本，目标变量为 花的类别 其都属于鸢尾属下的三个亚属，分别是山鸢尾 (Iris-setosa)，变色鸢尾 (Iris-versicolor) 和维吉尼亚鸢尾 (Iris-virginica)。包含的三种鸢尾花的四个特征，分别是花萼长度 (cm)、花萼宽度 (cm)、花瓣长度 (cm)、花瓣宽度 (cm)，这些形态特征在过去被用来识别物种。</p>\n<table>\n<thead>\n<tr>\n<th>变量</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>sepal length</td>\n<td>花萼长度 (cm)</td>\n</tr>\n<tr>\n<td>sepal width</td>\n<td>花萼宽度 (cm)</td>\n</tr>\n<tr>\n<td>petal length</td>\n<td>花瓣长度 (cm)</td>\n</tr>\n<tr>\n<td>petal width</td>\n<td>花瓣宽度 (cm)</td>\n</tr>\n<tr>\n<td>target</td>\n<td>鸢尾的三个亚属类别，‘setosa’(0), ‘versicolor’(1), ‘virginica’(2)</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Step2: 数据读取 / 载入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 我们利用 sklearn 中自带的 iris 数据作为数据载入，</span></span><br><span class=\"line\"><span class=\"comment\">#并利用Pandas转化为DataFrame格式</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\">data = load_iris() <span class=\"comment\">#得到数据特征</span></span><br><span class=\"line\">iris_target = data.target <span class=\"comment\">#得到数据对应的标签</span></span><br><span class=\"line\">iris_features = pd.DataFrame(data=data.data, columns=data.feature_names) </span><br><span class=\"line\"><span class=\"comment\">#利用Pandas转化为DataFrame格式</span></span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 数据信息简单查看</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 利用.info()查看数据的整体信息</span></span><br><span class=\"line\">iris_features.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 4 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   sepal length (cm)  150 non-null    float64\n 1   sepal width (cm)   150 non-null    float64\n 2   petal length (cm)  150 non-null    float64\n 3   petal width (cm)   150 non-null    float64\ndtypes: float64(4)\nmemory usage: 4.8 KB\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 进行简单的数据查看，我们可以利用 .head() 头部.tail()尾部</span></span><br><span class=\"line\">iris_features.head()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iris_features.tail()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 其对应的类别标签为，其中0，1，2分别代表&#x27;setosa&#x27;, &#x27;versicolor&#x27;, &#x27;virginica&#x27;三种不同花的类别。</span></span><br><span class=\"line\">iris_target</span><br></pre></td></tr></table></figure>\n<pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 利用value_counts函数查看每个类别数量</span></span><br><span class=\"line\">pd.Series(iris_target).value_counts()</span><br></pre></td></tr></table></figure>\n<pre><code>0    50\n1    50\n2    50\ndtype: int64\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 对于特征进行一些统计描述</span></span><br><span class=\"line\">iris_features.describe()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.057333</td>\n      <td>3.758000</td>\n      <td>1.199333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.435866</td>\n      <td>1.765298</td>\n      <td>0.762238</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>从统计描述中我们可以看到不同数值特征的变化范围。</p>\n<p><strong>Step4: 可视化描述</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 合并标签和特征信息</span></span><br><span class=\"line\">iris_all = iris_features.copy() <span class=\"comment\">##进行浅拷贝，防止对于原始数据的修改</span></span><br><span class=\"line\">iris_all[<span class=\"string\">&#x27;target&#x27;</span>] = iris_target</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 特征与标签组合的散点可视化</span></span><br><span class=\"line\">sns.pairplot(data=iris_all,diag_kind=<span class=\"string\">&#x27;hist&#x27;</span>, hue= <span class=\"string\">&#x27;target&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_26_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>从上图可以发现，在 2D 情况下不同的特征组合对于不同类别的花的散点分布，以及大概的区分能力。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> iris_features.columns:</span><br><span class=\"line\">    sns.boxplot(x=<span class=\"string\">&#x27;target&#x27;</span>, y=col, saturation=<span class=\"number\">0.5</span>,palette=<span class=\"string\">&#x27;pastel&#x27;</span>, data=iris_all)</span><br><span class=\"line\">    plt.title(col)</span><br><span class=\"line\">    plt.show()</span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_28_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_28_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_28_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_28_3.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>利用箱型图我们也可以得到不同类别在不同特征上的分布差异情况。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 选取其前三个特征绘制三维散点图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">8</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">&#x27;3d&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">iris_all_class0 = iris_all[iris_all[<span class=\"string\">&#x27;target&#x27;</span>]==<span class=\"number\">0</span>].values</span><br><span class=\"line\">iris_all_class1 = iris_all[iris_all[<span class=\"string\">&#x27;target&#x27;</span>]==<span class=\"number\">1</span>].values</span><br><span class=\"line\">iris_all_class2 = iris_all[iris_all[<span class=\"string\">&#x27;target&#x27;</span>]==<span class=\"number\">2</span>].values</span><br><span class=\"line\"><span class=\"comment\"># &#x27;setosa&#x27;(0), &#x27;versicolor&#x27;(1), &#x27;virginica&#x27;(2)</span></span><br><span class=\"line\">ax.scatter(iris_all_class0[:,<span class=\"number\">0</span>], iris_all_class0[:,<span class=\"number\">1</span>], iris_all_class0[:,<span class=\"number\">2</span>],label=<span class=\"string\">&#x27;setosa&#x27;</span>)</span><br><span class=\"line\">ax.scatter(iris_all_class1[:,<span class=\"number\">0</span>], iris_all_class1[:,<span class=\"number\">1</span>], iris_all_class1[:,<span class=\"number\">2</span>],label=<span class=\"string\">&#x27;versicolor&#x27;</span>)</span><br><span class=\"line\">ax.scatter(iris_all_class2[:,<span class=\"number\">0</span>], iris_all_class2[:,<span class=\"number\">1</span>], iris_all_class2[:,<span class=\"number\">2</span>],label=<span class=\"string\">&#x27;virginica&#x27;</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_30_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><strong>Step5: 利用 逻辑回归模型 在二分类上 进行训练和预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 为了正确评估模型性能，将数据划分为训练集和测试集，并在训练集上训练模型，在测试集上验证模型性能。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 选择其类别为0和1的样本 （不包括类别为2的样本）</span></span><br><span class=\"line\">iris_features_part = iris_features.iloc[:<span class=\"number\">100</span>]</span><br><span class=\"line\">iris_target_part = iris_target[:<span class=\"number\">100</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 测试集大小为20%， 80%/20%分</span></span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(iris_features_part, </span><br><span class=\"line\">                 iris_target_part, </span><br><span class=\"line\">                 test_size = <span class=\"number\">0.2</span>, </span><br><span class=\"line\">                 random_state = <span class=\"number\">2020</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 从sklearn中导入逻辑回归模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 定义 逻辑回归模型 </span></span><br><span class=\"line\">clf = LogisticRegression(random_state=<span class=\"number\">0</span>, solver=<span class=\"string\">&#x27;lbfgs&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在训练集上训练逻辑回归模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>LogisticRegression(random_state=0)\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 查看其对应的w</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the weight of Logistic Regression:&#x27;</span>,clf.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看其对应的w0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the intercept(w0) of Logistic Regression:&#x27;</span>,clf.intercept_)</span><br></pre></td></tr></table></figure>\n<pre><code>the weight of Logistic Regression: [[ 0.45181973 -0.81743611  2.14470304  0.89838607]]\nthe intercept(w0) of Logistic Regression: [-6.53367714]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用训练好的模型进行预测</span></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> metrics</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵 (预测值和真实值的各类情况统计矩阵)</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>The accuracy of the Logistic Regression is: 1.0\nThe accuracy of the Logistic Regression is: 1.0\nThe confusion matrix result:\n [[ 9  0]\n [ 0 11]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_38_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>我们可以发现其准确度为 1，代表所有的样本都预测正确了。</p>\n<p><strong>Step6: 利用 逻辑回归模型 在三分类 (多分类) 上 进行训练和预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 测试集大小为20%， 80%/20%分</span></span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(iris_features, </span><br><span class=\"line\">                                                    iris_target, test_size = <span class=\"number\">0.2</span>, </span><br><span class=\"line\">                                                    random_state = <span class=\"number\">2020</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 定义 逻辑回归模型 </span></span><br><span class=\"line\">clf = LogisticRegression(random_state=<span class=\"number\">0</span>, solver=<span class=\"string\">&#x27;lbfgs&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在训练集上训练逻辑回归模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>LogisticRegression(random_state=0)\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 查看其对应的w</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the weight of Logistic Regression:\\n&#x27;</span>,clf.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看其对应的w0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;the intercept(w0) of Logistic Regression:\\n&#x27;</span>,clf.intercept_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 由于这个是3分类，所有我们这里得到了三个逻辑回归模型的参数，其三个逻辑回归组合起来即可实现三分类。</span></span><br></pre></td></tr></table></figure>\n<pre><code>the weight of Logistic Regression:\n [[-0.45928925  0.83069887 -2.26606531 -0.99743981]\n [ 0.33117319 -0.72863424 -0.06841147 -0.9871103 ]\n [ 0.12811606 -0.10206464  2.33447678  1.98455011]]\nthe intercept(w0) of Logistic Regression:\n [  9.4388067    3.93047364 -13.36928034]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用训练好的模型进行预测</span></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 由于逻辑回归模型是概率预测模型（前文介绍的 p = p(y=1|x,\\theta)）,所有我们可以利用 predict_proba 函数预测其概率</span></span><br><span class=\"line\">train_predict_proba = clf.predict_proba(x_train)</span><br><span class=\"line\">test_predict_proba = clf.predict_proba(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The test predict Probability of each class:\\n&#x27;</span>,test_predict_proba)</span><br><span class=\"line\"><span class=\"comment\">## 其中第一列代表预测为0类的概率，第二列代表预测为1类的概率，第三列代表预测为2类的概率。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br></pre></td></tr></table></figure>\n<pre><code>The test predict Probability of each class:\n [[1.03461737e-05 2.33279477e-02 9.76661706e-01]\n [9.69926591e-01 3.00732874e-02 1.21677000e-07]\n [2.09992549e-02 8.69156616e-01 1.09844129e-01]\n [3.61934872e-03 7.91979966e-01 2.04400686e-01]\n [7.90943209e-03 8.00605299e-01 1.91485269e-01]\n [7.30034956e-04 6.60508053e-01 3.38761912e-01]\n [1.68614211e-04 1.86322045e-01 8.13509341e-01]\n [1.06915331e-01 8.90815532e-01 2.26913671e-03]\n [9.46928071e-01 5.30707288e-02 1.20016060e-06]\n [9.62346385e-01 3.76532228e-02 3.91897297e-07]\n [1.19533386e-04 1.38823469e-01 8.61056998e-01]\n [8.78881880e-03 6.97207359e-01 2.94003822e-01]\n [9.73938143e-01 2.60617342e-02 1.22613839e-07]\n [1.78434056e-03 4.79518177e-01 5.18697483e-01]\n [5.56924345e-04 2.46776840e-01 7.52666235e-01]\n [9.83549842e-01 1.64500666e-02 9.13617272e-08]\n [1.65201476e-02 9.54672748e-01 2.88071041e-02]\n [8.99853722e-03 7.82707575e-01 2.08293888e-01]\n [2.98015029e-05 5.45900069e-02 9.45380192e-01]\n [9.35695863e-01 6.43039522e-02 1.85301368e-07]\n [9.80621190e-01 1.93787398e-02 7.00125265e-08]\n [1.68478817e-04 3.30167227e-01 6.69664294e-01]\n [3.54046168e-03 4.02267804e-01 5.94191734e-01]\n [9.70617284e-01 2.93824735e-02 2.42443971e-07]\n [2.56895209e-04 1.54631583e-01 8.45111521e-01]\n [3.48668493e-02 9.11966140e-01 5.31670110e-02]\n [1.47218849e-02 6.84038113e-01 3.01240002e-01]\n [9.46510460e-04 4.28641987e-01 5.70411502e-01]\n [9.64848137e-01 3.51516747e-02 1.87917886e-07]\n [9.70436779e-01 2.95624021e-02 8.18591621e-07]]\nThe accuracy of the Logistic Regression is: 0.9833333333333333\nThe accuracy of the Logistic Regression is: 0.8666666666666667\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>The confusion matrix result:\n [[10  0  0]\n [ 0  8  2]\n [ 0  2  8]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_45_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<h2 id=\"重要知识点\"><a class=\"markdownIt-Anchor\" href=\"#重要知识点\">#</a> 重要知识点</h2>\n<p>逻辑回归 原理简介：</p>\n<p>Logistic 回归虽然名字里带 “回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别），所以利用了 Logistic 函数（或称为 Sigmoid 函数），函数形式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mn>2</mn></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">log(z) = \\frac {1}{1+e^{-2}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.09077em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>其对应的函数图像可以表示如下:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">x = np.arange(-<span class=\"number\">5</span>,<span class=\"number\">5</span>,<span class=\"number\">0.01</span>)</span><br><span class=\"line\">y = <span class=\"number\">1</span>/(<span class=\"number\">1</span>+np.exp(-x))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(x,y)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;z&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;y&#x27;</span>)</span><br><span class=\"line\">plt.grid()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_47_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p x_i=\"\">通过上图我们可以发现 Logistic 函数是单调递增函数，并且在 z=0 的时候取值为 0.5，并且 logi (⋅) 函数的取值范围为 (0,1)。<br>\n而回归的基本方程为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mn>0</mn></msub><mo>+</mo><msubsup><mo>∑</mo><mi>i</mi><mi>N</mi></msubsup><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">z=w_0+\\sum_{i}^N{w_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2809409999999999em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>将回归方程写入其中为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>p</mi><mo>=</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo>=</mo><mn>1</mn><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>θ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>θ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mn>0</mn></msub><mo>+</mo><munderover><mo>∑</mo><mi>i</mi><mi>N</mi></munderover><mrow><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">p=p(y=1|x,\\theta)=h_\\theta(x,\\theta)=\\frac{1}{1+e^{-(w_0+\\sum_i^N{w_ix_i})}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.247192em;vertical-align:-0.9257520000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.157578em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9524220000000001em;\"><span style=\"top:-3.0327570000000006em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-left:-0.02691em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mop mtight\"><span class=\"mop op-symbol small-op mtight\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8852357142857143em;\"><span style=\"top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-2.8971428571428572em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32143857142857146em;\"><span></span></span></span></span></span></span><span class=\"mspace mtight\" style=\"margin-right:0.19516666666666668em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.02691em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9257520000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>所以，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo>=</mo><mn>1</mn><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>θ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">p(y=1|x,\\theta)=h_\\theta(x,\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>,<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo>=</mo><mn>0</mn><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>θ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">p(y=0|x,\\theta)=1-h_\\theta(x,\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">0</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>逻辑回归从其原理上来说，逻辑回归其实是实现了一个决策边界：对于函数<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">y=\\frac1{1+e^{-z}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2484389999999999em;vertical-align:-0.403331em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7026642857142857em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>, 当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mo>=</mo><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">z =&gt; 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> 时，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">y =&gt; 0.5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">5</span></span></span></span>, 分类为 1，当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">z &lt; 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> 时，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>&lt;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">y &lt; 0.5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335400000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">5</span></span></span></span>, 分类为 0，其对应的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span> 值我们可以视为类别 1 的概率预测值.</p>\n<p>对于模型的训练而言：实质上来说就是利用数据求解出对应的模型的特定的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span></span></span></span>。从而得到一个针对于当前数据的特征逻辑回归模型。</p>\n<p>而对于多分类而言，将多个二分类的逻辑回归组合，即可实现多分类。</p>\n<p>END</p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/BP/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B(%E9%AD%8F)/BP/",
            "title": "BP神经网络",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow <span class=\"keyword\">import</span> keras</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy.io <span class=\"keyword\">as</span> sio</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fashion_mnist=sio.loadmat(<span class=\"string\">&#x27;fashion_mnist.mat&#x27;</span>)</span><br><span class=\"line\">train_img=fashion_mnist[<span class=\"string\">&#x27;train&#x27;</span>]</span><br><span class=\"line\">train_imglabels=fashion_mnist[<span class=\"string\">&#x27;trainlabels&#x27;</span>]</span><br><span class=\"line\">test_img=fashion_mnist[<span class=\"string\">&#x27;test&#x27;</span>]</span><br><span class=\"line\">test_imglabels=fashion_mnist[<span class=\"string\">&#x27;testlabels&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">input1=keras.layers.Input(shape=train_img.shape[<span class=\"number\">1</span>:])</span><br><span class=\"line\">hidden1=keras.layers.Dense(<span class=\"number\">100</span>,activation=<span class=\"string\">&quot;tanh&quot;</span>)(input1)</span><br><span class=\"line\">hidden2=keras.layers.Dense(<span class=\"number\">120</span>,activation=<span class=\"string\">&quot;tanh&quot;</span>)(hidden1)</span><br><span class=\"line\">concat=keras.layers.Concatenate()([input1,hidden2])</span><br><span class=\"line\">output=keras.layers.Dense(<span class=\"number\">10</span>,activation=<span class=\"string\">&quot;softmax&quot;</span>)(concat)</span><br><span class=\"line\">model=keras.Model(inputs=[input1],outputs=[output])</span><br><span class=\"line\"></span><br><span class=\"line\">model.<span class=\"built_in\">compile</span>(loss=<span class=\"string\">&quot;sparse_categorical_crossentropy&quot;</span>,optimizer=keras.optimizers.SGD(lr=<span class=\"number\">0.005</span>),metrics=[<span class=\"string\">&#x27;accuracy&#x27;</span>])</span><br><span class=\"line\">x_valid,x_train=train_img[:<span class=\"number\">5000</span>]/<span class=\"number\">255</span>,train_img[<span class=\"number\">5000</span>:]/<span class=\"number\">255</span></span><br><span class=\"line\">y_valid,y_train=train_imglabels[:<span class=\"number\">5000</span>],train_imglabels[<span class=\"number\">5000</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">model.fit(x_train,y_train,batch_size=<span class=\"number\">2500</span>,epochs=<span class=\"number\">100</span>,validation_data=(x_valid,y_valid),verbose=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>WARNING:tensorflow:From c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nTrain on 55000 samples, validate on 5000 samples\nEpoch 1/100\n55000/55000 [==============================] - 3s 46us/sample - loss: 2.2687 - acc: 0.1840 - val_loss: 2.0692 - val_acc: 0.2996\nEpoch 2/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.9678 - acc: 0.3960 - val_loss: 1.8557 - val_acc: 0.4844\nEpoch 3/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.7842 - acc: 0.5295 - val_loss: 1.6939 - val_acc: 0.5776\nEpoch 4/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.6412 - acc: 0.5905 - val_loss: 1.5654 - val_acc: 0.6198\nEpoch 5/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.5266 - acc: 0.6213 - val_loss: 1.4618 - val_acc: 0.6430\nEpoch 6/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.4337 - acc: 0.6395 - val_loss: 1.3775 - val_acc: 0.6570\nEpoch 7/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.3572 - acc: 0.6528 - val_loss: 1.3078 - val_acc: 0.6666\nEpoch 8/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.2934 - acc: 0.6628 - val_loss: 1.2492 - val_acc: 0.6752\nEpoch 9/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.2395 - acc: 0.6706 - val_loss: 1.1996 - val_acc: 0.6824\nEpoch 10/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.1935 - acc: 0.6769 - val_loss: 1.1571 - val_acc: 0.6874\nEpoch 11/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.1537 - acc: 0.6833 - val_loss: 1.1201 - val_acc: 0.6924\nEpoch 12/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.1190 - acc: 0.6876 - val_loss: 1.0877 - val_acc: 0.6988\nEpoch 13/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.0885 - acc: 0.6928 - val_loss: 1.0591 - val_acc: 0.7032\nEpoch 14/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.0614 - acc: 0.6970 - val_loss: 1.0337 - val_acc: 0.7074\nEpoch 15/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.0372 - acc: 0.7007 - val_loss: 1.0109 - val_acc: 0.7110\nEpoch 16/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 1.0154 - acc: 0.7045 - val_loss: 0.9903 - val_acc: 0.7146\nEpoch 17/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.9957 - acc: 0.7075 - val_loss: 0.9716 - val_acc: 0.7184\nEpoch 18/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.9777 - acc: 0.7114 - val_loss: 0.9546 - val_acc: 0.7220\nEpoch 19/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.9613 - acc: 0.7147 - val_loss: 0.9390 - val_acc: 0.7248\nEpoch 20/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.9462 - acc: 0.7171 - val_loss: 0.9246 - val_acc: 0.7268\nEpoch 21/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.9323 - acc: 0.7196 - val_loss: 0.9113 - val_acc: 0.7296\nEpoch 22/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.9194 - acc: 0.7229 - val_loss: 0.8990 - val_acc: 0.7320\nEpoch 23/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.9073 - acc: 0.7255 - val_loss: 0.8875 - val_acc: 0.7338\nEpoch 24/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8961 - acc: 0.7285 - val_loss: 0.8767 - val_acc: 0.7366\nEpoch 25/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8856 - acc: 0.7301 - val_loss: 0.8665 - val_acc: 0.7400\nEpoch 26/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8757 - acc: 0.7328 - val_loss: 0.8570 - val_acc: 0.7432\nEpoch 27/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8664 - acc: 0.7349 - val_loss: 0.8480 - val_acc: 0.7456\nEpoch 28/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8576 - acc: 0.7374 - val_loss: 0.8396 - val_acc: 0.7476\nEpoch 29/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8493 - acc: 0.7391 - val_loss: 0.8315 - val_acc: 0.7498\nEpoch 30/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8413 - acc: 0.7415 - val_loss: 0.8239 - val_acc: 0.7516\nEpoch 31/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8338 - acc: 0.7430 - val_loss: 0.8166 - val_acc: 0.7524\nEpoch 32/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8266 - acc: 0.7444 - val_loss: 0.8097 - val_acc: 0.7544\nEpoch 33/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8198 - acc: 0.7457 - val_loss: 0.8030 - val_acc: 0.7562\nEpoch 34/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8132 - acc: 0.7475 - val_loss: 0.7966 - val_acc: 0.7580\nEpoch 35/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8069 - acc: 0.7493 - val_loss: 0.7906 - val_acc: 0.7582\nEpoch 36/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.8009 - acc: 0.7509 - val_loss: 0.7847 - val_acc: 0.7604\nEpoch 37/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7951 - acc: 0.7519 - val_loss: 0.7791 - val_acc: 0.7608\nEpoch 38/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7896 - acc: 0.7535 - val_loss: 0.7737 - val_acc: 0.7638\nEpoch 39/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7842 - acc: 0.7550 - val_loss: 0.7684 - val_acc: 0.7650\nEpoch 40/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7790 - acc: 0.7564 - val_loss: 0.7634 - val_acc: 0.7660\nEpoch 41/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7740 - acc: 0.7574 - val_loss: 0.7585 - val_acc: 0.7676\nEpoch 42/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7692 - acc: 0.7592 - val_loss: 0.7538 - val_acc: 0.7684\nEpoch 43/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7645 - acc: 0.7607 - val_loss: 0.7493 - val_acc: 0.7696\nEpoch 44/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7600 - acc: 0.7619 - val_loss: 0.7449 - val_acc: 0.7714\nEpoch 45/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7556 - acc: 0.7634 - val_loss: 0.7406 - val_acc: 0.7738\nEpoch 46/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7514 - acc: 0.7646 - val_loss: 0.7365 - val_acc: 0.7750\nEpoch 47/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7472 - acc: 0.7656 - val_loss: 0.7324 - val_acc: 0.7758\nEpoch 48/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7432 - acc: 0.7671 - val_loss: 0.7286 - val_acc: 0.7770\nEpoch 49/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7393 - acc: 0.7678 - val_loss: 0.7247 - val_acc: 0.7784\nEpoch 50/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7355 - acc: 0.7697 - val_loss: 0.7210 - val_acc: 0.7792\nEpoch 51/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7319 - acc: 0.7702 - val_loss: 0.7174 - val_acc: 0.7802\nEpoch 52/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7283 - acc: 0.7711 - val_loss: 0.7139 - val_acc: 0.7812\nEpoch 53/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7248 - acc: 0.7726 - val_loss: 0.7105 - val_acc: 0.7816\nEpoch 54/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7213 - acc: 0.7733 - val_loss: 0.7072 - val_acc: 0.7820\nEpoch 55/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7180 - acc: 0.7739 - val_loss: 0.7039 - val_acc: 0.7828\nEpoch 56/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7148 - acc: 0.7749 - val_loss: 0.7007 - val_acc: 0.7830\nEpoch 57/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7116 - acc: 0.7755 - val_loss: 0.6976 - val_acc: 0.7840\nEpoch 58/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7085 - acc: 0.7766 - val_loss: 0.6946 - val_acc: 0.7840\nEpoch 59/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7054 - acc: 0.7775 - val_loss: 0.6917 - val_acc: 0.7846\nEpoch 60/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.7025 - acc: 0.7783 - val_loss: 0.6888 - val_acc: 0.7858\nEpoch 61/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6996 - acc: 0.7792 - val_loss: 0.6860 - val_acc: 0.7860\nEpoch 62/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6967 - acc: 0.7801 - val_loss: 0.6831 - val_acc: 0.7874\nEpoch 63/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6940 - acc: 0.7806 - val_loss: 0.6804 - val_acc: 0.7874\nEpoch 64/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6913 - acc: 0.7816 - val_loss: 0.6778 - val_acc: 0.7896\nEpoch 65/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6886 - acc: 0.7821 - val_loss: 0.6752 - val_acc: 0.7900\nEpoch 66/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6860 - acc: 0.7827 - val_loss: 0.6726 - val_acc: 0.7908\nEpoch 67/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6834 - acc: 0.7835 - val_loss: 0.6701 - val_acc: 0.7916\nEpoch 68/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6809 - acc: 0.7839 - val_loss: 0.6676 - val_acc: 0.7918\nEpoch 69/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6785 - acc: 0.7844 - val_loss: 0.6652 - val_acc: 0.7934\nEpoch 70/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6760 - acc: 0.7853 - val_loss: 0.6629 - val_acc: 0.7932\nEpoch 71/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6737 - acc: 0.7859 - val_loss: 0.6606 - val_acc: 0.7942\nEpoch 72/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6713 - acc: 0.7860 - val_loss: 0.6583 - val_acc: 0.7942\nEpoch 73/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6691 - acc: 0.7869 - val_loss: 0.6560 - val_acc: 0.7950\nEpoch 74/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6668 - acc: 0.7873 - val_loss: 0.6539 - val_acc: 0.7956\nEpoch 75/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6646 - acc: 0.7878 - val_loss: 0.6517 - val_acc: 0.7958\nEpoch 76/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6625 - acc: 0.7886 - val_loss: 0.6495 - val_acc: 0.7960\nEpoch 77/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6603 - acc: 0.7890 - val_loss: 0.6475 - val_acc: 0.7970\nEpoch 78/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6582 - acc: 0.7898 - val_loss: 0.6454 - val_acc: 0.7974\nEpoch 79/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6562 - acc: 0.7902 - val_loss: 0.6434 - val_acc: 0.7980\nEpoch 80/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6542 - acc: 0.7908 - val_loss: 0.6414 - val_acc: 0.7982\nEpoch 81/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6522 - acc: 0.7912 - val_loss: 0.6395 - val_acc: 0.7998\nEpoch 82/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6502 - acc: 0.7916 - val_loss: 0.6376 - val_acc: 0.7996\nEpoch 83/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6483 - acc: 0.7920 - val_loss: 0.6357 - val_acc: 0.8002\nEpoch 84/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6464 - acc: 0.7925 - val_loss: 0.6339 - val_acc: 0.8010\nEpoch 85/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6445 - acc: 0.7929 - val_loss: 0.6320 - val_acc: 0.8010\nEpoch 86/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6427 - acc: 0.7935 - val_loss: 0.6302 - val_acc: 0.8016\nEpoch 87/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6409 - acc: 0.7937 - val_loss: 0.6284 - val_acc: 0.8014\nEpoch 88/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6391 - acc: 0.7940 - val_loss: 0.6267 - val_acc: 0.8020\nEpoch 89/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6374 - acc: 0.7945 - val_loss: 0.6250 - val_acc: 0.8022\nEpoch 90/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6356 - acc: 0.7946 - val_loss: 0.6233 - val_acc: 0.8032\nEpoch 91/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6340 - acc: 0.7953 - val_loss: 0.6217 - val_acc: 0.8040\nEpoch 92/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6323 - acc: 0.7957 - val_loss: 0.6199 - val_acc: 0.8050\nEpoch 93/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6306 - acc: 0.7962 - val_loss: 0.6183 - val_acc: 0.8056\nEpoch 94/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6290 - acc: 0.7963 - val_loss: 0.6168 - val_acc: 0.8056\nEpoch 95/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6274 - acc: 0.7969 - val_loss: 0.6152 - val_acc: 0.8056\nEpoch 96/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6258 - acc: 0.7974 - val_loss: 0.6137 - val_acc: 0.8064\nEpoch 97/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6242 - acc: 0.7978 - val_loss: 0.6121 - val_acc: 0.8066\nEpoch 98/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6227 - acc: 0.7986 - val_loss: 0.6106 - val_acc: 0.8068\nEpoch 99/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6212 - acc: 0.7985 - val_loss: 0.6091 - val_acc: 0.8080\nEpoch 100/100\n55000/55000 [==============================] - 2s 44us/sample - loss: 0.6197 - acc: 0.7992 - val_loss: 0.6077 - val_acc: 0.8074\n\n\n\n\n\n&lt;tensorflow.python.keras.callbacks.History at 0x16f1a0a3a20&gt;\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8ELightGBM%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8ELightGBM%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "title": "基于LightGBM的分类预测",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"1-基于lightgbm的分类预测\"><a class=\"markdownIt-Anchor\" href=\"#1-基于lightgbm的分类预测\">#</a> 1. 基于 LightGBM 的分类预测</h1>\n<h2 id=\"11-lightgbm的介绍\"><a class=\"markdownIt-Anchor\" href=\"#11-lightgbm的介绍\">#</a> 1.1 LightGBM 的介绍</h2>\n<p>LightGBM 是 2017 年由微软推出的可扩展机器学习系统，是微软旗下 DMKT 的一个开源项目，由 2014 年首届阿里巴巴大数据竞赛获胜者之一柯国霖老师带领开发。它是一款基于 GBDT（梯度提升决策树）算法的分布式梯度提升框架，为了满足缩短模型计算时间的需求，LightGBM 的设计思路主要集中在减小数据对内存与计算性能的使用，以及减少多机器并行计算时的通讯代价。</p>\n<p>LightGBM 可以看作是 XGBoost 的升级豪华版，在获得与 XGBoost 近似精度的同时，又提供了更快的训练速度与更少的内存消耗。正如其名字中的 Light 所蕴含的那样，LightGBM 在大规模数据集上跑起来更加优雅轻盈，一经推出便成为各种数据竞赛中刷榜夺冠的神兵利器。</p>\n<p>LightGBM 的主要优点：</p>\n<ol>\n<li>简单易用。提供了主流的 Python\\C++\\R 语言接口，用户可以轻松使用 LightGBM 建模并获得相当不错的效果。</li>\n<li>高效可扩展。在处理大规模数据集时高效迅速、高准确度，对内存等硬件资源要求不高。</li>\n<li>鲁棒性强。相较于深度学习模型不需要精细调参便能取得近似的效果。</li>\n<li>LightGBM 直接支持缺失值与类别特征，无需对数据额外进行特殊处理</li>\n</ol>\n<p>LightGBM 的主要缺点：</p>\n<ol>\n<li>相对于深度学习模型无法对时空位置建模，不能很好地捕获图像、语音、文本等高维数据。</li>\n<li>在拥有海量训练数据，并能找到合适的深度学习模型时，深度学习的精度可以遥遥领先 LightGBM。</li>\n</ol>\n<h2 id=\"12-lightgbm的应用\"><a class=\"markdownIt-Anchor\" href=\"#12-lightgbm的应用\">#</a> 1.2 LightGBM 的应用</h2>\n<p>LightGBM 在机器学习与数据挖掘领域有着极为广泛的应用。据统计 LightGBM 模型自 2016 到 2019 年在 Kaggle 平台上累积获得数据竞赛前三名三十余次，其中包括 CIKM2017 AnalytiCup、IEEE Fraud Detection 等知名竞赛。这些竞赛来源于各行各业的真实业务，这些竞赛成绩表明 LightGBM 具有很好的可扩展性，在各类不同问题上都可以取得非常好的效果。</p>\n<p>同时，LightGBM 还被成功应用在工业界与学术界的各种问题中。例如金融风控、购买行为识别、交通流量预测、环境声音分类、基因分类、生物成分分析等诸多领域。虽然领域相关的数据分析和特性工程在这些解决方案中也发挥了重要作用，但学习者与实践者对 LightGBM 的一致选择表明了这一软件包的影响力与重要性。</p>\n<h1 id=\"2-实验室手册\"><a class=\"markdownIt-Anchor\" href=\"#2-实验室手册\">#</a> 2. 实验室手册</h1>\n<h2 id=\"21-学习目标\"><a class=\"markdownIt-Anchor\" href=\"#21-学习目标\">#</a> 2.1 学习目标</h2>\n<ul>\n<li>了解 LightGBM 的参数与相关知识</li>\n<li>掌握 LightGBM 的 Python 调用并将其运用到英雄联盟游戏胜负预测数据集上</li>\n</ul>\n<h2 id=\"22-代码流程\"><a class=\"markdownIt-Anchor\" href=\"#22-代码流程\">#</a> 2.2 代码流程</h2>\n<h4 id=\"part1-基于英雄联盟数据集的lightgbm分类实践\"><a class=\"markdownIt-Anchor\" href=\"#part1-基于英雄联盟数据集的lightgbm分类实践\">#</a> Part1 基于英雄联盟数据集的 LightGBM 分类实践</h4>\n<p><strong>Step1: 库函数导入</strong></p>\n<p><strong>Step2: 数据读取 / 载入</strong></p>\n<p><strong>Step3: 数据信息简单查看</strong></p>\n<p><strong>Step4: 可视化描述</strong></p>\n<p><strong>Step5: 利用 LightGBM 进行训练与预测</strong></p>\n<p><strong>Step6: 利用 LightGBM 进行特征选择</strong></p>\n<p><strong>Step7: 通过调整参数获得更好的效果</strong></p>\n<h2 id=\"23-算法实战\"><a class=\"markdownIt-Anchor\" href=\"#23-算法实战\">#</a> 2.3 算法实战</h2>\n<h3 id=\"231-基于英雄联盟数据集的lightgbm分类实战\"><a class=\"markdownIt-Anchor\" href=\"#231-基于英雄联盟数据集的lightgbm分类实战\">#</a> 2.3.1 基于英雄联盟数据集的 LightGBM 分类实战</h3>\n<p>在实践的最开始，我们首先需要导入一些基础的函数库包括：numpy （Python 进行科学计算的基础软件包），pandas（pandas 是一种快速，强大，灵活且易于使用的开源数据分析和处理工具），matplotlib 和 seaborn 绘图。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#下载需要用到的数据集</span></span><br><span class=\"line\">!wget https://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/8LightGBM/high_diamond_ranked_10min.csv</span><br></pre></td></tr></table></figure>\n<pre><code>'wget' 不是内部或外部命令，也不是可运行的程序\n或批处理文件。\n</code></pre>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##  基础函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 绘图函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br></pre></td></tr></table></figure>\n<p>本次我们选择英雄联盟数据集进行 LightGBM 的场景体验。英雄联盟是 2009 年美国拳头游戏开发的 MOBA 竞技网游，在每局比赛中蓝队与红队在同一个地图进行作战，游戏的目标是破坏敌方队伍的防御塔，进而摧毁敌方的水晶枢纽，拿下比赛的胜利。</p>\n<p>现在共有 9881 场英雄联盟韩服钻石段位以上的排位比赛数据，数据提供了在十分钟时的游戏状态，包括击杀数、死亡数、金币数量、经验值、等级…… 等信息。列 blueWins 是数据的标签，代表了本场比赛是否为蓝队获胜。</p>\n<p>数据的各个特征描述如下：</p>\n<table>\n<thead>\n<tr>\n<th>特征名称</th>\n<th>特征意义</th>\n<th>取值范围</th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>WardsPlaced</td>\n<td>插眼数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>WardsDestroyed</td>\n<td>拆眼数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>FirstBlood</td>\n<td>是否获得首次击杀</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Kills</td>\n<td>击杀英雄数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Deaths</td>\n<td>死亡数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Assists</td>\n<td>助攻数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>EliteMonsters</td>\n<td>击杀大型野怪数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Dragons</td>\n<td>击杀史诗野怪数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Heralds</td>\n<td>击杀峡谷先锋数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>TowersDestroyed</td>\n<td>推塔数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>TotalGold</td>\n<td>总经济</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>AvgLevel</td>\n<td>平均英雄等级</td>\n<td>浮点数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>TotalExperience</td>\n<td>英雄总经验</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>TotalMinionsKilled</td>\n<td>英雄补兵数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>TotalJungleMinionsKilled</td>\n<td>英雄击杀野怪数量</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>GoldDiff</td>\n<td>经济差距</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ExperienceDiff</td>\n<td>经验差距</td>\n<td>整数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>CSPerMin</td>\n<td>分均补刀</td>\n<td>浮点数</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>GoldPerMin</td>\n<td>分均经济</td>\n<td>浮点数</td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p><strong>Step2: 数据读取 / 载入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 我们利用Pandas自带的read_csv函数读取并转化为DataFrame格式</span></span><br><span class=\"line\"></span><br><span class=\"line\">df = pd.read_csv(<span class=\"string\">&#x27;./high_diamond_ranked_10min.csv&#x27;</span>)</span><br><span class=\"line\">y = df.blueWins</span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 数据信息简单查看</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 利用.info()查看数据的整体信息</span></span><br><span class=\"line\">df.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 9879 entries, 0 to 9878\nData columns (total 40 columns):\n #   Column                        Non-Null Count  Dtype  \n---  ------                        --------------  -----  \n 0   gameId                        9879 non-null   int64  \n 1   blueWins                      9879 non-null   int64  \n 2   blueWardsPlaced               9879 non-null   int64  \n 3   blueWardsDestroyed            9879 non-null   int64  \n 4   blueFirstBlood                9879 non-null   int64  \n 5   blueKills                     9879 non-null   int64  \n 6   blueDeaths                    9879 non-null   int64  \n 7   blueAssists                   9879 non-null   int64  \n 8   blueEliteMonsters             9879 non-null   int64  \n 9   blueDragons                   9879 non-null   int64  \n 10  blueHeralds                   9879 non-null   int64  \n 11  blueTowersDestroyed           9879 non-null   int64  \n 12  blueTotalGold                 9879 non-null   int64  \n 13  blueAvgLevel                  9879 non-null   float64\n 14  blueTotalExperience           9879 non-null   int64  \n 15  blueTotalMinionsKilled        9879 non-null   int64  \n 16  blueTotalJungleMinionsKilled  9879 non-null   int64  \n 17  blueGoldDiff                  9879 non-null   int64  \n 18  blueExperienceDiff            9879 non-null   int64  \n 19  blueCSPerMin                  9879 non-null   float64\n 20  blueGoldPerMin                9879 non-null   float64\n 21  redWardsPlaced                9879 non-null   int64  \n 22  redWardsDestroyed             9879 non-null   int64  \n 23  redFirstBlood                 9879 non-null   int64  \n 24  redKills                      9879 non-null   int64  \n 25  redDeaths                     9879 non-null   int64  \n 26  redAssists                    9879 non-null   int64  \n 27  redEliteMonsters              9879 non-null   int64  \n 28  redDragons                    9879 non-null   int64  \n 29  redHeralds                    9879 non-null   int64  \n 30  redTowersDestroyed            9879 non-null   int64  \n 31  redTotalGold                  9879 non-null   int64  \n 32  redAvgLevel                   9879 non-null   float64\n 33  redTotalExperience            9879 non-null   int64  \n 34  redTotalMinionsKilled         9879 non-null   int64  \n 35  redTotalJungleMinionsKilled   9879 non-null   int64  \n 36  redGoldDiff                   9879 non-null   int64  \n 37  redExperienceDiff             9879 non-null   int64  \n 38  redCSPerMin                   9879 non-null   float64\n 39  redGoldPerMin                 9879 non-null   float64\ndtypes: float64(6), int64(34)\nmemory usage: 3.0 MB\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 进行简单的数据查看，我们可以利用 .head() 头部.tail()尾部</span></span><br><span class=\"line\">df.head()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameId</th>\n      <th>blueWins</th>\n      <th>blueWardsPlaced</th>\n      <th>blueWardsDestroyed</th>\n      <th>blueFirstBlood</th>\n      <th>blueKills</th>\n      <th>blueDeaths</th>\n      <th>blueAssists</th>\n      <th>blueEliteMonsters</th>\n      <th>blueDragons</th>\n      <th>...</th>\n      <th>redTowersDestroyed</th>\n      <th>redTotalGold</th>\n      <th>redAvgLevel</th>\n      <th>redTotalExperience</th>\n      <th>redTotalMinionsKilled</th>\n      <th>redTotalJungleMinionsKilled</th>\n      <th>redGoldDiff</th>\n      <th>redExperienceDiff</th>\n      <th>redCSPerMin</th>\n      <th>redGoldPerMin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4519157822</td>\n      <td>0</td>\n      <td>28</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16567</td>\n      <td>6.8</td>\n      <td>17047</td>\n      <td>197</td>\n      <td>55</td>\n      <td>-643</td>\n      <td>8</td>\n      <td>19.7</td>\n      <td>1656.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4523371949</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>17620</td>\n      <td>6.8</td>\n      <td>17438</td>\n      <td>240</td>\n      <td>52</td>\n      <td>2908</td>\n      <td>1173</td>\n      <td>24.0</td>\n      <td>1762.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4521474530</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>11</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>17285</td>\n      <td>6.8</td>\n      <td>17254</td>\n      <td>203</td>\n      <td>28</td>\n      <td>1172</td>\n      <td>1033</td>\n      <td>20.3</td>\n      <td>1728.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4524384067</td>\n      <td>0</td>\n      <td>43</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16478</td>\n      <td>7.0</td>\n      <td>17961</td>\n      <td>235</td>\n      <td>47</td>\n      <td>1321</td>\n      <td>7</td>\n      <td>23.5</td>\n      <td>1647.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4436033771</td>\n      <td>0</td>\n      <td>75</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>17404</td>\n      <td>7.0</td>\n      <td>18313</td>\n      <td>225</td>\n      <td>67</td>\n      <td>1004</td>\n      <td>-230</td>\n      <td>22.5</td>\n      <td>1740.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df.tail()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameId</th>\n      <th>blueWins</th>\n      <th>blueWardsPlaced</th>\n      <th>blueWardsDestroyed</th>\n      <th>blueFirstBlood</th>\n      <th>blueKills</th>\n      <th>blueDeaths</th>\n      <th>blueAssists</th>\n      <th>blueEliteMonsters</th>\n      <th>blueDragons</th>\n      <th>...</th>\n      <th>redTowersDestroyed</th>\n      <th>redTotalGold</th>\n      <th>redAvgLevel</th>\n      <th>redTotalExperience</th>\n      <th>redTotalMinionsKilled</th>\n      <th>redTotalJungleMinionsKilled</th>\n      <th>redGoldDiff</th>\n      <th>redExperienceDiff</th>\n      <th>redCSPerMin</th>\n      <th>redGoldPerMin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9874</th>\n      <td>4527873286</td>\n      <td>1</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>15246</td>\n      <td>6.8</td>\n      <td>16498</td>\n      <td>229</td>\n      <td>34</td>\n      <td>-2519</td>\n      <td>-2469</td>\n      <td>22.9</td>\n      <td>1524.6</td>\n    </tr>\n    <tr>\n      <th>9875</th>\n      <td>4527797466</td>\n      <td>1</td>\n      <td>54</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>15456</td>\n      <td>7.0</td>\n      <td>18367</td>\n      <td>206</td>\n      <td>56</td>\n      <td>-782</td>\n      <td>-888</td>\n      <td>20.6</td>\n      <td>1545.6</td>\n    </tr>\n    <tr>\n      <th>9876</th>\n      <td>4527713716</td>\n      <td>0</td>\n      <td>23</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>18319</td>\n      <td>7.4</td>\n      <td>19909</td>\n      <td>261</td>\n      <td>60</td>\n      <td>2416</td>\n      <td>1877</td>\n      <td>26.1</td>\n      <td>1831.9</td>\n    </tr>\n    <tr>\n      <th>9877</th>\n      <td>4527628313</td>\n      <td>0</td>\n      <td>14</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>15298</td>\n      <td>7.2</td>\n      <td>18314</td>\n      <td>247</td>\n      <td>40</td>\n      <td>839</td>\n      <td>1085</td>\n      <td>24.7</td>\n      <td>1529.8</td>\n    </tr>\n    <tr>\n      <th>9878</th>\n      <td>4523772935</td>\n      <td>1</td>\n      <td>18</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>15339</td>\n      <td>6.8</td>\n      <td>17379</td>\n      <td>201</td>\n      <td>46</td>\n      <td>-927</td>\n      <td>58</td>\n      <td>20.1</td>\n      <td>1533.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 标注标签并利用value_counts函数查看训练集标签的数量</span></span><br><span class=\"line\">y = df.blueWins</span><br><span class=\"line\">y.value_counts()</span><br></pre></td></tr></table></figure>\n<pre><code>0    4949\n1    4930\nName: blueWins, dtype: int64\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 标注特征列</span></span><br><span class=\"line\">drop_cols = [<span class=\"string\">&#x27;gameId&#x27;</span>,<span class=\"string\">&#x27;blueWins&#x27;</span>]</span><br><span class=\"line\">x = df.drop(drop_cols, axis=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 对于特征进行一些统计描述</span></span><br><span class=\"line\">x.describe()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>blueWardsPlaced</th>\n      <th>blueWardsDestroyed</th>\n      <th>blueFirstBlood</th>\n      <th>blueKills</th>\n      <th>blueDeaths</th>\n      <th>blueAssists</th>\n      <th>blueEliteMonsters</th>\n      <th>blueDragons</th>\n      <th>blueHeralds</th>\n      <th>blueTowersDestroyed</th>\n      <th>...</th>\n      <th>redTowersDestroyed</th>\n      <th>redTotalGold</th>\n      <th>redAvgLevel</th>\n      <th>redTotalExperience</th>\n      <th>redTotalMinionsKilled</th>\n      <th>redTotalJungleMinionsKilled</th>\n      <th>redGoldDiff</th>\n      <th>redExperienceDiff</th>\n      <th>redCSPerMin</th>\n      <th>redGoldPerMin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>...</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>22.288288</td>\n      <td>2.824881</td>\n      <td>0.504808</td>\n      <td>6.183925</td>\n      <td>6.137666</td>\n      <td>6.645106</td>\n      <td>0.549954</td>\n      <td>0.361980</td>\n      <td>0.187974</td>\n      <td>0.051422</td>\n      <td>...</td>\n      <td>0.043021</td>\n      <td>16489.041401</td>\n      <td>6.925316</td>\n      <td>17961.730438</td>\n      <td>217.349226</td>\n      <td>51.313088</td>\n      <td>-14.414111</td>\n      <td>33.620306</td>\n      <td>21.734923</td>\n      <td>1648.904140</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>18.019177</td>\n      <td>2.174998</td>\n      <td>0.500002</td>\n      <td>3.011028</td>\n      <td>2.933818</td>\n      <td>4.064520</td>\n      <td>0.625527</td>\n      <td>0.480597</td>\n      <td>0.390712</td>\n      <td>0.244369</td>\n      <td>...</td>\n      <td>0.216900</td>\n      <td>1490.888406</td>\n      <td>0.305311</td>\n      <td>1198.583912</td>\n      <td>21.911668</td>\n      <td>10.027885</td>\n      <td>2453.349179</td>\n      <td>1920.370438</td>\n      <td>2.191167</td>\n      <td>149.088841</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>11212.000000</td>\n      <td>4.800000</td>\n      <td>10465.000000</td>\n      <td>107.000000</td>\n      <td>4.000000</td>\n      <td>-11467.000000</td>\n      <td>-8348.000000</td>\n      <td>10.700000</td>\n      <td>1121.200000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>14.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>15427.500000</td>\n      <td>6.800000</td>\n      <td>17209.500000</td>\n      <td>203.000000</td>\n      <td>44.000000</td>\n      <td>-1596.000000</td>\n      <td>-1212.000000</td>\n      <td>20.300000</td>\n      <td>1542.750000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>16.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>16378.000000</td>\n      <td>7.000000</td>\n      <td>17974.000000</td>\n      <td>218.000000</td>\n      <td>51.000000</td>\n      <td>-14.000000</td>\n      <td>28.000000</td>\n      <td>21.800000</td>\n      <td>1637.800000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>20.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>17418.500000</td>\n      <td>7.200000</td>\n      <td>18764.500000</td>\n      <td>233.000000</td>\n      <td>57.000000</td>\n      <td>1585.500000</td>\n      <td>1290.500000</td>\n      <td>23.300000</td>\n      <td>1741.850000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>250.000000</td>\n      <td>27.000000</td>\n      <td>1.000000</td>\n      <td>22.000000</td>\n      <td>22.000000</td>\n      <td>29.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>22732.000000</td>\n      <td>8.200000</td>\n      <td>22269.000000</td>\n      <td>289.000000</td>\n      <td>92.000000</td>\n      <td>10830.000000</td>\n      <td>9333.000000</td>\n      <td>28.900000</td>\n      <td>2273.200000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 38 columns</p>\n</div>\n<ul>\n<li>我们发现不同对局中插眼数和拆眼数的取值范围存在明显差距，甚至有前十分钟插了 250 个眼的异常值。</li>\n<li>我们发现 EliteMonsters 的取值相当于 Deagons + Heralds。</li>\n<li>我们发现 TotalGold 等变量在大部分对局中差距不大。</li>\n<li>我们发现两支队伍的经济差和经验差是相反数。</li>\n<li>我们发现红队和蓝队拿到首次击杀的概率大概都是 50%</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 根据上面的描述，我们可以去除一些重复变量，比如只要知道蓝队是否拿到一血，我们就知道红队有没有拿到，可以去除红队的相关冗余数据。</span></span><br><span class=\"line\">drop_cols = [<span class=\"string\">&#x27;redFirstBlood&#x27;</span>,<span class=\"string\">&#x27;redKills&#x27;</span>,<span class=\"string\">&#x27;redDeaths&#x27;</span></span><br><span class=\"line\">             ,<span class=\"string\">&#x27;redGoldDiff&#x27;</span>,<span class=\"string\">&#x27;redExperienceDiff&#x27;</span>, <span class=\"string\">&#x27;blueCSPerMin&#x27;</span>,</span><br><span class=\"line\">            <span class=\"string\">&#x27;blueGoldPerMin&#x27;</span>,<span class=\"string\">&#x27;redCSPerMin&#x27;</span>,<span class=\"string\">&#x27;redGoldPerMin&#x27;</span>]</span><br><span class=\"line\">x.drop(drop_cols, axis=<span class=\"number\">1</span>, inplace=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<p><strong>Step4: 可视化描述</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = x</span><br><span class=\"line\">data_std = (data - data.mean()) / data.std()</span><br><span class=\"line\">data = pd.concat([y, data_std.iloc[:, <span class=\"number\">0</span>:<span class=\"number\">9</span>]], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">data = pd.melt(data, id_vars=<span class=\"string\">&#x27;blueWins&#x27;</span>, var_name=<span class=\"string\">&#x27;Features&#x27;</span>, value_name=<span class=\"string\">&#x27;Values&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(<span class=\"number\">1</span>,<span class=\"number\">2</span>,figsize=(<span class=\"number\">15</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制小提琴图</span></span><br><span class=\"line\">sns.violinplot(x=<span class=\"string\">&#x27;Features&#x27;</span>, y=<span class=\"string\">&#x27;Values&#x27;</span>, hue=<span class=\"string\">&#x27;blueWins&#x27;</span>, data=data, split=<span class=\"literal\">True</span>,</span><br><span class=\"line\">               inner=<span class=\"string\">&#x27;quart&#x27;</span>, ax=ax[<span class=\"number\">0</span>], palette=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">fig.autofmt_xdate(rotation=<span class=\"number\">45</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">data = x</span><br><span class=\"line\">data_std = (data - data.mean()) / data.std()</span><br><span class=\"line\">data = pd.concat([y, data_std.iloc[:, <span class=\"number\">9</span>:<span class=\"number\">18</span>]], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">data = pd.melt(data, id_vars=<span class=\"string\">&#x27;blueWins&#x27;</span>, var_name=<span class=\"string\">&#x27;Features&#x27;</span>, value_name=<span class=\"string\">&#x27;Values&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制小提琴图</span></span><br><span class=\"line\">sns.violinplot(x=<span class=\"string\">&#x27;Features&#x27;</span>, y=<span class=\"string\">&#x27;Values&#x27;</span>, hue=<span class=\"string\">&#x27;blueWins&#x27;</span>, </span><br><span class=\"line\">               data=data, split=<span class=\"literal\">True</span>, inner=<span class=\"string\">&#x27;quart&#x27;</span>, ax=ax[<span class=\"number\">1</span>], palette=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">fig.autofmt_xdate(rotation=<span class=\"number\">45</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_16_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>提琴图 (Violin Plot) 是用来展示多组数据的分布状态以及概率密度。这种图表结合了箱形图和密度图的特征，主要用来显示数据的分布形状。</p>\n<p>从图中我们可以看出：</p>\n<ul>\n<li>击杀英雄数量越多更容易赢，死亡数量越多越容易输（bluekills 与 bluedeaths 左右的区别）。</li>\n<li>助攻数量与击杀英雄数量形成的图形状类似，说明他们对游戏结果的影响差不多。</li>\n<li>一血的取得情况与获胜有正相关，但是相关性不如击杀英雄数量明显。</li>\n<li>经济差与经验差对于游戏胜负的影响较小。</li>\n<li>击杀野怪数量对游戏胜负的影响并不大。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">18</span>,<span class=\"number\">14</span>))</span><br><span class=\"line\">sns.heatmap(<span class=\"built_in\">round</span>(x.corr(),<span class=\"number\">2</span>), cmap=<span class=\"string\">&#x27;Blues&#x27;</span>, annot=<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_18_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>同时我们画出各个特征之间的相关性热力图，颜色越深代表特征之间相关性越强，我们剔除那些相关性较强的冗余特征。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 去除冗余特征</span></span><br><span class=\"line\">drop_cols = [<span class=\"string\">&#x27;redAvgLevel&#x27;</span>,<span class=\"string\">&#x27;blueAvgLevel&#x27;</span>]</span><br><span class=\"line\">x.drop(drop_cols, axis=<span class=\"number\">1</span>, inplace=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sns.<span class=\"built_in\">set</span>(style=<span class=\"string\">&#x27;whitegrid&#x27;</span>, palette=<span class=\"string\">&#x27;muted&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 构造两个新特征</span></span><br><span class=\"line\">x[<span class=\"string\">&#x27;wardsPlacedDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueWardsPlaced&#x27;</span>] - x[<span class=\"string\">&#x27;redWardsPlaced&#x27;</span>]</span><br><span class=\"line\">x[<span class=\"string\">&#x27;wardsDestroyedDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueWardsDestroyed&#x27;</span>] - x[<span class=\"string\">&#x27;redWardsDestroyed&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">data = x[[<span class=\"string\">&#x27;blueWardsPlaced&#x27;</span>,<span class=\"string\">&#x27;blueWardsDestroyed&#x27;</span>,<span class=\"string\">&#x27;wardsPlacedDiff&#x27;</span>,<span class=\"string\">&#x27;wardsDestroyedDiff&#x27;</span>]].sample(<span class=\"number\">1000</span>)</span><br><span class=\"line\">data_std = (data - data.mean()) / data.std()</span><br><span class=\"line\">data = pd.concat([y, data_std], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">data = pd.melt(data, id_vars=<span class=\"string\">&#x27;blueWins&#x27;</span>, var_name=<span class=\"string\">&#x27;Features&#x27;</span>, value_name=<span class=\"string\">&#x27;Values&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">6</span>))</span><br><span class=\"line\">sns.swarmplot(x=<span class=\"string\">&#x27;Features&#x27;</span>, y=<span class=\"string\">&#x27;Values&#x27;</span>, hue=<span class=\"string\">&#x27;blueWins&#x27;</span>, data=data)</span><br><span class=\"line\">plt.xticks(rotation=<span class=\"number\">45</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 7.8% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 8.2% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 6.7% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 7.7% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_21_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>我们画出了插眼数量的散点图，发现不存在插眼数量与游戏胜负间的显著规律。猜测由于钻石分段以上在哪插眼在哪好排眼都是套路，所以数据中前十分钟插眼数拔眼数对游戏的影响不大。所以我们暂时先把这些特征去掉。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 去除和眼位相关的特征</span></span><br><span class=\"line\">drop_cols = [<span class=\"string\">&#x27;blueWardsPlaced&#x27;</span>,<span class=\"string\">&#x27;blueWardsDestroyed&#x27;</span>,<span class=\"string\">&#x27;wardsPlacedDiff&#x27;</span>,</span><br><span class=\"line\">            <span class=\"string\">&#x27;wardsDestroyedDiff&#x27;</span>,<span class=\"string\">&#x27;redWardsPlaced&#x27;</span>,<span class=\"string\">&#x27;redWardsDestroyed&#x27;</span>]</span><br><span class=\"line\">x.drop(drop_cols, axis=<span class=\"number\">1</span>, inplace=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x[<span class=\"string\">&#x27;killsDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueKills&#x27;</span>] - x[<span class=\"string\">&#x27;blueDeaths&#x27;</span>]</span><br><span class=\"line\">x[<span class=\"string\">&#x27;assistsDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueAssists&#x27;</span>] - x[<span class=\"string\">&#x27;redAssists&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">x[[<span class=\"string\">&#x27;blueKills&#x27;</span>,<span class=\"string\">&#x27;blueDeaths&#x27;</span>,<span class=\"string\">&#x27;blueAssists&#x27;</span>,<span class=\"string\">&#x27;killsDiff&#x27;</span>,<span class=\"string\">&#x27;assistsDiff&#x27;</span>,<span class=\"string\">&#x27;redAssists&#x27;</span>]].hist(figsize=(<span class=\"number\">12</span>,<span class=\"number\">10</span>), bins=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:400: MatplotlibDeprecationWarning: \nThe is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n  if ax.is_first_col():\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_24_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>我们发现击杀、死亡与助攻数的数据分布差别不大。但是击杀减去死亡、助攻减去死亡的分布与原分布差别很大，因此我们新构造这么两个特征。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = x[[<span class=\"string\">&#x27;blueKills&#x27;</span>,<span class=\"string\">&#x27;blueDeaths&#x27;</span>,<span class=\"string\">&#x27;blueAssists&#x27;</span>,<span class=\"string\">&#x27;killsDiff&#x27;</span>,<span class=\"string\">&#x27;assistsDiff&#x27;</span>,<span class=\"string\">&#x27;redAssists&#x27;</span>]].sample(<span class=\"number\">1000</span>)</span><br><span class=\"line\">data_std = (data - data.mean()) / data.std()</span><br><span class=\"line\">data = pd.concat([y, data_std], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">data = pd.melt(data, id_vars=<span class=\"string\">&#x27;blueWins&#x27;</span>, var_name=<span class=\"string\">&#x27;Features&#x27;</span>, value_name=<span class=\"string\">&#x27;Values&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">6</span>))</span><br><span class=\"line\">sns.swarmplot(x=<span class=\"string\">&#x27;Features&#x27;</span>, y=<span class=\"string\">&#x27;Values&#x27;</span>, hue=<span class=\"string\">&#x27;blueWins&#x27;</span>, data=data)</span><br><span class=\"line\">plt.xticks(rotation=<span class=\"number\">45</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 7.9% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 8.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 7.5% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 7.1% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 6.2% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 7.4% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_26_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>从上图我们可以发现击杀数与死亡数与助攻数，以及我们构造的特征对数据都有较好的分类能力。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = pd.concat([y, x], axis=<span class=\"number\">1</span>).sample(<span class=\"number\">500</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">sns.pairplot(data, <span class=\"built_in\">vars</span>=[<span class=\"string\">&#x27;blueKills&#x27;</span>,<span class=\"string\">&#x27;blueDeaths&#x27;</span>,<span class=\"string\">&#x27;blueAssists&#x27;</span>,<span class=\"string\">&#x27;killsDiff&#x27;</span>,<span class=\"string\">&#x27;assistsDiff&#x27;</span>,<span class=\"string\">&#x27;redAssists&#x27;</span>], </span><br><span class=\"line\">             hue=<span class=\"string\">&#x27;blueWins&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_28_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>一些特征两两组合后对于数据的划分能力也有提升。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x[<span class=\"string\">&#x27;dragonsDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueDragons&#x27;</span>] - x[<span class=\"string\">&#x27;redDragons&#x27;</span>]</span><br><span class=\"line\">x[<span class=\"string\">&#x27;heraldsDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueHeralds&#x27;</span>] - x[<span class=\"string\">&#x27;redHeralds&#x27;</span>]</span><br><span class=\"line\">x[<span class=\"string\">&#x27;eliteDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueEliteMonsters&#x27;</span>] - x[<span class=\"string\">&#x27;redEliteMonsters&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">data = pd.concat([y, x], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">eliteGroup = data.groupby([<span class=\"string\">&#x27;eliteDiff&#x27;</span>])[<span class=\"string\">&#x27;blueWins&#x27;</span>].mean()</span><br><span class=\"line\">dragonGroup = data.groupby([<span class=\"string\">&#x27;dragonsDiff&#x27;</span>])[<span class=\"string\">&#x27;blueWins&#x27;</span>].mean()</span><br><span class=\"line\">heraldGroup = data.groupby([<span class=\"string\">&#x27;heraldsDiff&#x27;</span>])[<span class=\"string\">&#x27;blueWins&#x27;</span>].mean()</span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(<span class=\"number\">1</span>,<span class=\"number\">3</span>, figsize=(<span class=\"number\">15</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">eliteGroup.plot(kind=<span class=\"string\">&#x27;bar&#x27;</span>, ax=ax[<span class=\"number\">0</span>])</span><br><span class=\"line\">dragonGroup.plot(kind=<span class=\"string\">&#x27;bar&#x27;</span>, ax=ax[<span class=\"number\">1</span>])</span><br><span class=\"line\">heraldGroup.plot(kind=<span class=\"string\">&#x27;bar&#x27;</span>, ax=ax[<span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(eliteGroup)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dragonGroup)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(heraldGroup)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:400: MatplotlibDeprecationWarning: \nThe is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n  if ax.is_first_col():\n\n\neliteDiff\n-2    0.286301\n-1    0.368772\n 0    0.500683\n 1    0.632093\n 2    0.735211\nName: blueWins, dtype: float64\ndragonsDiff\n-1    0.374173\n 0    0.500000\n 1    0.640940\nName: blueWins, dtype: float64\nheraldsDiff\n-1    0.387729\n 0    0.498680\n 1    0.595046\nName: blueWins, dtype: float64\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_30_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>我们构造了两队之间是否拿到龙、是否拿到峡谷先锋、击杀大型野怪的数量差值，发现在游戏的前期拿到龙比拿到峡谷先锋更容易获得胜利。拿到大型野怪的数量和胜率也存在着强相关。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x[<span class=\"string\">&#x27;towerDiff&#x27;</span>] = x[<span class=\"string\">&#x27;blueTowersDestroyed&#x27;</span>] - x[<span class=\"string\">&#x27;redTowersDestroyed&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">data = pd.concat([y, x], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">towerGroup = data.groupby([<span class=\"string\">&#x27;towerDiff&#x27;</span>])[<span class=\"string\">&#x27;blueWins&#x27;</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(towerGroup.count())</span><br><span class=\"line\"><span class=\"built_in\">print</span>(towerGroup.mean())</span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(<span class=\"number\">1</span>,<span class=\"number\">2</span>,figsize=(<span class=\"number\">15</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">towerGroup.mean().plot(kind=<span class=\"string\">&#x27;line&#x27;</span>, ax=ax[<span class=\"number\">0</span>])</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_title(<span class=\"string\">&#x27;Proportion of Blue Wins&#x27;</span>)</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">&#x27;Proportion&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">towerGroup.count().plot(kind=<span class=\"string\">&#x27;line&#x27;</span>, ax=ax[<span class=\"number\">1</span>])</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_title(<span class=\"string\">&#x27;Count of Towers Destroyed&#x27;</span>)</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">&#x27;Count&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>towerDiff\n-2      27\n-1     347\n 0    9064\n 1     406\n 2      28\n 3       6\n 4       1\nName: blueWins, dtype: int64\ntowerDiff\n-2    0.185185\n-1    0.216138\n 0    0.498124\n 1    0.741379\n 2    0.964286\n 3    1.000000\n 4    1.000000\nName: blueWins, dtype: float64\n\n\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:400: MatplotlibDeprecationWarning: \nThe is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n  if ax.is_first_col():\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:400: MatplotlibDeprecationWarning: \nThe is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n  if ax.is_first_col():\n\n\n\n\n\nText(0, 0.5, 'Count')\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_32_3.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>推塔是英雄联盟这个游戏的核心，因此推塔数量可能与游戏的胜负有很大关系。我们绘图发现，尽管前十分钟推掉第一座防御塔的概率很低，但是一旦某只队伍推掉第一座防御塔，获得游戏的胜率将大大增加。</p>\n<p><strong>Step5: 利用 LightGBM 进行训练与预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 为了正确评估模型性能，将数据划分为训练集和测试集，并在训练集上训练模型，在测试集上验证模型性能。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 选择其类别为0和1的样本 （不包括类别为2的样本）</span></span><br><span class=\"line\">data_target_part = y</span><br><span class=\"line\">data_features_part = x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 测试集大小为20%， 80%/20%分</span></span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(data_features_part, </span><br><span class=\"line\">                                                    data_target_part, </span><br><span class=\"line\">                                                    test_size = <span class=\"number\">0.2</span>, </span><br><span class=\"line\">                                                    random_state = <span class=\"number\">2020</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 导入LightGBM模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> lightgbm.sklearn <span class=\"keyword\">import</span> LGBMClassifier</span><br><span class=\"line\"><span class=\"comment\">## 定义 LightGBM 模型 </span></span><br><span class=\"line\">clf = LGBMClassifier()</span><br><span class=\"line\"><span class=\"comment\"># 在训练集上训练LightGBM模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>LGBMClassifier()\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用训练好的模型进行预测</span></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> metrics</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵 (预测值和真实值的各类情况统计矩阵)</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>The accuracy of the Logistic Regression is: 0.8447425028470201\nThe accuracy of the Logistic Regression is: 0.722165991902834\nThe confusion matrix result:\n [[714 300]\n [249 713]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_37_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>我们可以发现共有 718 + 707 个样本预测正确，306 + 245 个样本预测错误。</p>\n<p><strong>Step6: 利用 LightGBM 进行特征选择</strong></p>\n<p>LightGBM 的特征选择属于特征选择中的嵌入式方法，在 LightGBM 中可以用属性 feature_importances_去查看特征的重要度。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sns.barplot(y=data_features_part.columns, x=clf.feature_importances_)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;AxesSubplot:&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_40_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>总经济差距等特征，助攻数量、击杀死亡数量等特征都具有很大的作用。插眼数、推塔数对模型的影响并不大。</p>\n<p>初次之外，我们还可以使用 LightGBM 中的下列重要属性来评估特征的重要性。</p>\n<ul>\n<li>gain: 当利用特征做划分的时候的评价基尼指数</li>\n<li>split: 是以特征用到的次数来评价</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> lightgbm <span class=\"keyword\">import</span> plot_importance</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">estimate</span>(<span class=\"params\">model,data</span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#sns.barplot(data.columns,model.feature_importances_)</span></span><br><span class=\"line\">    ax1=plot_importance(model,importance_type=<span class=\"string\">&quot;gain&quot;</span>)</span><br><span class=\"line\">    ax1.set_title(<span class=\"string\">&#x27;gain&#x27;</span>)</span><br><span class=\"line\">    ax2=plot_importance(model, importance_type=<span class=\"string\">&quot;split&quot;</span>)</span><br><span class=\"line\">    ax2.set_title(<span class=\"string\">&#x27;split&#x27;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">classes</span>(<span class=\"params\">data,label,test</span>):</span></span><br><span class=\"line\">    model=LGBMClassifier()</span><br><span class=\"line\">    model.fit(data,label)</span><br><span class=\"line\">    ans=model.predict(test)</span><br><span class=\"line\">    estimate(model, data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ans</span><br><span class=\"line\"> </span><br><span class=\"line\">ans=classes(x_train,y_train,x_test)</span><br><span class=\"line\">pre=accuracy_score(y_test, ans)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;acc=&#x27;</span>,accuracy_score(y_test,ans))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_42_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_42_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<pre><code>acc= 0.722165991902834\n</code></pre>\n<p>这些图同样可以帮助我们更好的了解其他重要特征。</p>\n<p><strong>Step7: 通过调整参数获得更好的效果</strong></p>\n<p>LightGBM 中包括但不限于下列对模型影响较大的参数：</p>\n<ul>\n<li>learning_rate: 有时也叫作 eta，系统默认值为 0.3。每一步迭代的步长，很重要。太大了运行准确率不高，太小了运行速度慢。</li>\n<li>num_leaves：系统默认为 32。这个参数控制每棵树中最大叶子节点数量。</li>\n<li>feature_fraction：系统默认值为 1。我们一般设置成 0.8 左右。用来控制每棵随机采样的列数的占比 (每一列是一个特征)。</li>\n<li>max_depth： 系统默认值为 6，我们常用 3-10 之间的数字。这个值为树的最大深度。这个值是用来控制过拟合的。max_depth 越大，模型学习的更加具体。</li>\n</ul>\n<p>调节模型参数的方法有贪心算法、网格调参、贝叶斯调参等。这里我们采用网格调参，它的基本思想是穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 从sklearn库中导入网格调参函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> GridSearchCV</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 定义参数取值范围</span></span><br><span class=\"line\">learning_rate = [<span class=\"number\">0.1</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.6</span>]</span><br><span class=\"line\">feature_fraction = [<span class=\"number\">0.5</span>, <span class=\"number\">0.8</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">num_leaves = [<span class=\"number\">16</span>, <span class=\"number\">32</span>, <span class=\"number\">64</span>]</span><br><span class=\"line\">max_depth = [-<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">8</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">parameters = &#123; <span class=\"string\">&#x27;learning_rate&#x27;</span>: learning_rate,</span><br><span class=\"line\">              <span class=\"string\">&#x27;feature_fraction&#x27;</span>:feature_fraction,</span><br><span class=\"line\">              <span class=\"string\">&#x27;num_leaves&#x27;</span>: num_leaves,</span><br><span class=\"line\">              <span class=\"string\">&#x27;max_depth&#x27;</span>: max_depth&#125;</span><br><span class=\"line\">model = LGBMClassifier(n_estimators = <span class=\"number\">50</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 进行网格搜索</span></span><br><span class=\"line\">clf = GridSearchCV(model, parameters, cv=<span class=\"number\">3</span>, scoring=<span class=\"string\">&#x27;accuracy&#x27;</span>,verbose=<span class=\"number\">3</span>, n_jobs=-<span class=\"number\">1</span>)</span><br><span class=\"line\">clf = clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>Fitting 3 folds for each of 108 candidates, totalling 324 fits\n[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 网格搜索后的最好参数为</span></span><br><span class=\"line\"></span><br><span class=\"line\">clf.best_params_</span><br></pre></td></tr></table></figure>\n<pre><code>&#123;'feature_fraction': 1, 'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 16&#125;\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用最好的模型参数进行预测</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 定义带参数的 LightGBM模型 </span></span><br><span class=\"line\">clf = LGBMClassifier(feature_fraction = <span class=\"number\">1</span>,</span><br><span class=\"line\">                    learning_rate = <span class=\"number\">0.1</span>,</span><br><span class=\"line\">                    max_depth= <span class=\"number\">3</span>,</span><br><span class=\"line\">                    num_leaves = <span class=\"number\">16</span>)</span><br><span class=\"line\"><span class=\"comment\"># 在训练集上训练LightGBM模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵 (预测值和真实值的各类情况统计矩阵)</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\nThe accuracy of the Logistic Regression is: 0.7462988738453752\nThe accuracy of the Logistic Regression is: 0.7302631578947368\nThe confusion matrix result:\n [[724 294]\n [239 719]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_47_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>原本有 306 + 245 个错误，现在有 294 + 239 个错误，带来了明显的正确率提升。</p>\n<h2 id=\"24-重要知识点\"><a class=\"markdownIt-Anchor\" href=\"#24-重要知识点\">#</a> 2.4 重要知识点</h2>\n<h3 id=\"241-lightgbm的重要参数\"><a class=\"markdownIt-Anchor\" href=\"#241-lightgbm的重要参数\">#</a> 2.4.1 LightGBM 的重要参数</h3>\n<h4 id=\"2411-基本参数调整\"><a class=\"markdownIt-Anchor\" href=\"#2411-基本参数调整\">#</a> 2.4.1.1 基本参数调整</h4>\n<ol>\n<li>\n<p><strong>num_leaves 参数</strong> 这是控制树模型复杂度的主要参数，一般的我们会使 num_leaves 小于（2 的 max_depth 次方），以防止过拟合。由于 LightGBM 是 leaf-wise 建树与 XGBoost 的 depth-wise 建树方法不同，num_leaves 比 depth 有更大的作用。、</p>\n</li>\n<li>\n<p><strong>min_data_in_leaf</strong> 这是处理过拟合问题中一个非常重要的参数。它的值取决于训练数据的样本个树和 num_leaves 参数。将其设置的较大可以避免生成一个过深的树，但有可能导致欠拟合。实际应用中，对于大数据集，设置其为几百或几千就足够了.</p>\n</li>\n<li>\n<p><strong>max_depth</strong> 树的深度，depth 的概念在 leaf-wise 树中并没有多大作用，因为并不存在一个从 leaves 到 depth 的合理映射。</p>\n</li>\n</ol>\n<h4 id=\"2412-针对训练速度的参数调整\"><a class=\"markdownIt-Anchor\" href=\"#2412-针对训练速度的参数调整\">#</a> 2.4.1.2 针对训练速度的参数调整</h4>\n<ol>\n<li>通过设置 bagging_fraction 和 bagging_freq 参数来使用 bagging 方法。</li>\n<li>通过设置 feature_fraction 参数来使用特征的子抽样。</li>\n<li>选择较小的 max_bin 参数。</li>\n<li>使用 save_binary 在未来的学习过程对数据加载进行加速。</li>\n</ol>\n<h4 id=\"2413-针对准确率的参数调整\"><a class=\"markdownIt-Anchor\" href=\"#2413-针对准确率的参数调整\">#</a> 2.4.1.3 针对准确率的参数调整</h4>\n<ol>\n<li>使用较大的 max_bin （学习速度可能变慢）</li>\n<li>使用较小的 learning_rate 和较大的 num_iterations</li>\n<li>使用较大的 num_leaves （可能导致过拟合）</li>\n<li>使用更大的训练数据</li>\n<li>尝试 dart 模式</li>\n</ol>\n<h4 id=\"2414-针对过拟合的参数调整\"><a class=\"markdownIt-Anchor\" href=\"#2414-针对过拟合的参数调整\">#</a> 2.4.1.4 针对过拟合的参数调整</h4>\n<ol>\n<li>使用较小的 max_bin</li>\n<li>使用较小的 num_leaves</li>\n<li>使用 min_data_in_leaf 和 min_sum_hessian_in_leaf</li>\n<li>通过设置 bagging_fraction 和 bagging_freq 来使用 bagging</li>\n<li>通过设置 feature_fraction 来使用特征子抽样</li>\n<li>使用更大的训练数据</li>\n<li>使用 lambda_l1, lambda_l2 和 min_gain_to_split 来使用正则</li>\n<li>尝试 max_depth 来避免生成过深的树</li>\n</ol>\n<h3 id=\"242-lightgbm原理粗略讲解\"><a class=\"markdownIt-Anchor\" href=\"#242-lightgbm原理粗略讲解\">#</a> 2.4.2 LightGBM 原理粗略讲解</h3>\n<p>LightGBM 底层实现了 GBDT 算法，并且添加了一系列的新特性：</p>\n<ol>\n<li>基于直方图算法进行优化，使数据存储更加方便、运算更快、鲁棒性强、模型更加稳定等。</li>\n<li>提出了带深度限制的 Leaf-wise 算法，抛弃了大多数 GBDT 工具使用的按层生长 (level-wise) 的决策树生长策略，而使用了带有深度限制的按叶子生长策略，可以降低误差，得到更好的精度。</li>\n<li>提出了单边梯度采样算法，排除大部分小梯度的样本，仅用剩下的样本计算信息增益，它是一种在减少数据量和保证精度上平衡的算法。</li>\n<li>提出了互斥特征捆绑算法，高维度的数据往往是稀疏的，这种稀疏性启发我们设计一种无损的方法来减少特征的维度。通常被捆绑的特征都是互斥的（即特征不会同时为非零值，像 one-hot），这样两个特征捆绑起来就不会丢失信息。</li>\n</ol>\n<p>LightGBM 是基于 CART 树的集成模型，它的思想是串联多个决策树模型共同进行决策。</p>\n<p>那么如何串联呢？LightGBM 采用迭代预测误差的方法串联。举个通俗的例子，我们现在需要预测一辆车价值 3000 元。我们构建决策树 1 训练后预测为 2600 元，我们发现有 400 元的误差，那么决策树 2 的训练目标为 400 元，但决策树 2 的预测结果为 350 元，还存在 50 元的误差就交给第三棵树…… 以此类推，每一颗树用来估计之前所有树的误差，最后所有树预测结果的求和就是最终预测结果！</p>\n<p>LightGBM 的基模型是 CART 回归树，它有两个特点：（1）CART 树，是一颗二叉树。（2）回归树，最后拟合结果是连续值。</p>\n<p>LightGBM 模型可以表示为以下形式，我们约定<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_t(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> 表示前 t 颗树的和，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_t(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> 表示第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 颗决策树，模型定义如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_t(x) = \\sum_{t=1}^Th_t(x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0954490000000003em;vertical-align:-1.267113em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>由于模型递归生成，第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 步的模型由第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mtext>−</mtext><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t−1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord\">−</span><span class=\"mord\">1</span></span></span></span> 步的模型形成，可以写成：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>f</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_t(x)=f_{t-1}(x)+h_t(x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>每次需要加上的树<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_t(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> 是之前树求和的误差：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>r</mi><mrow><mi>t</mi><mo separator=\"true\">,</mo><mi>i</mi></mrow></msub><mo>=</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mi>f</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">r_{t,i} = y_i - f_{m-1}(x_i)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8EXGBoost%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%9F%BA%E4%BA%8EXGBoost%E7%9A%84%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B/",
            "title": "基于XGBoost的分类预测",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"1-实验室介绍\"><a class=\"markdownIt-Anchor\" href=\"#1-实验室介绍\">#</a> 1. 实验室介绍</h1>\n<h2 id=\"11-xgboost的介绍\"><a class=\"markdownIt-Anchor\" href=\"#11-xgboost的介绍\">#</a> 1.1 XGBoost 的介绍</h2>\n<p>XGBoost 是 2016 年由华盛顿大学陈天奇老师带领开发的一个可扩展机器学习系统。严格意义上讲 XGBoost 并不是一种模型，而是一个可供用户轻松解决分类、回归或排序问题的软件包。它内部实现了梯度提升树 (GBDT) 模型，并对模型中的算法进行了诸多优化，在取得高精度的同时又保持了极快的速度，在一段时间内成为了国内外数据挖掘、机器学习领域中的大规模杀伤性武器。</p>\n<p>更重要的是，XGBoost 在系统优化和机器学习原理方面都进行了深入的考虑。毫不夸张的讲，XGBoost 提供的可扩展性，可移植性与准确性推动了机器学习计算限制的上限，该系统在单台机器上运行速度比当时流行解决方案快十倍以上，甚至在分布式系统中可以处理十亿级的数据。</p>\n<p>XGBoost 的主要优点：</p>\n<ol>\n<li>简单易用。相对其他机器学习库，用户可以轻松使用 XGBoost 并获得相当不错的效果。</li>\n<li>高效可扩展。在处理大规模数据集时速度快效果好，对内存等硬件资源要求不高。</li>\n<li>鲁棒性强。相对于深度学习模型不需要精细调参便能取得接近的效果。</li>\n<li>XGBoost 内部实现提升树模型，可以自动处理缺失值。</li>\n</ol>\n<p>XGBoost 的主要缺点：</p>\n<ol>\n<li>相对于深度学习模型无法对时空位置建模，不能很好地捕获图像、语音、文本等高维数据。</li>\n<li>在拥有海量训练数据，并能找到合适的深度学习模型时，深度学习的精度可以遥遥领先 XGBoost。</li>\n</ol>\n<h2 id=\"12-xgboost的应用\"><a class=\"markdownIt-Anchor\" href=\"#12-xgboost的应用\">#</a> 1.2 XGboost 的应用</h2>\n<p>XGBoost 在机器学习与数据挖掘领域有着极为广泛的应用。据统计在 2015 年 Kaggle 平台上 29 个获奖方案中，17 只队伍使用了 XGBoost；在 2015 年 KDD-Cup 中，前十名的队伍均使用了 XGBoost，且集成其他模型比不上调节 XGBoost 的参数所带来的提升。这些实实在在的例子都表明，XGBoost 在各种问题上都可以取得非常好的效果。</p>\n<p>同时，XGBoost 还被成功应用在工业界与学术界的各种问题中。例如商店销售额预测、高能物理事件分类、web 文本分类；用户行为预测、运动检测、广告点击率预测、恶意软件分类、灾害风险预测、在线课程退学率预测。虽然领域相关的数据分析和特性工程在这些解决方案中也发挥了重要作用，但学习者与实践者对 XGBoost 的一致选择表明了这一软件包的影响力与重要性。</p>\n<h1 id=\"2-实验室手册\"><a class=\"markdownIt-Anchor\" href=\"#2-实验室手册\">#</a> 2. 实验室手册</h1>\n<h2 id=\"21-学习目标\"><a class=\"markdownIt-Anchor\" href=\"#21-学习目标\">#</a> 2.1 学习目标</h2>\n<ul>\n<li>了解 XGBoost 的参数与相关知识</li>\n<li>掌握 XGBoost 的 Python 调用并将其运用到天气数据集预测</li>\n</ul>\n<h2 id=\"22-代码流程\"><a class=\"markdownIt-Anchor\" href=\"#22-代码流程\">#</a> 2.2 代码流程</h2>\n<p><strong>Part1 基于天气数据集的 XGBoost 分类实践</strong></p>\n<ul>\n<li>Step1: 库函数导入</li>\n<li>Step2: 数据读取 / 载入</li>\n<li>Step3: 数据信息简单查看</li>\n<li>Step4: 可视化描述</li>\n<li>Step5: 对离散变量进行编码</li>\n<li>Step6: 利用 XGBoost 进行训练与预测</li>\n<li>Step7: 利用 XGBoost 进行特征选择</li>\n<li>Step8: 通过调整参数获得更好的效果</li>\n</ul>\n<h2 id=\"23-算法实战\"><a class=\"markdownIt-Anchor\" href=\"#23-算法实战\">#</a> 2.3 算法实战</h2>\n<h3 id=\"231-基于天气数据集的xgboost分类实战\"><a class=\"markdownIt-Anchor\" href=\"#231-基于天气数据集的xgboost分类实战\">#</a> 2.3.1 基于天气数据集的 XGBoost 分类实战</h3>\n<p>在实践的最开始，我们首先需要导入一些基础的函数库包括：numpy （Python 进行科学计算的基础软件包），pandas（pandas 是一种快速，强大，灵活且易于使用的开源数据分析和处理工具），matplotlib 和 seaborn 绘图。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#导入需要用到的数据集</span></span><br><span class=\"line\">!wget https://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/7XGBoost/train.csv</span><br></pre></td></tr></table></figure>\n<pre><code>'wget' 不是内部或外部命令，也不是可运行的程序\n或批处理文件。\n</code></pre>\n<p><strong>Step1: 库函数导入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##  基础函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 绘图函数库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br></pre></td></tr></table></figure>\n<p>本次我们选择天气数据集进行方法的尝试训练，现在有一些由气象站提供的每日降雨数据，我们需要根据历史降雨数据来预测明天会下雨的概率。样例涉及到的测试集数据 test.csv 与 train.csv 的格式完全相同，但其 RainTomorrow 未给出，为预测变量。</p>\n<p>数据的各个特征描述如下：</p>\n<table>\n<thead>\n<tr>\n<th>特征名称</th>\n<th>意义</th>\n<th>取值范围</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Date</td>\n<td>日期</td>\n<td>字符串</td>\n</tr>\n<tr>\n<td>Location</td>\n<td>气象站的地址</td>\n<td>字符串</td>\n</tr>\n<tr>\n<td>MinTemp</td>\n<td>最低温度</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>MaxTemp</td>\n<td>最高温度</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Rainfall</td>\n<td>降雨量</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Evaporation</td>\n<td>蒸发量</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Sunshine</td>\n<td>光照时间</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>WindGustDir</td>\n<td>最强的风的方向</td>\n<td>字符串</td>\n</tr>\n<tr>\n<td>WindGustSpeed</td>\n<td>最强的风的速度</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>WindDir9am</td>\n<td>早上 9 点的风向</td>\n<td>字符串</td>\n</tr>\n<tr>\n<td>WindDir3pm</td>\n<td>下午 3 点的风向</td>\n<td>字符串</td>\n</tr>\n<tr>\n<td>WindSpeed9am</td>\n<td>早上 9 点的风速</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>WindSpeed3pm</td>\n<td>下午 3 点的风速</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Humidity9am</td>\n<td>早上 9 点的湿度</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Humidity3pm</td>\n<td>下午 3 点的湿度</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Pressure9am</td>\n<td>早上 9 点的大气压</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Pressure3pm</td>\n<td>早上 3 点的大气压</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Cloud9am</td>\n<td>早上 9 点的云指数</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Cloud3pm</td>\n<td>早上 3 点的云指数</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Temp9am</td>\n<td>早上 9 点的温度</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>Temp3pm</td>\n<td>早上 3 点的温度</td>\n<td>实数</td>\n</tr>\n<tr>\n<td>RainToday</td>\n<td>今天是否下雨</td>\n<td>No，Yes</td>\n</tr>\n<tr>\n<td>RainTomorrow</td>\n<td>明天是否下雨</td>\n<td>No，Yes</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Step2: 数据读取 / 载入</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 我们利用Pandas自带的read_csv函数读取并转化为DataFrame格式</span></span><br><span class=\"line\"></span><br><span class=\"line\">data = pd.read_csv(<span class=\"string\">&#x27;train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p><strong>Step3: 数据信息简单查看</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 利用.info()查看数据的整体信息</span></span><br><span class=\"line\">data.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 106644 entries, 0 to 106643\nData columns (total 23 columns):\n #   Column         Non-Null Count   Dtype  \n---  ------         --------------   -----  \n 0   Date           106644 non-null  object \n 1   Location       106644 non-null  object \n 2   MinTemp        106183 non-null  float64\n 3   MaxTemp        106413 non-null  float64\n 4   Rainfall       105610 non-null  float64\n 5   Evaporation    60974 non-null   float64\n 6   Sunshine       55718 non-null   float64\n 7   WindGustDir    99660 non-null   object \n 8   WindGustSpeed  99702 non-null   float64\n 9   WindDir9am     99166 non-null   object \n 10  WindDir3pm     103788 non-null  object \n 11  WindSpeed9am   105643 non-null  float64\n 12  WindSpeed3pm   104653 non-null  float64\n 13  Humidity9am    105327 non-null  float64\n 14  Humidity3pm    103932 non-null  float64\n 15  Pressure9am    96107 non-null   float64\n 16  Pressure3pm    96123 non-null   float64\n 17  Cloud9am       66303 non-null   float64\n 18  Cloud3pm       63691 non-null   float64\n 19  Temp9am        105983 non-null  float64\n 20  Temp3pm        104599 non-null  float64\n 21  RainToday      105610 non-null  object \n 22  RainTomorrow   106644 non-null  object \ndtypes: float64(16), object(7)\nmemory usage: 18.7+ MB\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 进行简单的数据查看，我们可以利用 .head() 头部.tail()尾部</span></span><br><span class=\"line\">data.head()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012/1/19</td>\n      <td>MountGinini</td>\n      <td>12.1</td>\n      <td>23.1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>30.0</td>\n      <td>N</td>\n      <td>...</td>\n      <td>60.0</td>\n      <td>54.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>22.0</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015/4/13</td>\n      <td>Nhil</td>\n      <td>10.2</td>\n      <td>24.7</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>E</td>\n      <td>39.0</td>\n      <td>E</td>\n      <td>...</td>\n      <td>63.0</td>\n      <td>33.0</td>\n      <td>1021.9</td>\n      <td>1017.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.5</td>\n      <td>23.7</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010/8/5</td>\n      <td>Nuriootpa</td>\n      <td>-0.4</td>\n      <td>11.0</td>\n      <td>3.6</td>\n      <td>0.4</td>\n      <td>1.6</td>\n      <td>W</td>\n      <td>28.0</td>\n      <td>N</td>\n      <td>...</td>\n      <td>97.0</td>\n      <td>78.0</td>\n      <td>1025.9</td>\n      <td>1025.3</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>3.9</td>\n      <td>9.0</td>\n      <td>Yes</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013/3/18</td>\n      <td>Adelaide</td>\n      <td>13.2</td>\n      <td>22.6</td>\n      <td>0.0</td>\n      <td>15.4</td>\n      <td>11.0</td>\n      <td>SE</td>\n      <td>44.0</td>\n      <td>E</td>\n      <td>...</td>\n      <td>47.0</td>\n      <td>34.0</td>\n      <td>1025.0</td>\n      <td>1022.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.2</td>\n      <td>21.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011/2/16</td>\n      <td>Sale</td>\n      <td>14.1</td>\n      <td>28.6</td>\n      <td>0.0</td>\n      <td>6.6</td>\n      <td>6.7</td>\n      <td>E</td>\n      <td>28.0</td>\n      <td>NE</td>\n      <td>...</td>\n      <td>92.0</td>\n      <td>42.0</td>\n      <td>1018.0</td>\n      <td>1014.1</td>\n      <td>4.0</td>\n      <td>7.0</td>\n      <td>19.1</td>\n      <td>28.2</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>\n<p>这里我们发现数据集中存在 NaN，一般的我们认为 NaN 在数据集中代表了缺失值，可能是数据采集或处理时产生的一种错误。这里我们采用 - 1 将缺失值进行填补，还有其他例如 “中位数填补、平均数填补” 的缺失值处理方法有兴趣的同学也可以尝试。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = data.fillna(-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data.tail()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106639</th>\n      <td>2011/5/23</td>\n      <td>Launceston</td>\n      <td>10.1</td>\n      <td>16.1</td>\n      <td>15.8</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>SE</td>\n      <td>31.0</td>\n      <td>NNW</td>\n      <td>...</td>\n      <td>99.0</td>\n      <td>86.0</td>\n      <td>999.2</td>\n      <td>995.2</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>13.0</td>\n      <td>15.6</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>106640</th>\n      <td>2014/12/9</td>\n      <td>GoldCoast</td>\n      <td>19.3</td>\n      <td>31.7</td>\n      <td>36.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>SE</td>\n      <td>80.0</td>\n      <td>NNW</td>\n      <td>...</td>\n      <td>75.0</td>\n      <td>76.0</td>\n      <td>1013.8</td>\n      <td>1010.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>26.0</td>\n      <td>25.8</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>106641</th>\n      <td>2014/10/7</td>\n      <td>Wollongong</td>\n      <td>17.5</td>\n      <td>22.2</td>\n      <td>1.2</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>WNW</td>\n      <td>65.0</td>\n      <td>WNW</td>\n      <td>...</td>\n      <td>61.0</td>\n      <td>56.0</td>\n      <td>1008.2</td>\n      <td>1008.2</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>17.8</td>\n      <td>21.4</td>\n      <td>Yes</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>106642</th>\n      <td>2012/1/16</td>\n      <td>Newcastle</td>\n      <td>17.6</td>\n      <td>27.0</td>\n      <td>3.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1</td>\n      <td>-1.0</td>\n      <td>NE</td>\n      <td>...</td>\n      <td>68.0</td>\n      <td>88.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>22.6</td>\n      <td>26.4</td>\n      <td>Yes</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>106643</th>\n      <td>2014/10/21</td>\n      <td>AliceSprings</td>\n      <td>16.3</td>\n      <td>37.9</td>\n      <td>0.0</td>\n      <td>14.2</td>\n      <td>12.2</td>\n      <td>ESE</td>\n      <td>41.0</td>\n      <td>NNE</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>1017.9</td>\n      <td>1014.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>32.2</td>\n      <td>35.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>\n<p><strong>Step4: 可视化描述</strong></p>\n<p>为了方便，我们先纪录数字特征与非数字特征：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">numerical_features = [x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> data.columns <span class=\"keyword\">if</span> data[x].dtype == np.<span class=\"built_in\">float</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">category_features = [x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> data.columns <span class=\"keyword\">if</span> data[x].dtype != np.<span class=\"built_in\">float</span> <span class=\"keyword\">and</span> x != <span class=\"string\">&#x27;RainTomorrow&#x27;</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 选取三个特征与标签组合的散点可视化</span></span><br><span class=\"line\">sns.pairplot(data=data[[<span class=\"string\">&#x27;Rainfall&#x27;</span>,<span class=\"string\">&#x27;Evaporation&#x27;</span>,</span><br><span class=\"line\"><span class=\"string\">&#x27;Sunshine&#x27;</span>] + [<span class=\"string\">&#x27;RainTomorrow&#x27;</span>]], diag_kind=<span class=\"string\">&#x27;hist&#x27;</span>, hue= <span class=\"string\">&#x27;RainTomorrow&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_15_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>从上图可以发现，在 2D 情况下不同的特征组合对于第二天下雨与不下雨的散点分布，以及大概的区分能力。相对的 Sunshine 与其他特征的组合更具有区分能力</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> data[numerical_features].columns:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> col != <span class=\"string\">&#x27;RainTomorrow&#x27;</span>:</span><br><span class=\"line\">        sns.boxplot(x=<span class=\"string\">&#x27;RainTomorrow&#x27;</span>, y=col, saturation=<span class=\"number\">0.5</span>, palette=<span class=\"string\">&#x27;pastel&#x27;</span>, data=data)</span><br><span class=\"line\">        plt.title(col)</span><br><span class=\"line\">        plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_17_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_3.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_4.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_5.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_6.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_7.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_8.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_9.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_10.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_11.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_12.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_13.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_14.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_17_15.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>利用箱型图我们也可以得到不同类别在不同特征上的分布差异情况。我们可以发现 Sunshine,Humidity3pm,Cloud9am,Cloud3pm 的区分能力较强</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tlog = &#123;&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> category_features:</span><br><span class=\"line\">    tlog[i] = data[data[<span class=\"string\">&#x27;RainTomorrow&#x27;</span>] == <span class=\"string\">&#x27;Yes&#x27;</span>][i].value_counts()</span><br><span class=\"line\">flog = &#123;&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> category_features:</span><br><span class=\"line\">    flog[i] = data[data[<span class=\"string\">&#x27;RainTomorrow&#x27;</span>] == <span class=\"string\">&#x27;No&#x27;</span>][i].value_counts()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;RainTomorrow&#x27;</span>)</span><br><span class=\"line\">sns.barplot(x = pd.DataFrame(tlog[<span class=\"string\">&#x27;Location&#x27;</span>]).sort_index()[<span class=\"string\">&#x27;Location&#x27;</span>], </span><br><span class=\"line\">            y = pd.DataFrame(tlog[<span class=\"string\">&#x27;Location&#x27;</span>]).sort_index().index, color = <span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Not RainTomorrow&#x27;</span>)</span><br><span class=\"line\">sns.barplot(x = pd.DataFrame(flog[<span class=\"string\">&#x27;Location&#x27;</span>]).sort_index()[<span class=\"string\">&#x27;Location&#x27;</span>], </span><br><span class=\"line\">            y = pd.DataFrame(flog[<span class=\"string\">&#x27;Location&#x27;</span>]).sort_index().index, color = <span class=\"string\">&quot;blue&quot;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_20_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>从上图可以发现不同地区降雨情况差别很大，有些地方明显更容易降雨</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">2</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;RainTomorrow&#x27;</span>)</span><br><span class=\"line\">sns.barplot(x = pd.DataFrame(tlog[<span class=\"string\">&#x27;RainToday&#x27;</span>][:<span class=\"number\">2</span>]).sort_index()[<span class=\"string\">&#x27;RainToday&#x27;</span>], y = pd.DataFrame(tlog[<span class=\"string\">&#x27;RainToday&#x27;</span>][:<span class=\"number\">2</span>]).sort_index().index, color = <span class=\"string\">&quot;red&quot;</span>)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Not RainTomorrow&#x27;</span>)</span><br><span class=\"line\">sns.barplot(x = pd.DataFrame(flog[<span class=\"string\">&#x27;RainToday&#x27;</span>][:<span class=\"number\">2</span>]).sort_index()[<span class=\"string\">&#x27;RainToday&#x27;</span>], y = pd.DataFrame(flog[<span class=\"string\">&#x27;RainToday&#x27;</span>][:<span class=\"number\">2</span>]).sort_index().index, color = <span class=\"string\">&quot;blue&quot;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_22_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>上图我们可以发现，今天下雨明天不一定下雨，但今天不下雨，第二天大概率也不下雨。</p>\n<p><strong>Step5: 对离散变量进行编码</strong></p>\n<p>由于 XGBoost 无法处理字符串类型的数据，我们需要一些方法讲字符串数据转化为数据。一种最简单的方法是把所有的相同类别的特征编码成同一个值，例如女 = 0，男 = 1，狗狗 = 2，所以最后编码的特征值是在 [0, 特征数量−1] 之间的整数。除此之外，还有独热编码、求和编码、留一法编码等等方法可以获得更好的效果。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 把所有的相同类别的特征编码为同一个值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_mapfunction</span>(<span class=\"params\">x</span>):</span></span><br><span class=\"line\">    mapp = <span class=\"built_in\">dict</span>(<span class=\"built_in\">zip</span>(x.unique().tolist(),</span><br><span class=\"line\">         <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x.unique().tolist()))))</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">mapfunction</span>(<span class=\"params\">y</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> y <span class=\"keyword\">in</span> mapp:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> mapp[y]</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> -<span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> mapfunction</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> category_features:</span><br><span class=\"line\">    data[i] = data[i].apply(get_mapfunction(data[i]))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 编码后的字符串特征变成了数字</span></span><br><span class=\"line\"></span><br><span class=\"line\">data[<span class=\"string\">&#x27;Location&#x27;</span>].unique()</span><br></pre></td></tr></table></figure>\n<pre><code>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48],\n      dtype=int64)\n</code></pre>\n<p><strong>Step6: 利用 XGBoost 进行训练与预测</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 为了正确评估模型性能，将数据划分为训练集和测试集，</span></span><br><span class=\"line\"><span class=\"comment\">## 并在训练集上训练模型，在测试集上验证模型性能。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 选择其类别为0和1的样本 （不包括类别为2的样本）</span></span><br><span class=\"line\">data_target_part = data[<span class=\"string\">&#x27;RainTomorrow&#x27;</span>]</span><br><span class=\"line\">data_features_part = data[[x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> data.columns <span class=\"keyword\">if</span> x != <span class=\"string\">&#x27;RainTomorrow&#x27;</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 测试集大小为20%， 80%/20%分</span></span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(data_features_part, </span><br><span class=\"line\">                                                    data_target_part, </span><br><span class=\"line\">                                                    test_size = <span class=\"number\">0.2</span>, </span><br><span class=\"line\">                                                    random_state = <span class=\"number\">2020</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 导入XGBoost模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> xgboost.sklearn <span class=\"keyword\">import</span> XGBClassifier</span><br><span class=\"line\"><span class=\"comment\">## 定义 XGBoost模型 </span></span><br><span class=\"line\">clf = XGBClassifier()</span><br><span class=\"line\"><span class=\"comment\"># 在训练集上训练XGBoost模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n\n[15:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n\n\n\n\nXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=32, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用训练好的模型进行预测</span></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> metrics</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵 (预测值和真实值的各类情况统计矩阵)</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>The accuracy of the Logistic Regression is: 0.8982476703979371\nThe accuracy of the Logistic Regression is: 0.8575179333302076\nThe confusion matrix result:\n [[15656  2142]\n [  897  2634]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_30_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>我们可以发现共有 15759 + 2306 个样本预测正确，2470 + 794 个样本预测错误。</p>\n<p><strong>Step7: 利用 XGBoost 进行特征选择</strong></p>\n<p>XGBoost 的特征选择属于特征选择中的嵌入式方法，在 XGboost 中可以用属性 feature_importances_去查看特征的重要度。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">? sns.barplot</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sns.barplot(y=data_features_part.columns, x=clf.feature_importances_)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;AxesSubplot:&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_33_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>从图中我们可以发现下午 3 点的湿度与今天是否下雨是决定第二天是否下雨最重要的因素</p>\n<p>初次之外，我们还可以使用 XGBoost 中的下列重要属性来评估特征的重要性。</p>\n<ul>\n<li>weight: 是以特征用到的次数来评价</li>\n<li>gain: 当利用特征做划分的时候的评价基尼指数</li>\n<li>cover: 利用一个覆盖样本的指标二阶导数（具体原理不清楚有待探究）平均值来划分。</li>\n<li>total_gain: 总基尼指数</li>\n<li>total_cover: 总覆盖</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> xgboost <span class=\"keyword\">import</span> plot_importance</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">estimate</span>(<span class=\"params\">model,data</span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#sns.barplot(data.columns,model.feature_importances_)</span></span><br><span class=\"line\">    ax1=plot_importance(model,importance_type=<span class=\"string\">&quot;gain&quot;</span>)</span><br><span class=\"line\">    ax1.set_title(<span class=\"string\">&#x27;gain&#x27;</span>)</span><br><span class=\"line\">    ax2=plot_importance(model, importance_type=<span class=\"string\">&quot;weight&quot;</span>)</span><br><span class=\"line\">    ax2.set_title(<span class=\"string\">&#x27;weight&#x27;</span>)</span><br><span class=\"line\">    ax3 = plot_importance(model, importance_type=<span class=\"string\">&quot;cover&quot;</span>)</span><br><span class=\"line\">    ax3.set_title(<span class=\"string\">&#x27;cover&#x27;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">classes</span>(<span class=\"params\">data,label,test</span>):</span></span><br><span class=\"line\">    model=XGBClassifier()</span><br><span class=\"line\">    model.fit(data,label)</span><br><span class=\"line\">    ans=model.predict(test)</span><br><span class=\"line\">    estimate(model, data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ans</span><br><span class=\"line\"> </span><br><span class=\"line\">ans=classes(x_train,y_train,x_test)</span><br><span class=\"line\">pre=accuracy_score(y_test, ans)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;acc=&#x27;</span>,accuracy_score(y_test,ans))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n\n[15:25:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_35_2.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_35_3.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_35_4.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<pre><code>acc= 0.8575179333302076\n</code></pre>\n<p>这些图同样可以帮助我们更好的了解其他重要特征。</p>\n<p><strong>Step8: 通过调整参数获得更好的效果</strong></p>\n<p>XGBoost 中包括但不限于下列对模型影响较大的参数：</p>\n<ol>\n<li>learning_rate: 有时也叫作 eta，系统默认值为 0.3。每一步迭代的步长，很重要。太大了运行准确率不高，太小了运行速度慢。</li>\n<li>subsample：系统默认为 1。这个参数控制对于每棵树，随机采样的比例。减小这个参数的值，算法会更加保守，避免过拟合，取值范围零到一。</li>\n<li>colsample_bytree：系统默认值为 1。我们一般设置成 0.8 左右。用来控制每棵随机采样的列数的占比 (每一列是一个特征)。</li>\n<li>max_depth： 系统默认值为 6，我们常用 3-10 之间的数字。这个值为树的最大深度。这个值是用来控制过拟合的。max_depth 越大，模型学习的更加具体。</li>\n</ol>\n<p>调节模型参数的方法有贪心算法、网格调参、贝叶斯调参等。这里我们采用网格调参，它的基本思想是穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 从sklearn库中导入网格调参函数</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> GridSearchCV</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 定义参数取值范围</span></span><br><span class=\"line\">learning_rate = [<span class=\"number\">0.1</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.6</span>]</span><br><span class=\"line\">subsample = [<span class=\"number\">0.8</span>, <span class=\"number\">0.9</span>]</span><br><span class=\"line\">colsample_bytree = [<span class=\"number\">0.6</span>, <span class=\"number\">0.8</span>]</span><br><span class=\"line\">max_depth = [<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">8</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">parameters = &#123; <span class=\"string\">&#x27;learning_rate&#x27;</span>: learning_rate,</span><br><span class=\"line\">              <span class=\"string\">&#x27;subsample&#x27;</span>: subsample,</span><br><span class=\"line\">              <span class=\"string\">&#x27;colsample_bytree&#x27;</span>:colsample_bytree,</span><br><span class=\"line\">              <span class=\"string\">&#x27;max_depth&#x27;</span>: max_depth&#125;</span><br><span class=\"line\">model = XGBClassifier(n_estimators = <span class=\"number\">50</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 进行网格搜索</span></span><br><span class=\"line\">clf = GridSearchCV(model, parameters, cv=<span class=\"number\">3</span>, scoring=<span class=\"string\">&#x27;accuracy&#x27;</span>,verbose=<span class=\"number\">1</span>,n_jobs=-<span class=\"number\">1</span>)</span><br><span class=\"line\">clf = clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<pre><code>Fitting 3 folds for each of 36 candidates, totalling 108 fits\n\n\nc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n\n[15:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 网格搜索后的最好参数为</span></span><br><span class=\"line\"></span><br><span class=\"line\">clf.best_params_</span><br></pre></td></tr></table></figure>\n<pre><code>&#123;'colsample_bytree': 0.6,\n 'learning_rate': 0.1,\n 'max_depth': 8,\n 'subsample': 0.8&#125;\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 在训练集和测试集上分布利用最好的模型参数进行预测</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 定义带参数的 XGBoost模型 </span></span><br><span class=\"line\">clf = XGBClassifier(colsample_bytree = <span class=\"number\">0.6</span>, learning_rate = <span class=\"number\">0.3</span>, max_depth= <span class=\"number\">8</span>, subsample = <span class=\"number\">0.9</span>)</span><br><span class=\"line\"><span class=\"comment\"># 在训练集上训练XGBoost模型</span></span><br><span class=\"line\">clf.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">train_predict = clf.predict(x_train)</span><br><span class=\"line\">test_predict = clf.predict(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_train,train_predict))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The accuracy of the Logistic Regression is:&#x27;</span>,metrics.accuracy_score(y_test,test_predict))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 查看混淆矩阵 (预测值和真实值的各类情况统计矩阵)</span></span><br><span class=\"line\">confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The confusion matrix result:\\n&#x27;</span>,confusion_matrix_result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 利用热力图对于结果进行可视化</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">sns.heatmap(confusion_matrix_result, annot=<span class=\"literal\">True</span>, cmap=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Predicted labels&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;True labels&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>[15:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nThe accuracy of the Logistic Regression is: 0.9434917658090606\nThe accuracy of the Logistic Regression is: 0.8577992404707206\nThe confusion matrix result:\n [[15639  2119]\n [  914  2657]]\n</code></pre>\n<p><img \"\" class=\"lazyload placeholder\" data-original=\"output_41_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"></p>\n<p>原本有 2470 + 790 个错误，现在有 2112 + 939 个错误，带来了明显的正确率提升。</p>\n<h2 id=\"24-重要知识点\"><a class=\"markdownIt-Anchor\" href=\"#24-重要知识点\">#</a> 2.4 重要知识点</h2>\n<h3 id=\"241-xgboost的重要参数\"><a class=\"markdownIt-Anchor\" href=\"#241-xgboost的重要参数\">#</a> 2.4.1 XGBoost 的重要参数</h3>\n<p>1.eta [默认 0.3]</p>\n<p>通过为每一颗树增加权重，提高模型的鲁棒性。<br>\n典型值为 0.01-0.2。</p>\n<p>2.min_child_weight [默认 1]</p>\n<p>决定最小叶子节点样本权重和。<br>\n这个参数可以避免过拟合。当它的值较大时，可以避免模型学习到局部的特殊样本。<br>\n但是如果这个值过高，则会导致模型拟合不充分。</p>\n<p>3.max_depth [默认 6]</p>\n<p>这个值也是用来避免过拟合的。max_depth 越大，模型会学到更具体更局部的样本。<br>\n典型值：3-10</p>\n<p>4.max_leaf_nodes</p>\n<p>树上最大的节点或叶子的数量。<br>\n可以替代 max_depth 的作用。<br>\n这个参数的定义会导致忽略 max_depth 参数。</p>\n<p>5.gamma [默认 0]</p>\n<p>在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma 指定了节点分裂所需的最小损失函数下降值。 这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关。</p>\n<p>6.max_delta_step [默认 0]</p>\n<p>这参数限制每棵树权重改变的最大步长。如果这个参数的值为 0，那就意味着没有约束。如果它被赋予了某个正值，那么它会让这个算法更加保守。<br>\n但是当各类别的样本十分不平衡时，它对分类问题是很有帮助的。</p>\n<p>7.subsample [默认 1]</p>\n<p>这个参数控制对于每棵树，随机采样的比例。<br>\n减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。<br>\n典型值：0.5-1</p>\n<p>8.colsample_bytree [默认 1]</p>\n<p>用来控制每棵随机采样的列数的占比 (每一列是一个特征)。<br>\n典型值：0.5-1</p>\n<p>9.colsample_bylevel [默认 1]</p>\n<p>用来控制树的每一级的每一次分裂，对列数的采样的占比。<br>\nsubsample 参数和 colsample_bytree 参数可以起到相同的作用，一般用不到。</p>\n<p>10.lambda [默认 1]</p>\n<p>权重的 L2 正则化项。(和 Ridge regression 类似)。<br>\n这个参数是用来控制 XGBoost 的正则化部分的。虽然大部分数据科学家很少用到这个参数，但是这个参数在减少过拟合上还是可以挖掘出更多用处的。</p>\n<p>11.alpha [默认 1]</p>\n<p>权重的 L1 正则化项。(和 Lasso regression 类似)。<br>\n可以应用在很高维度的情况下，使得算法的速度更快。</p>\n<p>12.scale_pos_weight [默认 1]</p>\n<p>在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。</p>\n<h3 id=\"242-xgboost原理粗略讲解\"><a class=\"markdownIt-Anchor\" href=\"#242-xgboost原理粗略讲解\">#</a> 2.4.2 XGBoost 原理粗略讲解</h3>\n<p>XGBoost 底层实现了 GBDT 算法，并对 GBDT 算法做了一系列优化：</p>\n<ol>\n<li>对目标函数进行了泰勒展示的二阶展开，可以更加高效拟合误差。</li>\n<li>提出了一种估计分裂点的算法加速 CART 树的构建过程，同时可以处理稀疏数据。</li>\n<li>提出了一种树的并行策略加速迭代。</li>\n<li>为模型的分布式算法进行了底层优化。</li>\n</ol>\n<p>XGBoost 是基于 CART 树的集成模型，它的思想是串联多个决策树模型共同进行决策。</p>\n<p>那么如何串联呢？XGBoost 采用迭代预测误差的方法串联。举个通俗的例子，我们现在需要预测一辆车价值 3000 元。我们构建决策树 1 训练后预测为 2600 元，我们发现有 400 元的误差，那么决策树 2 的训练目标为 400 元，但决策树 2 的预测结果为 350 元，还存在 50 元的误差就交给第三棵树…… 以此类推，每一颗树用来估计之前所有树的误差，最后所有树预测结果的求和就是最终预测结果！</p>\n<p>XGBoost 的基模型是 CART 回归树，它有两个特点：（1）CART 树，是一颗二叉树。（2）回归树，最后拟合结果是连续值。</p>\n<p>XGBoost 模型可以表示为以下形式，我们约定<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_t(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> 表示前<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 颗树的和，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_t(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> 表示第 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 颗决策树，模型定义如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_t(x) = \\sum_{t=1}^{T}h_t(x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0954490000000003em;vertical-align:-1.267113em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>由于模型递归生成，第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 步的模型由第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mtext>−</mtext><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t−1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord\">−</span><span class=\"mord\">1</span></span></span></span> 步的模型形成，可以写成：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>f</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_t(x) = f_{t-1}(x) + h_t(x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>每次需要加上的树<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_t(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> 是之前树求和的误差：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>r</mi><mrow><mi>t</mi><mo separator=\"true\">,</mo><mi>i</mi></mrow></msub><mo>=</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mi>f</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">r_{t,i} = y_i - f_{m-1}(x_i)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>我们每一步只要拟合一颗输出为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mrow><mi>t</mi><mo separator=\"true\">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">r_{t,i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 的 CART 树加到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_{t-1}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> 就可以了。</p>\n",
            "tags": [
                "机器学习"
            ]
        },
        {
            "id": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/",
            "url": "http://example.com/2021/11/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A9%E6%B1%A0/%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/",
            "title": "工业蒸汽数据分析",
            "date_published": "2021-11-08T07:02:54.000Z",
            "content_html": "<h1 id=\"导入数据探索的工具包\"><a class=\"markdownIt-Anchor\" href=\"#导入数据探索的工具包\">#</a> 导入数据探索的工具包</h1>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy <span class=\"keyword\">import</span> stats</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">&quot;ignore&quot;</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\">%matplotlib inline</span><br></pre></td></tr></table></figure>\n<h1 id=\"读取数据文件\"><a class=\"markdownIt-Anchor\" href=\"#读取数据文件\">#</a> 读取数据文件</h1>\n<p>使用 Pandas 库 read_csv () 函数进行数据读取，分割符为‘\\t’</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载需要用到的数据集</span></span><br><span class=\"line\">!wget http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/Industrial_Steam_Forecast/zhengqi_test.txt</span><br><span class=\"line\">!wget http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/Industrial_Steam_Forecast/zhengqi_train.txt</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data_file = <span class=\"string\">&quot;./zhengqi_train.txt&quot;</span></span><br><span class=\"line\">test_data_file =  <span class=\"string\">&quot;./zhengqi_test.txt&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_data = pd.read_csv(train_data_file, sep=<span class=\"string\">&#x27;\\t&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">test_data = pd.read_csv(test_data_file, sep=<span class=\"string\">&#x27;\\t&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<h1 id=\"查看训练集特征变量信息\"><a class=\"markdownIt-Anchor\" href=\"#查看训练集特征变量信息\">#</a> 查看训练集特征变量信息</h1>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2888 entries, 0 to 2887\nData columns (total 39 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   V0      2888 non-null   float64\n 1   V1      2888 non-null   float64\n 2   V2      2888 non-null   float64\n 3   V3      2888 non-null   float64\n 4   V4      2888 non-null   float64\n 5   V5      2888 non-null   float64\n 6   V6      2888 non-null   float64\n 7   V7      2888 non-null   float64\n 8   V8      2888 non-null   float64\n 9   V9      2888 non-null   float64\n 10  V10     2888 non-null   float64\n 11  V11     2888 non-null   float64\n 12  V12     2888 non-null   float64\n 13  V13     2888 non-null   float64\n 14  V14     2888 non-null   float64\n 15  V15     2888 non-null   float64\n 16  V16     2888 non-null   float64\n 17  V17     2888 non-null   float64\n 18  V18     2888 non-null   float64\n 19  V19     2888 non-null   float64\n 20  V20     2888 non-null   float64\n 21  V21     2888 non-null   float64\n 22  V22     2888 non-null   float64\n 23  V23     2888 non-null   float64\n 24  V24     2888 non-null   float64\n 25  V25     2888 non-null   float64\n 26  V26     2888 non-null   float64\n 27  V27     2888 non-null   float64\n 28  V28     2888 non-null   float64\n 29  V29     2888 non-null   float64\n 30  V30     2888 non-null   float64\n 31  V31     2888 non-null   float64\n 32  V32     2888 non-null   float64\n 33  V33     2888 non-null   float64\n 34  V34     2888 non-null   float64\n 35  V35     2888 non-null   float64\n 36  V36     2888 non-null   float64\n 37  V37     2888 non-null   float64\n 38  target  2888 non-null   float64\ndtypes: float64(39)\nmemory usage: 880.1 KB\n</code></pre>\n<p>此训练集数据共有 2888 个样本，数据中有 V0-V37 共计 38 个特征变量，变量类型都为数值类型，所有数据特征没有缺失值数据； 数据字段由于采用了脱敏处理，删除了特征数据的具体含义；target 字段为标签变量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_data.info()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1925 entries, 0 to 1924\nData columns (total 38 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   V0      1925 non-null   float64\n 1   V1      1925 non-null   float64\n 2   V2      1925 non-null   float64\n 3   V3      1925 non-null   float64\n 4   V4      1925 non-null   float64\n 5   V5      1925 non-null   float64\n 6   V6      1925 non-null   float64\n 7   V7      1925 non-null   float64\n 8   V8      1925 non-null   float64\n 9   V9      1925 non-null   float64\n 10  V10     1925 non-null   float64\n 11  V11     1925 non-null   float64\n 12  V12     1925 non-null   float64\n 13  V13     1925 non-null   float64\n 14  V14     1925 non-null   float64\n 15  V15     1925 non-null   float64\n 16  V16     1925 non-null   float64\n 17  V17     1925 non-null   float64\n 18  V18     1925 non-null   float64\n 19  V19     1925 non-null   float64\n 20  V20     1925 non-null   float64\n 21  V21     1925 non-null   float64\n 22  V22     1925 non-null   float64\n 23  V23     1925 non-null   float64\n 24  V24     1925 non-null   float64\n 25  V25     1925 non-null   float64\n 26  V26     1925 non-null   float64\n 27  V27     1925 non-null   float64\n 28  V28     1925 non-null   float64\n 29  V29     1925 non-null   float64\n 30  V30     1925 non-null   float64\n 31  V31     1925 non-null   float64\n 32  V32     1925 non-null   float64\n 33  V33     1925 non-null   float64\n 34  V34     1925 non-null   float64\n 35  V35     1925 non-null   float64\n 36  V36     1925 non-null   float64\n 37  V37     1925 non-null   float64\ndtypes: float64(38)\nmemory usage: 571.6 KB\n</code></pre>\n<p>测试集数据共有 1925 个样本，数据中有 V0-V37 共计 38 个特征变量，变量类型都为数值类型</p>\n<h1 id=\"查看数据统计信息\"><a class=\"markdownIt-Anchor\" href=\"#查看数据统计信息\">#</a> 查看数据统计信息</h1>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data.describe()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>...</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n      <td>2888.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.123048</td>\n      <td>0.056068</td>\n      <td>0.289720</td>\n      <td>-0.067790</td>\n      <td>0.012921</td>\n      <td>-0.558565</td>\n      <td>0.182892</td>\n      <td>0.116155</td>\n      <td>0.177856</td>\n      <td>-0.169452</td>\n      <td>...</td>\n      <td>0.097648</td>\n      <td>0.055477</td>\n      <td>0.127791</td>\n      <td>0.020806</td>\n      <td>0.007801</td>\n      <td>0.006715</td>\n      <td>0.197764</td>\n      <td>0.030658</td>\n      <td>-0.130330</td>\n      <td>0.126353</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.928031</td>\n      <td>0.941515</td>\n      <td>0.911236</td>\n      <td>0.970298</td>\n      <td>0.888377</td>\n      <td>0.517957</td>\n      <td>0.918054</td>\n      <td>0.955116</td>\n      <td>0.895444</td>\n      <td>0.953813</td>\n      <td>...</td>\n      <td>1.061200</td>\n      <td>0.901934</td>\n      <td>0.873028</td>\n      <td>0.902584</td>\n      <td>1.006995</td>\n      <td>1.003291</td>\n      <td>0.985675</td>\n      <td>0.970812</td>\n      <td>1.017196</td>\n      <td>0.983966</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-4.335000</td>\n      <td>-5.122000</td>\n      <td>-3.420000</td>\n      <td>-3.956000</td>\n      <td>-4.742000</td>\n      <td>-2.182000</td>\n      <td>-4.576000</td>\n      <td>-5.048000</td>\n      <td>-4.692000</td>\n      <td>-12.891000</td>\n      <td>...</td>\n      <td>-2.912000</td>\n      <td>-4.507000</td>\n      <td>-5.859000</td>\n      <td>-4.053000</td>\n      <td>-4.627000</td>\n      <td>-4.789000</td>\n      <td>-5.695000</td>\n      <td>-2.608000</td>\n      <td>-3.630000</td>\n      <td>-3.044000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.297000</td>\n      <td>-0.226250</td>\n      <td>-0.313000</td>\n      <td>-0.652250</td>\n      <td>-0.385000</td>\n      <td>-0.853000</td>\n      <td>-0.310000</td>\n      <td>-0.295000</td>\n      <td>-0.159000</td>\n      <td>-0.390000</td>\n      <td>...</td>\n      <td>-0.664000</td>\n      <td>-0.283000</td>\n      <td>-0.170250</td>\n      <td>-0.407250</td>\n      <td>-0.499000</td>\n      <td>-0.290000</td>\n      <td>-0.202500</td>\n      <td>-0.413000</td>\n      <td>-0.798250</td>\n      <td>-0.350250</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.359000</td>\n      <td>0.272500</td>\n      <td>0.386000</td>\n      <td>-0.044500</td>\n      <td>0.110000</td>\n      <td>-0.466000</td>\n      <td>0.388000</td>\n      <td>0.344000</td>\n      <td>0.362000</td>\n      <td>0.042000</td>\n      <td>...</td>\n      <td>-0.023000</td>\n      <td>0.053500</td>\n      <td>0.299500</td>\n      <td>0.039000</td>\n      <td>-0.040000</td>\n      <td>0.160000</td>\n      <td>0.364000</td>\n      <td>0.137000</td>\n      <td>-0.185500</td>\n      <td>0.313000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.726000</td>\n      <td>0.599000</td>\n      <td>0.918250</td>\n      <td>0.624000</td>\n      <td>0.550250</td>\n      <td>-0.154000</td>\n      <td>0.831250</td>\n      <td>0.782250</td>\n      <td>0.726000</td>\n      <td>0.042000</td>\n      <td>...</td>\n      <td>0.745250</td>\n      <td>0.488000</td>\n      <td>0.635000</td>\n      <td>0.557000</td>\n      <td>0.462000</td>\n      <td>0.273000</td>\n      <td>0.602000</td>\n      <td>0.644250</td>\n      <td>0.495250</td>\n      <td>0.793250</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.121000</td>\n      <td>1.918000</td>\n      <td>2.828000</td>\n      <td>2.457000</td>\n      <td>2.689000</td>\n      <td>0.489000</td>\n      <td>1.895000</td>\n      <td>1.918000</td>\n      <td>2.245000</td>\n      <td>1.335000</td>\n      <td>...</td>\n      <td>4.580000</td>\n      <td>2.689000</td>\n      <td>2.013000</td>\n      <td>2.395000</td>\n      <td>5.465000</td>\n      <td>5.110000</td>\n      <td>2.324000</td>\n      <td>5.238000</td>\n      <td>3.000000</td>\n      <td>2.538000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 39 columns</p>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_data.describe()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V28</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>...</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n      <td>1925.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.184404</td>\n      <td>-0.083912</td>\n      <td>-0.434762</td>\n      <td>0.101671</td>\n      <td>-0.019172</td>\n      <td>0.838049</td>\n      <td>-0.274092</td>\n      <td>-0.173971</td>\n      <td>-0.266709</td>\n      <td>0.255114</td>\n      <td>...</td>\n      <td>-0.206871</td>\n      <td>-0.146463</td>\n      <td>-0.083215</td>\n      <td>-0.191729</td>\n      <td>-0.030782</td>\n      <td>-0.011433</td>\n      <td>-0.009985</td>\n      <td>-0.296895</td>\n      <td>-0.046270</td>\n      <td>0.195735</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.073333</td>\n      <td>1.076670</td>\n      <td>0.969541</td>\n      <td>1.034925</td>\n      <td>1.147286</td>\n      <td>0.963043</td>\n      <td>1.054119</td>\n      <td>1.040101</td>\n      <td>1.085916</td>\n      <td>1.014394</td>\n      <td>...</td>\n      <td>1.064140</td>\n      <td>0.880593</td>\n      <td>1.126414</td>\n      <td>1.138454</td>\n      <td>1.130228</td>\n      <td>0.989732</td>\n      <td>0.995213</td>\n      <td>0.946896</td>\n      <td>1.040854</td>\n      <td>0.940599</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-4.814000</td>\n      <td>-5.488000</td>\n      <td>-4.283000</td>\n      <td>-3.276000</td>\n      <td>-4.921000</td>\n      <td>-1.168000</td>\n      <td>-5.649000</td>\n      <td>-5.625000</td>\n      <td>-6.059000</td>\n      <td>-6.784000</td>\n      <td>...</td>\n      <td>-2.435000</td>\n      <td>-2.413000</td>\n      <td>-4.507000</td>\n      <td>-7.698000</td>\n      <td>-4.057000</td>\n      <td>-4.627000</td>\n      <td>-4.789000</td>\n      <td>-7.477000</td>\n      <td>-2.608000</td>\n      <td>-3.346000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.664000</td>\n      <td>-0.451000</td>\n      <td>-0.978000</td>\n      <td>-0.644000</td>\n      <td>-0.497000</td>\n      <td>0.122000</td>\n      <td>-0.732000</td>\n      <td>-0.509000</td>\n      <td>-0.775000</td>\n      <td>-0.390000</td>\n      <td>...</td>\n      <td>-0.453000</td>\n      <td>-0.818000</td>\n      <td>-0.339000</td>\n      <td>-0.476000</td>\n      <td>-0.472000</td>\n      <td>-0.460000</td>\n      <td>-0.290000</td>\n      <td>-0.349000</td>\n      <td>-0.593000</td>\n      <td>-0.432000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.065000</td>\n      <td>0.195000</td>\n      <td>-0.267000</td>\n      <td>0.220000</td>\n      <td>0.118000</td>\n      <td>0.437000</td>\n      <td>-0.082000</td>\n      <td>0.018000</td>\n      <td>-0.004000</td>\n      <td>0.401000</td>\n      <td>...</td>\n      <td>-0.445000</td>\n      <td>-0.199000</td>\n      <td>0.010000</td>\n      <td>0.100000</td>\n      <td>0.155000</td>\n      <td>-0.040000</td>\n      <td>0.160000</td>\n      <td>-0.270000</td>\n      <td>0.083000</td>\n      <td>0.152000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.549000</td>\n      <td>0.589000</td>\n      <td>0.278000</td>\n      <td>0.793000</td>\n      <td>0.610000</td>\n      <td>1.928000</td>\n      <td>0.457000</td>\n      <td>0.515000</td>\n      <td>0.482000</td>\n      <td>0.904000</td>\n      <td>...</td>\n      <td>-0.434000</td>\n      <td>0.468000</td>\n      <td>0.447000</td>\n      <td>0.471000</td>\n      <td>0.627000</td>\n      <td>0.419000</td>\n      <td>0.273000</td>\n      <td>0.364000</td>\n      <td>0.651000</td>\n      <td>0.797000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.100000</td>\n      <td>2.120000</td>\n      <td>1.946000</td>\n      <td>2.603000</td>\n      <td>4.475000</td>\n      <td>3.176000</td>\n      <td>1.528000</td>\n      <td>1.394000</td>\n      <td>2.408000</td>\n      <td>1.766000</td>\n      <td>...</td>\n      <td>4.656000</td>\n      <td>3.022000</td>\n      <td>3.139000</td>\n      <td>1.428000</td>\n      <td>2.299000</td>\n      <td>5.465000</td>\n      <td>5.110000</td>\n      <td>1.671000</td>\n      <td>2.861000</td>\n      <td>3.021000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 38 columns</p>\n</div>\n<p>上面数据显示了数据的统计信息，例如样本数，数据的均值 mean，标准差 std，最小值，最大值等</p>\n<h1 id=\"查看数据字段信息\"><a class=\"markdownIt-Anchor\" href=\"#查看数据字段信息\">#</a> 查看数据字段信息</h1>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data.head()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.566</td>\n      <td>0.016</td>\n      <td>-0.143</td>\n      <td>0.407</td>\n      <td>0.452</td>\n      <td>-0.901</td>\n      <td>-1.812</td>\n      <td>-2.360</td>\n      <td>-0.436</td>\n      <td>-2.114</td>\n      <td>...</td>\n      <td>0.136</td>\n      <td>0.109</td>\n      <td>-0.615</td>\n      <td>0.327</td>\n      <td>-4.627</td>\n      <td>-4.789</td>\n      <td>-5.101</td>\n      <td>-2.608</td>\n      <td>-3.508</td>\n      <td>0.175</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.968</td>\n      <td>0.437</td>\n      <td>0.066</td>\n      <td>0.566</td>\n      <td>0.194</td>\n      <td>-0.893</td>\n      <td>-1.566</td>\n      <td>-2.360</td>\n      <td>0.332</td>\n      <td>-2.114</td>\n      <td>...</td>\n      <td>-0.128</td>\n      <td>0.124</td>\n      <td>0.032</td>\n      <td>0.600</td>\n      <td>-0.843</td>\n      <td>0.160</td>\n      <td>0.364</td>\n      <td>-0.335</td>\n      <td>-0.730</td>\n      <td>0.676</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.013</td>\n      <td>0.568</td>\n      <td>0.235</td>\n      <td>0.370</td>\n      <td>0.112</td>\n      <td>-0.797</td>\n      <td>-1.367</td>\n      <td>-2.360</td>\n      <td>0.396</td>\n      <td>-2.114</td>\n      <td>...</td>\n      <td>-0.009</td>\n      <td>0.361</td>\n      <td>0.277</td>\n      <td>-0.116</td>\n      <td>-0.843</td>\n      <td>0.160</td>\n      <td>0.364</td>\n      <td>0.765</td>\n      <td>-0.589</td>\n      <td>0.633</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.733</td>\n      <td>0.368</td>\n      <td>0.283</td>\n      <td>0.165</td>\n      <td>0.599</td>\n      <td>-0.679</td>\n      <td>-1.200</td>\n      <td>-2.086</td>\n      <td>0.403</td>\n      <td>-2.114</td>\n      <td>...</td>\n      <td>0.015</td>\n      <td>0.417</td>\n      <td>0.279</td>\n      <td>0.603</td>\n      <td>-0.843</td>\n      <td>-0.065</td>\n      <td>0.364</td>\n      <td>0.333</td>\n      <td>-0.112</td>\n      <td>0.206</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.684</td>\n      <td>0.638</td>\n      <td>0.260</td>\n      <td>0.209</td>\n      <td>0.337</td>\n      <td>-0.454</td>\n      <td>-1.073</td>\n      <td>-2.086</td>\n      <td>0.314</td>\n      <td>-2.114</td>\n      <td>...</td>\n      <td>0.183</td>\n      <td>1.078</td>\n      <td>0.328</td>\n      <td>0.418</td>\n      <td>-0.843</td>\n      <td>-0.215</td>\n      <td>0.364</td>\n      <td>-0.280</td>\n      <td>-0.028</td>\n      <td>0.384</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>\n<p>上面显示训练集前 5 条数据的基本信息，可以看到数据都是浮点型数据，数据都是数值型连续型特征</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_data.head()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V28</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.368</td>\n      <td>0.380</td>\n      <td>-0.225</td>\n      <td>-0.049</td>\n      <td>0.379</td>\n      <td>0.092</td>\n      <td>0.550</td>\n      <td>0.551</td>\n      <td>0.244</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.449</td>\n      <td>0.047</td>\n      <td>0.057</td>\n      <td>-0.042</td>\n      <td>0.847</td>\n      <td>0.534</td>\n      <td>-0.009</td>\n      <td>-0.190</td>\n      <td>-0.567</td>\n      <td>0.388</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.148</td>\n      <td>0.489</td>\n      <td>-0.247</td>\n      <td>-0.049</td>\n      <td>0.122</td>\n      <td>-0.201</td>\n      <td>0.487</td>\n      <td>0.493</td>\n      <td>-0.127</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.443</td>\n      <td>0.047</td>\n      <td>0.560</td>\n      <td>0.176</td>\n      <td>0.551</td>\n      <td>0.046</td>\n      <td>-0.220</td>\n      <td>0.008</td>\n      <td>-0.294</td>\n      <td>0.104</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.166</td>\n      <td>-0.062</td>\n      <td>-0.311</td>\n      <td>0.046</td>\n      <td>-0.055</td>\n      <td>0.063</td>\n      <td>0.485</td>\n      <td>0.493</td>\n      <td>-0.227</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.458</td>\n      <td>-0.398</td>\n      <td>0.101</td>\n      <td>0.199</td>\n      <td>0.634</td>\n      <td>0.017</td>\n      <td>-0.234</td>\n      <td>0.008</td>\n      <td>0.373</td>\n      <td>0.569</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.102</td>\n      <td>0.294</td>\n      <td>-0.259</td>\n      <td>0.051</td>\n      <td>-0.183</td>\n      <td>0.148</td>\n      <td>0.474</td>\n      <td>0.504</td>\n      <td>0.010</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.456</td>\n      <td>-0.398</td>\n      <td>1.007</td>\n      <td>0.137</td>\n      <td>1.042</td>\n      <td>-0.040</td>\n      <td>-0.290</td>\n      <td>0.008</td>\n      <td>-0.666</td>\n      <td>0.391</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.300</td>\n      <td>0.428</td>\n      <td>0.208</td>\n      <td>0.051</td>\n      <td>-0.033</td>\n      <td>0.116</td>\n      <td>0.408</td>\n      <td>0.497</td>\n      <td>0.155</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.458</td>\n      <td>-0.776</td>\n      <td>0.291</td>\n      <td>0.370</td>\n      <td>0.181</td>\n      <td>-0.040</td>\n      <td>-0.290</td>\n      <td>0.008</td>\n      <td>-0.140</td>\n      <td>-0.497</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>\n<h1 id=\"画箱形图探索数据\"><a class=\"markdownIt-Anchor\" href=\"#画箱形图探索数据\">#</a> 画箱形图探索数据</h1>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">4</span>, <span class=\"number\">6</span>))  <span class=\"comment\"># 指定绘图对象宽度和高度</span></span><br><span class=\"line\">sns.boxplot(train_data[<span class=\"string\">&#x27;V0&#x27;</span>],orient=<span class=\"string\">&quot;v&quot;</span>, width=<span class=\"number\">0.5</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>&lt;AxesSubplot:xlabel='V0'&gt;\n</code></pre>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_17_1.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画箱式图</span></span><br><span class=\"line\">column = train_data.columns.tolist()[:<span class=\"number\">39</span>]  <span class=\"comment\"># 列表头</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">20</span>, <span class=\"number\">40</span>))  <span class=\"comment\"># 指定绘图对象宽度和高度</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">38</span>):</span><br><span class=\"line\">    plt.subplot(<span class=\"number\">13</span>, <span class=\"number\">3</span>, i + <span class=\"number\">1</span>)  <span class=\"comment\"># 13行3列子图</span></span><br><span class=\"line\">    sns.boxplot(train_data[column[i]], orient=<span class=\"string\">&quot;v&quot;</span>, width=<span class=\"number\">0.5</span>)  <span class=\"comment\"># 箱式图</span></span><br><span class=\"line\">    plt.ylabel(column[i], fontsize=<span class=\"number\">8</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_18_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<h1 id=\"查看数据分布图\"><a class=\"markdownIt-Anchor\" href=\"#查看数据分布图\">#</a> 查看数据分布图</h1>\n<p>查看特征变量‘V0’的数据分布直方图，并绘制 Q-Q 图查看数据是否近似于正态分布</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">ax=plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">sns.distplot(train_data[<span class=\"string\">&#x27;V0&#x27;</span>],fit=stats.norm)</span><br><span class=\"line\">ax=plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">res = stats.probplot(train_data[<span class=\"string\">&#x27;V0&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_20_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>查看查看所有数据的直方图和 Q-Q 图，查看训练集的数据是否近似于正态分布</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_cols = <span class=\"number\">6</span></span><br><span class=\"line\">train_rows = <span class=\"built_in\">len</span>(train_data.columns)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">4</span>*train_cols,<span class=\"number\">4</span>*train_rows))</span><br><span class=\"line\"></span><br><span class=\"line\">i=<span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> train_data.columns:</span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    ax=plt.subplot(train_rows,train_cols,i)</span><br><span class=\"line\">    sns.distplot(train_data[col],fit=stats.norm)</span><br><span class=\"line\">    </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    ax=plt.subplot(train_rows,train_cols,i)</span><br><span class=\"line\">    res = stats.probplot(train_data[col], plot=plt)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_22_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>由上面的数据分布图信息可以看出，很多特征变量（如’V1’,‘V9’,‘V24’,'V28’等）的数据分布不是正态的，数据并不跟随对角线，后续可以使用数据变换对数据进行转换。</p>\n<p>对比同一特征变量‘V0’下，训练集数据和测试集数据的分布情况，查看数据分布是否一致</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ax = sns.kdeplot(train_data[<span class=\"string\">&#x27;V0&#x27;</span>], color=<span class=\"string\">&quot;Red&quot;</span>, shade=<span class=\"literal\">True</span>)</span><br><span class=\"line\">ax = sns.kdeplot(test_data[<span class=\"string\">&#x27;V0&#x27;</span>], color=<span class=\"string\">&quot;Blue&quot;</span>, shade=<span class=\"literal\">True</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;V0&#x27;</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&quot;Frequency&quot;</span>)</span><br><span class=\"line\">ax = ax.legend([<span class=\"string\">&quot;train&quot;</span>,<span class=\"string\">&quot;test&quot;</span>])</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_24_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>查看所有特征变量下，训练集数据和测试集数据的分布情况，分析并寻找出数据分布不一致的特征变量。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dist_cols = <span class=\"number\">6</span></span><br><span class=\"line\">dist_rows = <span class=\"built_in\">len</span>(test_data.columns)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">4</span>*dist_cols,<span class=\"number\">4</span>*dist_rows))</span><br><span class=\"line\"></span><br><span class=\"line\">i=<span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> test_data.columns:</span><br><span class=\"line\">    ax=plt.subplot(dist_rows,dist_cols,i)</span><br><span class=\"line\">    ax = sns.kdeplot(train_data[col], color=<span class=\"string\">&quot;Red&quot;</span>, shade=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    ax = sns.kdeplot(test_data[col], color=<span class=\"string\">&quot;Blue&quot;</span>, shade=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    ax.set_xlabel(col)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">&quot;Frequency&quot;</span>)</span><br><span class=\"line\">    ax = ax.legend([<span class=\"string\">&quot;train&quot;</span>,<span class=\"string\">&quot;test&quot;</span>])</span><br><span class=\"line\">    </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_26_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>查看特征’V5’, ‘V17’, ‘V28’, ‘V22’, ‘V11’, 'V9’数据的数据分布</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">drop_col = <span class=\"number\">6</span></span><br><span class=\"line\">drop_row = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">5</span>*drop_col,<span class=\"number\">5</span>*drop_row))</span><br><span class=\"line\"></span><br><span class=\"line\">i=<span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> [<span class=\"string\">&quot;V5&quot;</span>,<span class=\"string\">&quot;V9&quot;</span>,<span class=\"string\">&quot;V11&quot;</span>,<span class=\"string\">&quot;V17&quot;</span>,<span class=\"string\">&quot;V22&quot;</span>,<span class=\"string\">&quot;V28&quot;</span>]:</span><br><span class=\"line\">    ax =plt.subplot(drop_row,drop_col,i)</span><br><span class=\"line\">    ax = sns.kdeplot(train_data[col], color=<span class=\"string\">&quot;Red&quot;</span>, shade=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    ax = sns.kdeplot(test_data[col], color=<span class=\"string\">&quot;Blue&quot;</span>, shade=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    ax.set_xlabel(col)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">&quot;Frequency&quot;</span>)</span><br><span class=\"line\">    ax = ax.legend([<span class=\"string\">&quot;train&quot;</span>,<span class=\"string\">&quot;test&quot;</span>])</span><br><span class=\"line\">    </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_28_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>由上图的数据分布可以看到特征’V5’,‘V9’,‘V11’,‘V17’,‘V22’,‘V28’ 训练集数据与测试集数据分布不一致，会导致模型泛化能力差，采用删除此类特征方法。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">drop_columns = [<span class=\"string\">&#x27;V5&#x27;</span>,<span class=\"string\">&#x27;V9&#x27;</span>,<span class=\"string\">&#x27;V11&#x27;</span>,<span class=\"string\">&#x27;V17&#x27;</span>,<span class=\"string\">&#x27;V22&#x27;</span>,<span class=\"string\">&#x27;V28&#x27;</span>]</span><br><span class=\"line\"><span class=\"comment\">#合并训练集和测试集数据，并可视化训练集和测试集数据特征分布图</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"可视化线性回归关系\"><a class=\"markdownIt-Anchor\" href=\"#可视化线性回归关系\">#</a> 可视化线性回归关系</h1>\n<p>查看特征变量‘V0’与’target’变量的线性回归关系</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fcols = <span class=\"number\">2</span></span><br><span class=\"line\">frows = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">ax=plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">sns.regplot(x=<span class=\"string\">&#x27;V0&#x27;</span>, y=<span class=\"string\">&#x27;target&#x27;</span>, data=train_data, ax=ax, </span><br><span class=\"line\">            scatter_kws=&#123;<span class=\"string\">&#x27;marker&#x27;</span>:<span class=\"string\">&#x27;.&#x27;</span>,<span class=\"string\">&#x27;s&#x27;</span>:<span class=\"number\">3</span>,<span class=\"string\">&#x27;alpha&#x27;</span>:<span class=\"number\">0.3</span>&#125;,</span><br><span class=\"line\">            line_kws=&#123;<span class=\"string\">&#x27;color&#x27;</span>:<span class=\"string\">&#x27;k&#x27;</span>&#125;);</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;V0&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;target&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax=plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">sns.distplot(train_data[<span class=\"string\">&#x27;V0&#x27;</span>].dropna())</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;V0&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_32_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>查看所有特征变量与’target’变量的线性回归关系</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fcols = <span class=\"number\">6</span></span><br><span class=\"line\">frows = <span class=\"built_in\">len</span>(test_data.columns)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">5</span>*fcols,<span class=\"number\">4</span>*frows))</span><br><span class=\"line\"></span><br><span class=\"line\">i=<span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> test_data.columns:</span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    ax=plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    sns.regplot(x=col, y=<span class=\"string\">&#x27;target&#x27;</span>, data=train_data, ax=ax, </span><br><span class=\"line\">                scatter_kws=&#123;<span class=\"string\">&#x27;marker&#x27;</span>:<span class=\"string\">&#x27;.&#x27;</span>,<span class=\"string\">&#x27;s&#x27;</span>:<span class=\"number\">3</span>,<span class=\"string\">&#x27;alpha&#x27;</span>:<span class=\"number\">0.3</span>&#125;,</span><br><span class=\"line\">                line_kws=&#123;<span class=\"string\">&#x27;color&#x27;</span>:<span class=\"string\">&#x27;k&#x27;</span>&#125;);</span><br><span class=\"line\">    plt.xlabel(col)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">&#x27;target&#x27;</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    ax=plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    sns.distplot(train_data[col].dropna())</span><br><span class=\"line\">    plt.xlabel(col)</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_34_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<h1 id=\"查看特征变量的相关性\"><a class=\"markdownIt-Anchor\" href=\"#查看特征变量的相关性\">#</a> 查看特征变量的相关性</h1>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data_train1 = train_data.drop([<span class=\"string\">&#x27;V5&#x27;</span>,<span class=\"string\">&#x27;V9&#x27;</span>,<span class=\"string\">&#x27;V11&#x27;</span>,<span class=\"string\">&#x27;V17&#x27;</span>,<span class=\"string\">&#x27;V22&#x27;</span>,<span class=\"string\">&#x27;V28&#x27;</span>],axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">train_corr = data_train1.corr()</span><br><span class=\"line\">train_corr</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V10</th>\n      <th>V12</th>\n      <th>...</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>V0</th>\n      <td>1.000000</td>\n      <td>0.908607</td>\n      <td>0.463643</td>\n      <td>0.409576</td>\n      <td>0.781212</td>\n      <td>0.189267</td>\n      <td>0.141294</td>\n      <td>0.794013</td>\n      <td>0.298443</td>\n      <td>0.751830</td>\n      <td>...</td>\n      <td>0.302145</td>\n      <td>0.156968</td>\n      <td>0.675003</td>\n      <td>0.050951</td>\n      <td>0.056439</td>\n      <td>-0.019342</td>\n      <td>0.138933</td>\n      <td>0.231417</td>\n      <td>-0.494076</td>\n      <td>0.873212</td>\n    </tr>\n    <tr>\n      <th>V1</th>\n      <td>0.908607</td>\n      <td>1.000000</td>\n      <td>0.506514</td>\n      <td>0.383924</td>\n      <td>0.657790</td>\n      <td>0.276805</td>\n      <td>0.205023</td>\n      <td>0.874650</td>\n      <td>0.310120</td>\n      <td>0.656186</td>\n      <td>...</td>\n      <td>0.147096</td>\n      <td>0.175997</td>\n      <td>0.769745</td>\n      <td>0.085604</td>\n      <td>0.035129</td>\n      <td>-0.029115</td>\n      <td>0.146329</td>\n      <td>0.235299</td>\n      <td>-0.494043</td>\n      <td>0.871846</td>\n    </tr>\n    <tr>\n      <th>V2</th>\n      <td>0.463643</td>\n      <td>0.506514</td>\n      <td>1.000000</td>\n      <td>0.410148</td>\n      <td>0.057697</td>\n      <td>0.615938</td>\n      <td>0.477114</td>\n      <td>0.703431</td>\n      <td>0.346006</td>\n      <td>0.059941</td>\n      <td>...</td>\n      <td>-0.275764</td>\n      <td>0.175943</td>\n      <td>0.653764</td>\n      <td>0.033942</td>\n      <td>0.050309</td>\n      <td>-0.025620</td>\n      <td>0.043648</td>\n      <td>0.316462</td>\n      <td>-0.734956</td>\n      <td>0.638878</td>\n    </tr>\n    <tr>\n      <th>V3</th>\n      <td>0.409576</td>\n      <td>0.383924</td>\n      <td>0.410148</td>\n      <td>1.000000</td>\n      <td>0.315046</td>\n      <td>0.233896</td>\n      <td>0.197836</td>\n      <td>0.411946</td>\n      <td>0.321262</td>\n      <td>0.306397</td>\n      <td>...</td>\n      <td>0.117610</td>\n      <td>0.043966</td>\n      <td>0.421954</td>\n      <td>-0.092423</td>\n      <td>-0.007159</td>\n      <td>-0.031898</td>\n      <td>0.080034</td>\n      <td>0.324475</td>\n      <td>-0.229613</td>\n      <td>0.512074</td>\n    </tr>\n    <tr>\n      <th>V4</th>\n      <td>0.781212</td>\n      <td>0.657790</td>\n      <td>0.057697</td>\n      <td>0.315046</td>\n      <td>1.000000</td>\n      <td>-0.117529</td>\n      <td>-0.052370</td>\n      <td>0.449542</td>\n      <td>0.141129</td>\n      <td>0.927685</td>\n      <td>...</td>\n      <td>0.659093</td>\n      <td>0.022807</td>\n      <td>0.447016</td>\n      <td>-0.026186</td>\n      <td>0.062367</td>\n      <td>0.028659</td>\n      <td>0.100010</td>\n      <td>0.113609</td>\n      <td>-0.031054</td>\n      <td>0.603984</td>\n    </tr>\n    <tr>\n      <th>V6</th>\n      <td>0.189267</td>\n      <td>0.276805</td>\n      <td>0.615938</td>\n      <td>0.233896</td>\n      <td>-0.117529</td>\n      <td>1.000000</td>\n      <td>0.917502</td>\n      <td>0.468233</td>\n      <td>0.415660</td>\n      <td>-0.087312</td>\n      <td>...</td>\n      <td>-0.467980</td>\n      <td>0.188907</td>\n      <td>0.546535</td>\n      <td>0.144550</td>\n      <td>0.054210</td>\n      <td>-0.002914</td>\n      <td>0.044992</td>\n      <td>0.433804</td>\n      <td>-0.404817</td>\n      <td>0.370037</td>\n    </tr>\n    <tr>\n      <th>V7</th>\n      <td>0.141294</td>\n      <td>0.205023</td>\n      <td>0.477114</td>\n      <td>0.197836</td>\n      <td>-0.052370</td>\n      <td>0.917502</td>\n      <td>1.000000</td>\n      <td>0.389987</td>\n      <td>0.310982</td>\n      <td>-0.036791</td>\n      <td>...</td>\n      <td>-0.311363</td>\n      <td>0.170113</td>\n      <td>0.475254</td>\n      <td>0.122707</td>\n      <td>0.034508</td>\n      <td>-0.019103</td>\n      <td>0.111166</td>\n      <td>0.340479</td>\n      <td>-0.292285</td>\n      <td>0.287815</td>\n    </tr>\n    <tr>\n      <th>V8</th>\n      <td>0.794013</td>\n      <td>0.874650</td>\n      <td>0.703431</td>\n      <td>0.411946</td>\n      <td>0.449542</td>\n      <td>0.468233</td>\n      <td>0.389987</td>\n      <td>1.000000</td>\n      <td>0.419703</td>\n      <td>0.420557</td>\n      <td>...</td>\n      <td>-0.011091</td>\n      <td>0.150258</td>\n      <td>0.878072</td>\n      <td>0.038430</td>\n      <td>0.026843</td>\n      <td>-0.036297</td>\n      <td>0.179167</td>\n      <td>0.326586</td>\n      <td>-0.553121</td>\n      <td>0.831904</td>\n    </tr>\n    <tr>\n      <th>V10</th>\n      <td>0.298443</td>\n      <td>0.310120</td>\n      <td>0.346006</td>\n      <td>0.321262</td>\n      <td>0.141129</td>\n      <td>0.415660</td>\n      <td>0.310982</td>\n      <td>0.419703</td>\n      <td>1.000000</td>\n      <td>0.140462</td>\n      <td>...</td>\n      <td>-0.105042</td>\n      <td>-0.036705</td>\n      <td>0.560213</td>\n      <td>-0.093213</td>\n      <td>0.016739</td>\n      <td>-0.026994</td>\n      <td>0.026846</td>\n      <td>0.922190</td>\n      <td>-0.045851</td>\n      <td>0.394767</td>\n    </tr>\n    <tr>\n      <th>V12</th>\n      <td>0.751830</td>\n      <td>0.656186</td>\n      <td>0.059941</td>\n      <td>0.306397</td>\n      <td>0.927685</td>\n      <td>-0.087312</td>\n      <td>-0.036791</td>\n      <td>0.420557</td>\n      <td>0.140462</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.666775</td>\n      <td>0.028866</td>\n      <td>0.441963</td>\n      <td>-0.007658</td>\n      <td>0.046674</td>\n      <td>0.010122</td>\n      <td>0.081963</td>\n      <td>0.112150</td>\n      <td>-0.054827</td>\n      <td>0.594189</td>\n    </tr>\n    <tr>\n      <th>V13</th>\n      <td>0.185144</td>\n      <td>0.157518</td>\n      <td>0.204762</td>\n      <td>-0.003636</td>\n      <td>0.075993</td>\n      <td>0.138367</td>\n      <td>0.110973</td>\n      <td>0.153299</td>\n      <td>-0.059553</td>\n      <td>0.098771</td>\n      <td>...</td>\n      <td>0.008235</td>\n      <td>0.027328</td>\n      <td>0.113743</td>\n      <td>0.130598</td>\n      <td>0.157513</td>\n      <td>0.116944</td>\n      <td>0.219906</td>\n      <td>-0.024751</td>\n      <td>-0.379714</td>\n      <td>0.203373</td>\n    </tr>\n    <tr>\n      <th>V14</th>\n      <td>-0.004144</td>\n      <td>-0.006268</td>\n      <td>-0.106282</td>\n      <td>-0.232677</td>\n      <td>0.023853</td>\n      <td>0.072911</td>\n      <td>0.163931</td>\n      <td>0.008138</td>\n      <td>-0.077543</td>\n      <td>0.020069</td>\n      <td>...</td>\n      <td>0.056814</td>\n      <td>-0.004057</td>\n      <td>0.010989</td>\n      <td>0.106581</td>\n      <td>0.073535</td>\n      <td>0.043218</td>\n      <td>0.233523</td>\n      <td>-0.086217</td>\n      <td>0.010553</td>\n      <td>0.008424</td>\n    </tr>\n    <tr>\n      <th>V15</th>\n      <td>0.314520</td>\n      <td>0.164702</td>\n      <td>-0.224573</td>\n      <td>0.143457</td>\n      <td>0.615704</td>\n      <td>-0.431542</td>\n      <td>-0.291272</td>\n      <td>0.018366</td>\n      <td>-0.046737</td>\n      <td>0.642081</td>\n      <td>...</td>\n      <td>0.951314</td>\n      <td>-0.111311</td>\n      <td>0.011768</td>\n      <td>-0.104618</td>\n      <td>0.050254</td>\n      <td>0.048602</td>\n      <td>0.100817</td>\n      <td>-0.051861</td>\n      <td>0.245635</td>\n      <td>0.154020</td>\n    </tr>\n    <tr>\n      <th>V16</th>\n      <td>0.347357</td>\n      <td>0.435606</td>\n      <td>0.782474</td>\n      <td>0.394517</td>\n      <td>0.023818</td>\n      <td>0.847119</td>\n      <td>0.752683</td>\n      <td>0.680031</td>\n      <td>0.546975</td>\n      <td>0.025736</td>\n      <td>...</td>\n      <td>-0.342210</td>\n      <td>0.154794</td>\n      <td>0.778538</td>\n      <td>0.041474</td>\n      <td>0.028878</td>\n      <td>-0.054775</td>\n      <td>0.082293</td>\n      <td>0.551880</td>\n      <td>-0.420053</td>\n      <td>0.536748</td>\n    </tr>\n    <tr>\n      <th>V18</th>\n      <td>0.148622</td>\n      <td>0.123862</td>\n      <td>0.132105</td>\n      <td>0.022868</td>\n      <td>0.136022</td>\n      <td>0.110570</td>\n      <td>0.098691</td>\n      <td>0.093682</td>\n      <td>-0.024693</td>\n      <td>0.119833</td>\n      <td>...</td>\n      <td>0.053958</td>\n      <td>0.470341</td>\n      <td>0.079718</td>\n      <td>0.411967</td>\n      <td>0.512139</td>\n      <td>0.365410</td>\n      <td>0.152088</td>\n      <td>0.019603</td>\n      <td>-0.181937</td>\n      <td>0.170721</td>\n    </tr>\n    <tr>\n      <th>V19</th>\n      <td>-0.100294</td>\n      <td>-0.092673</td>\n      <td>-0.161802</td>\n      <td>-0.246008</td>\n      <td>-0.205729</td>\n      <td>0.215290</td>\n      <td>0.158371</td>\n      <td>-0.144693</td>\n      <td>0.074903</td>\n      <td>-0.148319</td>\n      <td>...</td>\n      <td>-0.205409</td>\n      <td>0.100133</td>\n      <td>-0.131542</td>\n      <td>0.144018</td>\n      <td>-0.021517</td>\n      <td>-0.079753</td>\n      <td>-0.220737</td>\n      <td>0.087605</td>\n      <td>0.012115</td>\n      <td>-0.114976</td>\n    </tr>\n    <tr>\n      <th>V20</th>\n      <td>0.462493</td>\n      <td>0.459795</td>\n      <td>0.298385</td>\n      <td>0.289594</td>\n      <td>0.291309</td>\n      <td>0.136091</td>\n      <td>0.089399</td>\n      <td>0.412868</td>\n      <td>0.207612</td>\n      <td>0.271559</td>\n      <td>...</td>\n      <td>0.016233</td>\n      <td>0.086165</td>\n      <td>0.326863</td>\n      <td>0.050699</td>\n      <td>0.009358</td>\n      <td>-0.000979</td>\n      <td>0.048981</td>\n      <td>0.161315</td>\n      <td>-0.322006</td>\n      <td>0.444965</td>\n    </tr>\n    <tr>\n      <th>V21</th>\n      <td>-0.029285</td>\n      <td>-0.012911</td>\n      <td>-0.030932</td>\n      <td>0.114373</td>\n      <td>0.174025</td>\n      <td>-0.051806</td>\n      <td>-0.065300</td>\n      <td>-0.047839</td>\n      <td>0.082288</td>\n      <td>0.144371</td>\n      <td>...</td>\n      <td>0.157097</td>\n      <td>-0.077945</td>\n      <td>0.053025</td>\n      <td>-0.159128</td>\n      <td>-0.087561</td>\n      <td>-0.053707</td>\n      <td>-0.199398</td>\n      <td>0.047340</td>\n      <td>0.315470</td>\n      <td>-0.010063</td>\n    </tr>\n    <tr>\n      <th>V23</th>\n      <td>0.231136</td>\n      <td>0.222574</td>\n      <td>0.065509</td>\n      <td>0.081374</td>\n      <td>0.196530</td>\n      <td>0.069901</td>\n      <td>0.125180</td>\n      <td>0.174124</td>\n      <td>-0.066537</td>\n      <td>0.180049</td>\n      <td>...</td>\n      <td>0.116122</td>\n      <td>0.363963</td>\n      <td>0.129783</td>\n      <td>0.367086</td>\n      <td>0.183666</td>\n      <td>0.196681</td>\n      <td>0.635252</td>\n      <td>-0.035949</td>\n      <td>-0.187582</td>\n      <td>0.226331</td>\n    </tr>\n    <tr>\n      <th>V24</th>\n      <td>-0.324959</td>\n      <td>-0.233556</td>\n      <td>0.010225</td>\n      <td>-0.237326</td>\n      <td>-0.529866</td>\n      <td>0.072418</td>\n      <td>-0.030292</td>\n      <td>-0.136898</td>\n      <td>-0.029420</td>\n      <td>-0.550881</td>\n      <td>...</td>\n      <td>-0.642370</td>\n      <td>0.033532</td>\n      <td>-0.202097</td>\n      <td>0.060608</td>\n      <td>-0.134320</td>\n      <td>-0.095588</td>\n      <td>-0.243738</td>\n      <td>-0.041325</td>\n      <td>-0.137614</td>\n      <td>-0.264815</td>\n    </tr>\n    <tr>\n      <th>V25</th>\n      <td>-0.200706</td>\n      <td>-0.070627</td>\n      <td>0.481785</td>\n      <td>-0.100569</td>\n      <td>-0.444375</td>\n      <td>0.438610</td>\n      <td>0.316744</td>\n      <td>0.173320</td>\n      <td>0.079805</td>\n      <td>-0.448877</td>\n      <td>...</td>\n      <td>-0.575154</td>\n      <td>0.088238</td>\n      <td>0.201243</td>\n      <td>0.065501</td>\n      <td>-0.013312</td>\n      <td>-0.030747</td>\n      <td>-0.093948</td>\n      <td>0.069302</td>\n      <td>-0.246742</td>\n      <td>-0.019373</td>\n    </tr>\n    <tr>\n      <th>V26</th>\n      <td>-0.125140</td>\n      <td>-0.043012</td>\n      <td>0.035370</td>\n      <td>-0.027685</td>\n      <td>-0.080487</td>\n      <td>0.106055</td>\n      <td>0.160566</td>\n      <td>0.015724</td>\n      <td>0.072366</td>\n      <td>-0.124111</td>\n      <td>...</td>\n      <td>-0.133694</td>\n      <td>-0.057247</td>\n      <td>0.062879</td>\n      <td>-0.004545</td>\n      <td>-0.034596</td>\n      <td>0.051294</td>\n      <td>0.085576</td>\n      <td>0.064963</td>\n      <td>0.010880</td>\n      <td>-0.046724</td>\n    </tr>\n    <tr>\n      <th>V27</th>\n      <td>0.733198</td>\n      <td>0.824198</td>\n      <td>0.726250</td>\n      <td>0.392006</td>\n      <td>0.412083</td>\n      <td>0.474441</td>\n      <td>0.424185</td>\n      <td>0.901100</td>\n      <td>0.246085</td>\n      <td>0.374380</td>\n      <td>...</td>\n      <td>-0.032772</td>\n      <td>0.208074</td>\n      <td>0.790239</td>\n      <td>0.095127</td>\n      <td>0.030135</td>\n      <td>-0.036123</td>\n      <td>0.159884</td>\n      <td>0.226713</td>\n      <td>-0.617771</td>\n      <td>0.812585</td>\n    </tr>\n    <tr>\n      <th>V29</th>\n      <td>0.302145</td>\n      <td>0.147096</td>\n      <td>-0.275764</td>\n      <td>0.117610</td>\n      <td>0.659093</td>\n      <td>-0.467980</td>\n      <td>-0.311363</td>\n      <td>-0.011091</td>\n      <td>-0.105042</td>\n      <td>0.666775</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>-0.122817</td>\n      <td>-0.004364</td>\n      <td>-0.110699</td>\n      <td>0.035272</td>\n      <td>0.035392</td>\n      <td>0.078588</td>\n      <td>-0.099309</td>\n      <td>0.285581</td>\n      <td>0.123329</td>\n    </tr>\n    <tr>\n      <th>V30</th>\n      <td>0.156968</td>\n      <td>0.175997</td>\n      <td>0.175943</td>\n      <td>0.043966</td>\n      <td>0.022807</td>\n      <td>0.188907</td>\n      <td>0.170113</td>\n      <td>0.150258</td>\n      <td>-0.036705</td>\n      <td>0.028866</td>\n      <td>...</td>\n      <td>-0.122817</td>\n      <td>1.000000</td>\n      <td>0.114318</td>\n      <td>0.695725</td>\n      <td>0.083693</td>\n      <td>-0.028573</td>\n      <td>-0.027987</td>\n      <td>0.006961</td>\n      <td>-0.256814</td>\n      <td>0.187311</td>\n    </tr>\n    <tr>\n      <th>V31</th>\n      <td>0.675003</td>\n      <td>0.769745</td>\n      <td>0.653764</td>\n      <td>0.421954</td>\n      <td>0.447016</td>\n      <td>0.546535</td>\n      <td>0.475254</td>\n      <td>0.878072</td>\n      <td>0.560213</td>\n      <td>0.441963</td>\n      <td>...</td>\n      <td>-0.004364</td>\n      <td>0.114318</td>\n      <td>1.000000</td>\n      <td>0.016782</td>\n      <td>0.016733</td>\n      <td>-0.047273</td>\n      <td>0.152314</td>\n      <td>0.510851</td>\n      <td>-0.357785</td>\n      <td>0.750297</td>\n    </tr>\n    <tr>\n      <th>V32</th>\n      <td>0.050951</td>\n      <td>0.085604</td>\n      <td>0.033942</td>\n      <td>-0.092423</td>\n      <td>-0.026186</td>\n      <td>0.144550</td>\n      <td>0.122707</td>\n      <td>0.038430</td>\n      <td>-0.093213</td>\n      <td>-0.007658</td>\n      <td>...</td>\n      <td>-0.110699</td>\n      <td>0.695725</td>\n      <td>0.016782</td>\n      <td>1.000000</td>\n      <td>0.105255</td>\n      <td>0.069300</td>\n      <td>0.016901</td>\n      <td>-0.054411</td>\n      <td>-0.162417</td>\n      <td>0.066606</td>\n    </tr>\n    <tr>\n      <th>V33</th>\n      <td>0.056439</td>\n      <td>0.035129</td>\n      <td>0.050309</td>\n      <td>-0.007159</td>\n      <td>0.062367</td>\n      <td>0.054210</td>\n      <td>0.034508</td>\n      <td>0.026843</td>\n      <td>0.016739</td>\n      <td>0.046674</td>\n      <td>...</td>\n      <td>0.035272</td>\n      <td>0.083693</td>\n      <td>0.016733</td>\n      <td>0.105255</td>\n      <td>1.000000</td>\n      <td>0.719126</td>\n      <td>0.167597</td>\n      <td>0.031586</td>\n      <td>-0.062715</td>\n      <td>0.077273</td>\n    </tr>\n    <tr>\n      <th>V34</th>\n      <td>-0.019342</td>\n      <td>-0.029115</td>\n      <td>-0.025620</td>\n      <td>-0.031898</td>\n      <td>0.028659</td>\n      <td>-0.002914</td>\n      <td>-0.019103</td>\n      <td>-0.036297</td>\n      <td>-0.026994</td>\n      <td>0.010122</td>\n      <td>...</td>\n      <td>0.035392</td>\n      <td>-0.028573</td>\n      <td>-0.047273</td>\n      <td>0.069300</td>\n      <td>0.719126</td>\n      <td>1.000000</td>\n      <td>0.233616</td>\n      <td>-0.019032</td>\n      <td>-0.006854</td>\n      <td>-0.006034</td>\n    </tr>\n    <tr>\n      <th>V35</th>\n      <td>0.138933</td>\n      <td>0.146329</td>\n      <td>0.043648</td>\n      <td>0.080034</td>\n      <td>0.100010</td>\n      <td>0.044992</td>\n      <td>0.111166</td>\n      <td>0.179167</td>\n      <td>0.026846</td>\n      <td>0.081963</td>\n      <td>...</td>\n      <td>0.078588</td>\n      <td>-0.027987</td>\n      <td>0.152314</td>\n      <td>0.016901</td>\n      <td>0.167597</td>\n      <td>0.233616</td>\n      <td>1.000000</td>\n      <td>0.025401</td>\n      <td>-0.077991</td>\n      <td>0.140294</td>\n    </tr>\n    <tr>\n      <th>V36</th>\n      <td>0.231417</td>\n      <td>0.235299</td>\n      <td>0.316462</td>\n      <td>0.324475</td>\n      <td>0.113609</td>\n      <td>0.433804</td>\n      <td>0.340479</td>\n      <td>0.326586</td>\n      <td>0.922190</td>\n      <td>0.112150</td>\n      <td>...</td>\n      <td>-0.099309</td>\n      <td>0.006961</td>\n      <td>0.510851</td>\n      <td>-0.054411</td>\n      <td>0.031586</td>\n      <td>-0.019032</td>\n      <td>0.025401</td>\n      <td>1.000000</td>\n      <td>-0.039478</td>\n      <td>0.319309</td>\n    </tr>\n    <tr>\n      <th>V37</th>\n      <td>-0.494076</td>\n      <td>-0.494043</td>\n      <td>-0.734956</td>\n      <td>-0.229613</td>\n      <td>-0.031054</td>\n      <td>-0.404817</td>\n      <td>-0.292285</td>\n      <td>-0.553121</td>\n      <td>-0.045851</td>\n      <td>-0.054827</td>\n      <td>...</td>\n      <td>0.285581</td>\n      <td>-0.256814</td>\n      <td>-0.357785</td>\n      <td>-0.162417</td>\n      <td>-0.062715</td>\n      <td>-0.006854</td>\n      <td>-0.077991</td>\n      <td>-0.039478</td>\n      <td>1.000000</td>\n      <td>-0.565795</td>\n    </tr>\n    <tr>\n      <th>target</th>\n      <td>0.873212</td>\n      <td>0.871846</td>\n      <td>0.638878</td>\n      <td>0.512074</td>\n      <td>0.603984</td>\n      <td>0.370037</td>\n      <td>0.287815</td>\n      <td>0.831904</td>\n      <td>0.394767</td>\n      <td>0.594189</td>\n      <td>...</td>\n      <td>0.123329</td>\n      <td>0.187311</td>\n      <td>0.750297</td>\n      <td>0.066606</td>\n      <td>0.077273</td>\n      <td>-0.006034</td>\n      <td>0.140294</td>\n      <td>0.319309</td>\n      <td>-0.565795</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>33 rows × 33 columns</p>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 画出相关性热力图</span></span><br><span class=\"line\">ax = plt.subplots(figsize=(<span class=\"number\">20</span>, <span class=\"number\">16</span>))<span class=\"comment\">#调整画布大小</span></span><br><span class=\"line\"></span><br><span class=\"line\">ax = sns.heatmap(train_corr, vmax=<span class=\"number\">.8</span>, square=<span class=\"literal\">True</span>, annot=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\">#画热力图   annot=True 显示系数</span></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_37_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 找出相关程度</span></span><br><span class=\"line\">data_train1 = train_data.drop([<span class=\"string\">&#x27;V5&#x27;</span>,<span class=\"string\">&#x27;V9&#x27;</span>,<span class=\"string\">&#x27;V11&#x27;</span>,<span class=\"string\">&#x27;V17&#x27;</span>,<span class=\"string\">&#x27;V22&#x27;</span>,<span class=\"string\">&#x27;V28&#x27;</span>],axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">20</span>, <span class=\"number\">16</span>))  <span class=\"comment\"># 指定绘图对象宽度和高度</span></span><br><span class=\"line\">colnm = data_train1.columns.tolist()  <span class=\"comment\"># 列表头</span></span><br><span class=\"line\">mcorr = data_train1[colnm].corr(method=<span class=\"string\">&quot;spearman&quot;</span>)  <span class=\"comment\"># 相关系数矩阵，即给出了任意两个变量之间的相关系数</span></span><br><span class=\"line\">mask = np.zeros_like(mcorr, dtype=np.<span class=\"built_in\">bool</span>)  <span class=\"comment\"># 构造与mcorr同维数矩阵 为bool型</span></span><br><span class=\"line\">mask[np.triu_indices_from(mask)] = <span class=\"literal\">True</span>  <span class=\"comment\"># 角分线右侧为True</span></span><br><span class=\"line\">cmap = sns.diverging_palette(<span class=\"number\">220</span>, <span class=\"number\">10</span>, as_cmap=<span class=\"literal\">True</span>)  <span class=\"comment\"># 返回matplotlib colormap对象</span></span><br><span class=\"line\">g = sns.heatmap(mcorr, mask=mask, cmap=cmap, square=<span class=\"literal\">True</span>, annot=<span class=\"literal\">True</span>, fmt=<span class=\"string\">&#x27;0.2f&#x27;</span>)  <span class=\"comment\"># 热力图（看两两相似度）</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_38_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<p>上图为所有特征变量和 target 变量两两之间的相关系数，由此可以看出各个特征变量 V0-V37 之间的相关性以及特征变量 V0-V37 与 target 的相关性。</p>\n<h1 id=\"查找出特征变量和target变量相关系数大于05的特征变量\"><a class=\"markdownIt-Anchor\" href=\"#查找出特征变量和target变量相关系数大于05的特征变量\">#</a> 查找出特征变量和 target 变量相关系数大于 0.5 的特征变量</h1>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#寻找K个最相关的特征信息</span></span><br><span class=\"line\">k = <span class=\"number\">10</span> <span class=\"comment\"># number of variables for heatmap</span></span><br><span class=\"line\">cols = train_corr.nlargest(k, <span class=\"string\">&#x27;target&#x27;</span>)[<span class=\"string\">&#x27;target&#x27;</span>].index</span><br><span class=\"line\"></span><br><span class=\"line\">cm = np.corrcoef(train_data[cols].values.T)</span><br><span class=\"line\">hm = plt.subplots(figsize=(<span class=\"number\">10</span>, <span class=\"number\">10</span>))<span class=\"comment\">#调整画布大小</span></span><br><span class=\"line\"><span class=\"comment\">#hm = sns.heatmap(cm, cbar=True, annot=True, square=True)</span></span><br><span class=\"line\"><span class=\"comment\">#g = sns.heatmap(train_data[cols].corr(),annot=True,square=True,cmap=&quot;RdYlGn&quot;)</span></span><br><span class=\"line\">hm = sns.heatmap(train_data[cols].corr(),annot=<span class=\"literal\">True</span>,square=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_40_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">threshold = <span class=\"number\">0.5</span></span><br><span class=\"line\"></span><br><span class=\"line\">corrmat = train_data.corr()</span><br><span class=\"line\">top_corr_features = corrmat.index[<span class=\"built_in\">abs</span>(corrmat[<span class=\"string\">&quot;target&quot;</span>])&gt;threshold]</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\">g = sns.heatmap(train_data[top_corr_features].corr(),annot=<span class=\"literal\">True</span>,cmap=<span class=\"string\">&quot;RdYlGn&quot;</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_41_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">drop_columns.clear()</span><br><span class=\"line\">drop_columns = [<span class=\"string\">&#x27;V5&#x27;</span>,<span class=\"string\">&#x27;V9&#x27;</span>,<span class=\"string\">&#x27;V11&#x27;</span>,<span class=\"string\">&#x27;V17&#x27;</span>,<span class=\"string\">&#x27;V22&#x27;</span>,<span class=\"string\">&#x27;V28&#x27;</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Threshold for removing correlated variables</span></span><br><span class=\"line\">threshold = <span class=\"number\">0.5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Absolute value correlation matrix</span></span><br><span class=\"line\">corr_matrix = data_train1.corr().<span class=\"built_in\">abs</span>()</span><br><span class=\"line\">drop_col=corr_matrix[corr_matrix[<span class=\"string\">&quot;target&quot;</span>]&lt;threshold].index</span><br><span class=\"line\"><span class=\"comment\">#data_all.drop(drop_col, axis=1, inplace=True)</span></span><br></pre></td></tr></table></figure>\n<p>由于’V14’, ‘V21’, ‘V25’, ‘V26’, ‘V32’, ‘V33’, 'V34’特征的相关系数值小于 0.5，故认为这些特征与最终的预测 target 值不相关，删除这些特征变量；</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#merge train_set and test_set</span></span><br><span class=\"line\">train_x =  train_data.drop([<span class=\"string\">&#x27;target&#x27;</span>], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#data_all=pd.concat([train_data,test_data],axis=0,ignore_index=True)</span></span><br><span class=\"line\">data_all = pd.concat([train_x,test_data]) </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">data_all.drop(drop_columns,axis=<span class=\"number\">1</span>,inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\">#View data</span></span><br><span class=\"line\">data_all.head()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V10</th>\n      <th>V12</th>\n      <th>...</th>\n      <th>V27</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.566</td>\n      <td>0.016</td>\n      <td>-0.143</td>\n      <td>0.407</td>\n      <td>0.452</td>\n      <td>-1.812</td>\n      <td>-2.360</td>\n      <td>-0.436</td>\n      <td>-0.940</td>\n      <td>-0.073</td>\n      <td>...</td>\n      <td>0.168</td>\n      <td>0.136</td>\n      <td>0.109</td>\n      <td>-0.615</td>\n      <td>0.327</td>\n      <td>-4.627</td>\n      <td>-4.789</td>\n      <td>-5.101</td>\n      <td>-2.608</td>\n      <td>-3.508</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.968</td>\n      <td>0.437</td>\n      <td>0.066</td>\n      <td>0.566</td>\n      <td>0.194</td>\n      <td>-1.566</td>\n      <td>-2.360</td>\n      <td>0.332</td>\n      <td>0.188</td>\n      <td>-0.134</td>\n      <td>...</td>\n      <td>0.338</td>\n      <td>-0.128</td>\n      <td>0.124</td>\n      <td>0.032</td>\n      <td>0.600</td>\n      <td>-0.843</td>\n      <td>0.160</td>\n      <td>0.364</td>\n      <td>-0.335</td>\n      <td>-0.730</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.013</td>\n      <td>0.568</td>\n      <td>0.235</td>\n      <td>0.370</td>\n      <td>0.112</td>\n      <td>-1.367</td>\n      <td>-2.360</td>\n      <td>0.396</td>\n      <td>0.874</td>\n      <td>-0.072</td>\n      <td>...</td>\n      <td>0.326</td>\n      <td>-0.009</td>\n      <td>0.361</td>\n      <td>0.277</td>\n      <td>-0.116</td>\n      <td>-0.843</td>\n      <td>0.160</td>\n      <td>0.364</td>\n      <td>0.765</td>\n      <td>-0.589</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.733</td>\n      <td>0.368</td>\n      <td>0.283</td>\n      <td>0.165</td>\n      <td>0.599</td>\n      <td>-1.200</td>\n      <td>-2.086</td>\n      <td>0.403</td>\n      <td>0.011</td>\n      <td>-0.014</td>\n      <td>...</td>\n      <td>0.277</td>\n      <td>0.015</td>\n      <td>0.417</td>\n      <td>0.279</td>\n      <td>0.603</td>\n      <td>-0.843</td>\n      <td>-0.065</td>\n      <td>0.364</td>\n      <td>0.333</td>\n      <td>-0.112</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.684</td>\n      <td>0.638</td>\n      <td>0.260</td>\n      <td>0.209</td>\n      <td>0.337</td>\n      <td>-1.073</td>\n      <td>-2.086</td>\n      <td>0.314</td>\n      <td>-0.251</td>\n      <td>0.199</td>\n      <td>...</td>\n      <td>0.332</td>\n      <td>0.183</td>\n      <td>1.078</td>\n      <td>0.328</td>\n      <td>0.418</td>\n      <td>-0.843</td>\n      <td>-0.215</td>\n      <td>0.364</td>\n      <td>-0.280</td>\n      <td>-0.028</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># normalise numeric columns</span></span><br><span class=\"line\">cols_numeric=<span class=\"built_in\">list</span>(data_all.columns)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">scale_minmax</span>(<span class=\"params\">col</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (col-col.<span class=\"built_in\">min</span>())/(col.<span class=\"built_in\">max</span>()-col.<span class=\"built_in\">min</span>())</span><br><span class=\"line\"></span><br><span class=\"line\">data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax,axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">data_all[cols_numeric].describe()</span><br></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V10</th>\n      <th>V12</th>\n      <th>...</th>\n      <th>V27</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>...</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n      <td>4813.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.694172</td>\n      <td>0.721357</td>\n      <td>0.602300</td>\n      <td>0.603139</td>\n      <td>0.523743</td>\n      <td>0.748823</td>\n      <td>0.745740</td>\n      <td>0.715607</td>\n      <td>0.348518</td>\n      <td>0.578507</td>\n      <td>...</td>\n      <td>0.881401</td>\n      <td>0.388683</td>\n      <td>0.589459</td>\n      <td>0.792709</td>\n      <td>0.628824</td>\n      <td>0.458493</td>\n      <td>0.483790</td>\n      <td>0.762873</td>\n      <td>0.332385</td>\n      <td>0.545795</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.144198</td>\n      <td>0.131443</td>\n      <td>0.140628</td>\n      <td>0.152462</td>\n      <td>0.106430</td>\n      <td>0.132560</td>\n      <td>0.132577</td>\n      <td>0.118105</td>\n      <td>0.134882</td>\n      <td>0.105088</td>\n      <td>...</td>\n      <td>0.128221</td>\n      <td>0.133475</td>\n      <td>0.130786</td>\n      <td>0.102976</td>\n      <td>0.155003</td>\n      <td>0.099095</td>\n      <td>0.101020</td>\n      <td>0.102037</td>\n      <td>0.127456</td>\n      <td>0.150356</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.626676</td>\n      <td>0.679416</td>\n      <td>0.514414</td>\n      <td>0.503888</td>\n      <td>0.478182</td>\n      <td>0.683324</td>\n      <td>0.696938</td>\n      <td>0.664934</td>\n      <td>0.284327</td>\n      <td>0.532892</td>\n      <td>...</td>\n      <td>0.888575</td>\n      <td>0.292445</td>\n      <td>0.550092</td>\n      <td>0.761816</td>\n      <td>0.562461</td>\n      <td>0.409037</td>\n      <td>0.454490</td>\n      <td>0.727273</td>\n      <td>0.270584</td>\n      <td>0.445647</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.729488</td>\n      <td>0.752497</td>\n      <td>0.617072</td>\n      <td>0.614270</td>\n      <td>0.535866</td>\n      <td>0.774125</td>\n      <td>0.771974</td>\n      <td>0.742884</td>\n      <td>0.366469</td>\n      <td>0.591635</td>\n      <td>...</td>\n      <td>0.916015</td>\n      <td>0.375734</td>\n      <td>0.594428</td>\n      <td>0.815055</td>\n      <td>0.643056</td>\n      <td>0.454518</td>\n      <td>0.499949</td>\n      <td>0.800020</td>\n      <td>0.347056</td>\n      <td>0.539317</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.790195</td>\n      <td>0.799553</td>\n      <td>0.700464</td>\n      <td>0.710474</td>\n      <td>0.585036</td>\n      <td>0.842259</td>\n      <td>0.836405</td>\n      <td>0.790835</td>\n      <td>0.432965</td>\n      <td>0.641971</td>\n      <td>...</td>\n      <td>0.932555</td>\n      <td>0.471837</td>\n      <td>0.650798</td>\n      <td>0.852229</td>\n      <td>0.719777</td>\n      <td>0.500000</td>\n      <td>0.511365</td>\n      <td>0.800020</td>\n      <td>0.414861</td>\n      <td>0.643061</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 32 columns</p>\n</div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#col_data_process = cols_numeric.append(&#x27;target&#x27;)</span></span><br><span class=\"line\">train_data_process = train_data[cols_numeric]</span><br><span class=\"line\">train_data_process = train_data_process[cols_numeric].apply(scale_minmax,axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">test_data_process = test_data[cols_numeric]</span><br><span class=\"line\">test_data_process = test_data_process[cols_numeric].apply(scale_minmax,axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cols_numeric_left = cols_numeric[<span class=\"number\">0</span>:<span class=\"number\">13</span>]</span><br><span class=\"line\">cols_numeric_right = cols_numeric[<span class=\"number\">13</span>:]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## Check effect of Box-Cox transforms on distributions of continuous variables</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_data_process = pd.concat([train_data_process, train_data[<span class=\"string\">&#x27;target&#x27;</span>]], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fcols = <span class=\"number\">6</span></span><br><span class=\"line\">frows = <span class=\"built_in\">len</span>(cols_numeric_left)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">4</span>*fcols,<span class=\"number\">4</span>*frows))</span><br><span class=\"line\">i=<span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> var <span class=\"keyword\">in</span> cols_numeric_left:</span><br><span class=\"line\">    dat = train_data_process[[var, <span class=\"string\">&#x27;target&#x27;</span>]].dropna()</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    sns.distplot(dat[var] , fit=stats.norm);</span><br><span class=\"line\">    plt.title(var+<span class=\"string\">&#x27; Original&#x27;</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    _=stats.probplot(dat[var], plot=plt)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;skew=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(stats.skew(dat[var])))</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    plt.plot(dat[var], dat[<span class=\"string\">&#x27;target&#x27;</span>],<span class=\"string\">&#x27;.&#x27;</span>,alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;corr=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(np.corrcoef(dat[var], dat[<span class=\"string\">&#x27;target&#x27;</span>])[<span class=\"number\">0</span>][<span class=\"number\">1</span>]))</span><br><span class=\"line\"> </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    trans_var, lambda_var = stats.boxcox(dat[var].dropna()+<span class=\"number\">1</span>)</span><br><span class=\"line\">    trans_var = scale_minmax(trans_var)      </span><br><span class=\"line\">    sns.distplot(trans_var , fit=stats.norm);</span><br><span class=\"line\">    plt.title(var+<span class=\"string\">&#x27; Tramsformed&#x27;</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    _=stats.probplot(trans_var, plot=plt)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;skew=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(stats.skew(trans_var)))</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    plt.plot(trans_var, dat[<span class=\"string\">&#x27;target&#x27;</span>],<span class=\"string\">&#x27;.&#x27;</span>,alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;corr=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(np.corrcoef(trans_var,dat[<span class=\"string\">&#x27;target&#x27;</span>])[<span class=\"number\">0</span>][<span class=\"number\">1</span>]))</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_49_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## Check effect of Box-Cox transforms on distributions of continuous variables</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">fcols = <span class=\"number\">6</span></span><br><span class=\"line\">frows = <span class=\"built_in\">len</span>(cols_numeric_right)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">4</span>*fcols,<span class=\"number\">4</span>*frows))</span><br><span class=\"line\">i=<span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> var <span class=\"keyword\">in</span> cols_numeric_right:</span><br><span class=\"line\">    dat = train_data_process[[var, <span class=\"string\">&#x27;target&#x27;</span>]].dropna()</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    sns.distplot(dat[var] , fit=stats.norm);</span><br><span class=\"line\">    plt.title(var+<span class=\"string\">&#x27; Original&#x27;</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    _=stats.probplot(dat[var], plot=plt)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;skew=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(stats.skew(dat[var])))</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    plt.plot(dat[var], dat[<span class=\"string\">&#x27;target&#x27;</span>],<span class=\"string\">&#x27;.&#x27;</span>,alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;corr=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(np.corrcoef(dat[var], dat[<span class=\"string\">&#x27;target&#x27;</span>])[<span class=\"number\">0</span>][<span class=\"number\">1</span>]))</span><br><span class=\"line\"> </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    trans_var, lambda_var = stats.boxcox(dat[var].dropna()+<span class=\"number\">1</span>)</span><br><span class=\"line\">    trans_var = scale_minmax(trans_var)      </span><br><span class=\"line\">    sns.distplot(trans_var , fit=stats.norm);</span><br><span class=\"line\">    plt.title(var+<span class=\"string\">&#x27; Tramsformed&#x27;</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    _=stats.probplot(trans_var, plot=plt)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;skew=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(stats.skew(trans_var)))</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    i+=<span class=\"number\">1</span></span><br><span class=\"line\">    plt.subplot(frows,fcols,i)</span><br><span class=\"line\">    plt.plot(trans_var, dat[<span class=\"string\">&#x27;target&#x27;</span>],<span class=\"string\">&#x27;.&#x27;</span>,alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">&#x27;corr=&#x27;</span>+<span class=\"string\">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(np.corrcoef(trans_var,dat[<span class=\"string\">&#x27;target&#x27;</span>])[<span class=\"number\">0</span>][<span class=\"number\">1</span>]))</span><br></pre></td></tr></table></figure>\n<p>​<br>\n<img \"\" class=\"lazyload placeholder\" data-original=\"output_50_0.png\" src=\"https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif\" alt=\"png\"><br>\n​</p>\n",
            "tags": [
                "机器学习"
            ]
        }
    ]
}